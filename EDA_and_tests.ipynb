{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#train_err = pd.read_csv('./data/train_err_data.csv')\n",
    "#train_qual = pd.read_csv('./data/train_quality_data.csv')\n",
    "train_prob = pd.read_csv('./data/train_problem_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16554663, 6), (828624, 16), (5429, 2))"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_err.shape, train_qual.shape, train_prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_qual에서 quality 3와 4는 모두 0의 값을 가지기 때문에 삭제, 나머지 열은 data type을 모두 숫자형으로 바꿔준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fwver</th>\n",
       "      <th>time</th>\n",
       "      <th>quality_0</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_6</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "      <th>quality_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       fwver            time  quality_0  quality_1  quality_2  \\\n",
       "0    10000  05.15.2138  20201129090000        0.0          0        0.0   \n",
       "1    10000  05.15.2138  20201129090000        0.0          0        0.0   \n",
       "2    10000  05.15.2138  20201129090000        0.0          0        0.0   \n",
       "3    10000  05.15.2138  20201129090000        0.0          0        0.0   \n",
       "4    10000  05.15.2138  20201129090000        0.0          0        0.0   \n",
       "\n",
       "   quality_5  quality_6  quality_7  quality_8  quality_9  quality_10  \\\n",
       "0        0.0          0        0.0        0.0        0.0         4.0   \n",
       "1        0.0          0        0.0        0.0        0.0         4.0   \n",
       "2        0.0          0        0.0        0.0        0.0         4.0   \n",
       "3        0.0          0        0.0        0.0        0.0         4.0   \n",
       "4        0.0          0        0.0        0.0        0.0         4.0   \n",
       "\n",
       "   quality_11  quality_12  \n",
       "0           0           0  \n",
       "1           0           0  \n",
       "2           0           0  \n",
       "3           0           0  \n",
       "4           0           0  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_qual_num = train_qual_num = train_qual[['quality_' + str(i) for i in range(13)]]\n",
    "\n",
    "del train_qual_num['quality_3']\n",
    "del train_qual_num['quality_4']\n",
    "\n",
    "obj_col = ['quality_5', 'quality_7', 'quality_8', 'quality_9', 'quality_10']\n",
    "num_col = ['quality_0', 'quality_1', 'quality_2', 'quality_6', 'quality_11', 'quality_12']\n",
    "\n",
    "for col in obj_col:\n",
    "    train_qual_num[col] = train_qual_num[col].astype(str).str.replace(',', '').astype(float)\n",
    "    \n",
    "new_train_qual = train_qual[['user_id', 'fwver', 'time']].join(train_qual_num)\n",
    "new_train_qual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qual_col = ['quality_' + str(i) for i in range(3)] + ['quality_' + str(i) for i in range(5, 13)]\n",
    "\n",
    "#nnew_train_qual = new_train_qual.drop_duplicates(subset=['user_id', 'fwver'] + qual_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric features - train_qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABQkAAAR6CAYAAADoP/EuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3WGMneV95/3vrzikJFtiQwfE2iBomSctYRUCI3A3UvU0LsakVcyLIEGrtRVZ8oo63WRZqTH7xl1YHhFptbQ8m1hyYhd71Q1x2UZYWYNrOYlWlYAwJBQCLvLESWHWFE+wIeyiJA/p/3lxrkkOkzMzZ46dDJ7z/UhH933/7+u6/2feHF3zv+/7ulJVSJIkSZIkSRpev7TYX0CSJEmSJEnS4rJIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkFu22F/gdPvVX/3VuvTSSxf7a0j6OXjyySe/V1Uji/09zhT+HkpLl7+HC+PvobS0+Zu4MP4mSkvXqf4eLrki4aWXXsr4+Phifw1JPwdJ/mGxv8OZxN9Daeny93Bh/D2UljZ/ExfG30Rp6TrV30NfN5YkSZIkSZKGnEVCSZIkSZIkachZJJQkSZIkSZKG3LxFwiTvTfJU1+f7ST6Z5LwkB5McadsVrX2S3JdkIsnTSa7uutbG1v5Iko1d8WuSPNP63JckLd4zhyRJkiRJkqTTZ94iYVU9X1VXVdVVwDXAG8CXgK3AoaoaBQ61Y4AbgdH22Qxsh07BD9gGXAdcC2zrKvptb22n+61r8dlySJIkSZIkSTpNFvq68Rrg21X1D8B6YHeL7wZuavvrgT3V8RiwPMlFwA3Awao6UVUngYPAunbu3Kp6tKoK2DPjWr1ySJIkSZIkSTpNFlokvAX4Qtu/sKpeAmjbC1p8JfBiV5/JFpsrPtkjPlcOSZIkLbIk/zbJs0m+leQLSX45yWVJHm/TxXwxydmt7Tvb8UQ7f2nXde5o8eeT3NAVX9diE0m2dsV75pAkSdLg+i4StsHXR4C/mq9pj1gNEO9bks1JxpOMT01NLaSrJEmSBpBkJfBvgLGquhI4i84N5U8D97bpYk4Cm1qXTcDJqrocuLe1I8kVrd/76Ew589kkZyU5C/gMnalsrgBubW2ZI4ckSZIGtJAnCW8EvlFVL7fjl9urwrTt8RafBC7u6rcKODZPfFWP+Fw53qKqdlTVWFWNjYyMLOBPkiRJ0ilYBpyTZBnwLuAl4EPAg+38zClppqeReRBY0xarWw88UFU/rKrvABN05q++FpioqqNV9SPgAWB96zNbDkmSJA1oIUXCW/npq8YA+4DpFYo3Ag91xTe0VY5XA6+1V4UPAGuTrGgLlqwFDrRzrydZ3QZ9G2Zcq1cOSZIkLaKq+l/AfwJeoFMcfA14Eni1qt5szbqnkfnJ1DPt/GvA+Sx8qprz58ghSZKkAfVVJEzyLuB64K+7wvcA1yc50s7d0+L7gaN07gJ/DvgjgKo6AdwFPNE+d7YYwG3A51ufbwMPz5NDkiRJi6jd9F0PXAb8c+DddN48mWl6GpnTNSVNX1PVOB2NJEnSwizrp1FVvUHnrm137BU6qx3PbFvAllmuswvY1SM+DlzZI94zhyRJkhbd7wLfqaopgCR/DfxLYHmSZe1Jv+5pZKannplsrye/BzjB7FPSMEv8e3Pk+Imq2gHsABgbG1vQfNeSJEnDaKGrG0uSJEnQec14dZJ3tSlj1gDPAV8FPtrazJySZnoamY8CX2k3l/cBt7TVjy8DRoGv03nzZLStZHw2ncVN9rU+s+WQJEnSgCwSSpIkacGq6nE6i4d8A3iGzrhyB/Ap4PYkE3TeRNnZuuwEzm/x24Gt7TrPAnvpFBgfAbZU1Y/bU4IfpzOv9WFgb2vLHDkkSZI0oL5eN16q/tvjL/xM7A+uu2QRvokkLS5/DyUNoqq2AdtmhI/SWZl4ZtsfADfPcp27gbt7xPfTme96ZrxnjtNl5m+iv4eShpVjRGm4+CShJEmSJEmSNOQsEkqSJEmSJElDziKhJEmSJEmSNOQsEkqSJEmSJElDziKhJEmSJEmSNOQsEkqSJEmSJElDziKhJC1Akn+b5Nkk30ryhSS/nOSyJI8nOZLki0nObm3f2Y4n2vlLu65zR4s/n+SGrvi6FptIsrUr3jOHJEmSFp9jRElLgUVCSepTkpXAvwHGqupK4CzgFuDTwL1VNQqcBDa1LpuAk1V1OXBva0eSK1q/9wHrgM8mOSvJWcBngBuBK4BbW1vmyCFJkqRF5BhR0lJhkVCSFmYZcE6SZcC7gJeADwEPtvO7gZva/vp2TDu/Jkla/IGq+mFVfQeYAK5tn4mqOlpVPwIeANa3PrPlkCRJ0uJzjCjpjGeRUJL6VFX/C/hPwAt0Bn6vAU8Cr1bVm63ZJLCy7a8EXmx932ztz++Oz+gzW/z8OXJIkiRpETlGlLRUWCSUpD4lWUHnDu9lwD8H3k3ntY+ZarrLLOdOV7zXd9ycZDzJ+NTUVK8mkiRJOo0cI0paKiwSSlL/fhf4TlVNVdX/B/w18C+B5e3VEoBVwLG2PwlcDNDOvwc40R2f0We2+PfmyPEWVbWjqsaqamxkZORU/lZJkiT1xzGipCXBIqEk9e8FYHWSd7U5YNYAzwFfBT7a2mwEHmr7+9ox7fxXqqpa/Ja2st1lwCjwdeAJYLStUnc2nYmr97U+s+WQJEnS4nKMKGlJsEgoSX2qqsfpTAz9DeAZOr+hO4BPAbcnmaAzN8zO1mUncH6L3w5sbdd5FthLZ/D4CLClqn7c5pP5OHAAOAzsbW2ZI4ckSZIWkWNESUvFsvmbSJKmVdU2YNuM8FE6q87NbPsD4OZZrnM3cHeP+H5gf494zxySJElafI4RJS0FPkkoSZIkSZIkDTmLhJIkSZIkSdKQs0goSZIkSZIkDTmLhJIkSZIkSdKQs0goSZIkSZIkDTmLhJIkSZIkSdKQs0goSZIkSZIkDTmLhJIkSZIkSdKQs0goSZIkSZIkDTmLhJIkSZIkSdKQs0goSZIkSZIkDTmLhJIkSZIkSdKQs0goSZIkSZIkDTmLhJIkSZIkSdKQs0goSZIkSZIkDTmLhJIkSZIkSdKQs0goSZKkBUvy3iRPdX2+n+STSc5LcjDJkbZd0donyX1JJpI8neTqrmttbO2PJNnYFb8myTOtz31J0uI9c0iSJGlwFgklSZK0YFX1fFVdVVVXAdcAbwBfArYCh6pqFDjUjgFuBEbbZzOwHToFP2AbcB1wLbCtq+i3vbWd7reuxWfLIUmSpAFZJJQkSdKpWgN8u6r+AVgP7G7x3cBNbX89sKc6HgOWJ7kIuAE4WFUnquokcBBY186dW1WPVlUBe2Zcq1cOSZIkDcgioSRJkk7VLcAX2v6FVfUSQNte0OIrgRe7+ky22FzxyR7xuXJIkiRpQH0VCZMsT/Jgkr9PcjjJbznfjCRJkpKcDXwE+Kv5mvaI1QDxfr/X5iTjScanpqb67SZJkjS0+n2S8M+BR6rqN4D3A4dxvhlJkiR1xn7fqKqX2/HL7VVh2vZ4i08CF3f1WwUcmye+qkd8rhw/UVU7qmqsqsZGRkZO4c+TJEkaDvMWCZOcC/w2sBOgqn5UVa/ifDOSJEmCW/npq8YA+4DpN0Y2Ag91xTe0t05WA6+1V4UPAGuTrGg3kNcCB9q515Osbm+ZbJhxrV45JEmSNKBlfbT5NWAK+Isk7weeBD7BjLlgkvzc55vpyvEWSTbTeRKRSy65pI8/SZIkSacqybuA64F/3RW+B9ibZBPwAnBzi+8HPgxM0FkJ+WMAVXUiyV3AE63dnVV1ou3fBtwPnAM83D5z5ZAkSdKA+ikSLgOuBv64qh5P8ufM/drvL3S+Gei8TgLsABgbG1tQX0mSJA2mqt4Azp8Re4XOascz2xawZZbr7AJ29YiPA1f2iPfMIUmSpMH1MyfhJDBZVY+34wfpFA3fFvPNSJIkSZIkSTo18xYJq+ofgReTvLeF1gDP4XwzkiRJkiRJ0pLQz+vGAH8M/GWSs4GjdOaQ+SWcb0aSJEmSJEk64/VVJKyqp4CxHqecb0aSJEmSJEk6w/UzJ6EkSZIkSZKkJcwioST1Kcl7kzzV9fl+kk8mOS/JwSRH2nZFa58k9yWZSPJ0kqu7rrWxtT+SZGNX/Jokz7Q+97W5WpkthyRJkhaXY0RJS4VFQknqU1U9X1VXVdVVwDV05l39ErAVOFRVo8ChdgxwIzDaPpuB7dAZzAHbgOuAa4FtXQO67a3tdL91LT5bDkmSJC0ix4iSlgqLhJI0mDXAt6vqH4D1wO4W3w3c1PbXA3uq4zFgeZKLgBuAg1V1oqpOAgeBde3cuVX1aJvfdc+Ma/XKIUmSpLcPx4iSzlgWCSVpMLcAX2j7F1bVSwBte0GLrwRe7Ooz2WJzxSd7xOfKIUmSpLcPx4iSzlgWCSVpgZKcDXwE+Kv5mvaI1QDxhXy3zUnGk4xPTU0tpKskSZJOgWNESWc6i4SStHA3At+oqpfb8cvtNRDa9niLTwIXd/VbBRybJ76qR3yuHG9RVTuqaqyqxkZGRgb88yRJkjQAx4iSzmgWCSVp4W7lp6+RAOwDplef2wg81BXf0FawWw281l4DOQCsTbKiTUa9FjjQzr2eZHVbsW7DjGv1yiFJkqS3B8eIks5oyxb7C0jSmSTJu4DrgX/dFb4H2JtkE/ACcHOL7wc+DEzQWeXuYwBVdSLJXcATrd2dVXWi7d8G3A+cAzzcPnPlkCRJ0iJzjChpKbBIKEkLUFVvAOfPiL1CZyW7mW0L2DLLdXYBu3rEx4Ere8R75pAkSdLic4woaSnwdWNJkiRJkiRpyFkklCRJkiRJkoacRUJJkiRJkiRpyFkklCRJkiRJkoacRUJJkiRJkiRpyFkklCRJkiRJkoacRUJJkiRJkiRpyFkklCRJkiRJkoacRUJJkiRJkiRpyFkklCRJkiRJkoacRUJJkiRJkiRpyFkklCRJkiRJkoacRUJJkiRJkiRpyFkklCRJkiRJkoacRUJJkiRJkiRpyFkklCRJkiRJkoacRUJJkiRJkiRpyFkklCRJkiRJkoacRUJJkiQNJMnyJA8m+fskh5P8VpLzkhxMcqRtV7S2SXJfkokkTye5uus6G1v7I0k2dsWvSfJM63NfkrR4zxySJEkanEVCSZIkDerPgUeq6jeA9wOHga3AoaoaBQ61Y4AbgdH22Qxsh07BD9gGXAdcC2zrKvptb22n+61r8dlySJIkaUAWCSVJkrRgSc4FfhvYCVBVP6qqV4H1wO7WbDdwU9tfD+ypjseA5UkuAm4ADlbViao6CRwE1rVz51bVo1VVwJ4Z1+qVQ5IkSQOySChJkqRB/BowBfxFkm8m+XySdwMXVtVLAG17QWu/Enixq/9ki80Vn+wRZ44ckiRJGpBFQkmSJA1iGXA1sL2qPgD8H+Z+7Tc9YjVAvC9JNicZTzI+NTXVbzdJkqShZZFQkiRJg5gEJqvq8Xb8IJ2i4cvtVWHa9nhX+4u7+q8Cjs0TX9Ujzhw5fqKqdlTVWFWNjYyMDPxHSpIkDQuLhJIkSVqwqvpH4MUk722hNcBzwD5geoXijcBDbX8fsKGtcrwaeK29KnwAWJtkRVuwZC1woJ17PcnqtqrxhhnX6pVDkiRJA1q22F9AkiRJZ6w/Bv4yydnAUeBjdG5C702yCXgBuLm13Q98GJgA3mhtqaoTSe4Cnmjt7qyqE23/NuB+4Bzg4fYBuGeWHJIkSRqQRUJJkiQNpKqeAsZ6nFrTo20BW2a5zi5gV4/4OHBlj/grvXJIkiRpcL5uLEmSJEmSJA25voqESb6b5JkkTyUZb7HzkhxMcqRtV7R4ktyXZCLJ00mu7rrOxtb+SJKNXfFr2vUnWt/MlUOSJEmSJEnS6bOQJwl/p6quqqrpV0q2AoeqahQ41I4BbgRG22czsB06BT9gG3AdcC2wravot721ne63bp4ckrQokixP8mCSv09yOMlvedNEkiRJknSmO5XXjdcDu9v+buCmrvie6ngMWJ7kIuAG4GBVnaiqk8BBYF07d25VPdrmqtkz41q9ckjSYvlz4JGq+g3g/cBhvGkiSZI01LyRLGkp6LdIWMDfJHkyyeYWu7CqXgJo2wtafCXwYlffyRabKz7ZIz5XjrdIsjnJeJLxqampPv8kSVqYJOcCvw3sBKiqH1XVq3jTRJIkadh5I1nSGa/fIuEHq+pqOj9mW5L89hxt0yNWA8T7VlU7qmqsqsZGRkYW0lWSFuLXgCngL5J8M8nnk7ybt9FNE0mSJP1ieSNZ0lLRV5Gwqo617XHgS3Tuarzcfqxo2+Ot+SRwcVf3VcCxeeKresSZI4ckLYZlwNXA9qr6APB/mPtu7S/8polPVkuSJP3Cve1vJDtGlNSPeYuESd6d5Fem94G1wLeAfcD0HAkbgYfa/j5gQ5tnYTXwWvuxOgCsTbKiPTK9FjjQzr2eZHWbV2HDjGv1yiFJi2ESmKyqx9vxg3SKhm+bmyY+WS1JkvQL97a/kewYUVI/+nmS8ELgb5P8HfB14H9U1SPAPcD1SY4A17djgP3AUWAC+BzwRwBVdQK4C3iife5sMYDbgM+3Pt8GHm7x2XJI0i9cVf0j8GKS97bQGuA5vGkiSZI0zN72N5IlqR/L5mtQVUfpTLw6M/4KnX+QZ8YL2DLLtXYBu3rEx4Er+80hSYvoj4G/THI2nRsiH6Nzw2Vvkk3AC8DNre1+4MN0boC80dpSVSeSTN80gZ+9aXI/cA6dGybdN0165ZAkSdIiqqp/TPJikvdW1fP89Ebyc3Ru7t7Dz95I/niSB+gsUvJaVb2U5ADw/3QtVrIWuKONHV9vN50fp3Mj+f/tulavHJK0YPMWCSVJP1VVTwFjPU5500SSJGl4eSNZ0hnPIqEkSZIkSafAG8mSloK+VjeWJEmSJEmStHRZJJQkSZIkSZKGnEVCSZIkSZIkachZJJQkSZIkSZKGnEVCSZIkSZIkachZJJQkSZIkSZKGnEVCSZIkSZIkachZJJQkSZIkSZKGnEVCSZIkSZIkachZJJQkSZIkSZKGnEVCSZIkSZIkachZJJQkSZIkSZKGnEVCSZIkSZIkachZJJQkSZIkSZKGnEVCSZIkSZIkachZJJQkSZIkSZKGnEVCSZIkSZIkachZJJQkSZIkSZKGnEVCSZIkSZIkachZJJQkSdJAknw3yTNJnkoy3mLnJTmY5EjbrmjxJLkvyUSSp5Nc3XWdja39kSQbu+LXtOtPtL6ZK4ckSZIGZ5FQkiRJp+J3quqqqhprx1uBQ1U1ChxqxwA3AqPtsxnYDp2CH7ANuA64FtjWVfTb3tpO91s3Tw5JkiQNyCKhJEmSTqf1wO62vxu4qSu+pzoeA5YnuQi4AThYVSeq6iRwEFjXzp1bVY9WVQF7ZlyrVw5JkiQNyCKhJEmSBlXA3yR5MsnmFruwql4CaNsLWnwl8GJX38kWmys+2SM+Vw5JkiQNaNlifwFJkiSdsT5YVceSXAAcTPL3c7RNj1gNEO9LK1puBrjkkkv67SZJkjS0fJJQkiRJA6mqY217HPgSnTkFX26vCtO2x1vzSeDiru6rgGPzxFf1iDNHju7vtqOqxqpqbGRk5FT+TEmSpKFgkVCSJEkLluTdSX5leh9YC3wL2AdMr1C8EXio7e8DNrRVjlcDr7VXhQ8Aa5OsaAuWrAUOtHOvJ1ndVjXeMONavXJIkiRpQL5uLEmSpEFcCHypU79jGfDfquqRJE8Ae5NsAl4Abm7t9wMfBiaAN4CPAVTViSR3AU+0dndW1Ym2fxtwP3AO8HD7ANwzSw5JkiQNyCKhJEmSFqyqjgLv7xF/BVjTI17AllmutQvY1SM+DlzZbw5JkiQNzteNJUmSJEmSpCFnkVCSFiDJd5M8k+SpJOMtdl6Sg0mOtO2KFk+S+5JMJHk6ydVd19nY2h9JsrErfk27/kTrm7lySJIkafE5RpS0FFgklKSF+52quqqqxtrxVuBQVY0Ch9oxwI3AaPtsBrZDZzAHbAOuo7MS6LauAd321na637p5ckiSJOntwTGipDOaRUJJOnXrgd1tfzdwU1d8T3U8BixPchFwA3Cwqk5U1UngILCunTu3qh5tc3ftmXGtXjkkSZL09uQYUdIZxSKhJC1MAX+T5Mkkm1vswqp6CaBtL2jxlcCLXX0nW2yu+GSP+Fw5JEmStPgcI0o647m6sSQtzAer6liSC4CDSf5+jrbpEasB4n1rg9LNAJdccslCukqSJGlwjhElnfF8klCSFqCqjrXtceBLdOaLebm9BkLbHm/NJ4GLu7qvAo7NE1/VI84cOWZ+vx1VNVZVYyMjI4P+mZIkSVoAx4iSloK+i4RJzkryzSRfbseXJXm8raL0xSRnt/g72/FEO39p1zXuaPHnk9zQFV/XYhNJtnbFe+aQpMWQ5N1JfmV6H1gLfAvYB0yvPrcReKjt7wM2tBXsVgOvtddADgBrk6xok1GvBQ60c68nWd1WrNsw41q9ckiSJGkROUaUtFQs5EnCTwCHu44/DdzbVlE6CWxq8U3Ayaq6HLi3tSPJFcAtwPvorMT02VZ4PAv4DJ0Vnq4Abm1t58ohSYvhQuBvk/wd8HXgf1TVI8A9wPVJjgDXt2OA/cBRYAL4HPBHAFV1ArgLeKJ97mwxgNuAz7c+3wYebvHZckiSJGlxOUaUtCT0NSdhklXA7wF3A7e3uxcfAv6gNdkN/CmdZdnXt32AB4H/0tqvBx6oqh8C30kyQecRbICJqjracj0ArE9yeI4ckvQL136n3t8j/gqwpke8gC2zXGsXsKtHfBy4st8ckiRJWlyOESUtFf0+SfhnwJ8A/9SOzwderao323H36ko/WZGpnX+ttV/oCk5z5ZAkSZIkSZJ0msxbJEzy+8DxqnqyO9yjac1z7ue2glOSzUnGk4xPTU31aiJJkiRJkiRpFv08SfhB4CNJvgs8QOcV4D8DlieZfl25e3Wln6zI1M6/BzjBwldw+t4cOd7ClZokSZIkSZKkwc1bJKyqO6pqVVVdSmfhka9U1R8CXwU+2prNXKlpenWlj7b21eK3tNWPLwNG6Uzq+gQw2lYyPrvl2Nf6zJZDkiRJkiRJ0mmykNWNZ/oUnUVMJujMH7izxXcC57f47cBWgKp6FtgLPAc8Amypqh+3OQc/Tme598PA3tZ2rhySJEmSJEmSTpO+VjeeVlVfA77W9o/y09WJu9v8ALh5lv5301kheWZ8P51l4GfGe+aQJEmSJEmSdPqcypOEkiRJkiRJkpYAi4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSpIEkOSvJN5N8uR1fluTxJEeSfDHJ2S3+znY80c5f2nWNO1r8+SQ3dMXXtdhEkq1d8Z45JEmSdGosEkqSJGlQnwAOdx1/Gri3qkaBk8CmFt8EnKyqy4F7WzuSXAHcArwPWAd8thUezwI+A9wIXAHc2trOlUOSJEmnwCKhJEmSFizJKuD3gM+34wAfAh5sTXYDN7X99e2Ydn5Na78eeKCqflhV3wEmgGvbZ6KqjlbVj4AHgPXz5JAkSdIpsEgoSZKkQfwZ8CfAP7Xj84FXq+rNdjwJrGz7K4EXAdr511r7n8Rn9JktPlcOSZIknQKLhJIkSVqQJL8PHK+qJ7vDPZrWPOdOV7zXd9ycZDzJ+NTUVK8mkiRJ6mKRUJIkSQv1QeAjSb5L51XgD9F5snB5kmWtzSrgWNufBC4GaOffA5zojs/oM1v8e3PkeIuq2lFVY1U1NjIyMvhfKkmSNCQsEkqSJGlBquqOqlpVVZfSWXjkK1X1h8BXgY+2ZhuBh9r+vnZMO/+VqqoWv6WtfnwZMAp8HXgCGG0rGZ/dcuxrfWbLIUmSpFNgkVCSJEmny6eA25NM0Jk/cGeL7wTOb/Hbga0AVfUssBd4DngE2FJVP25zDn4cOEBn9eS9re1cOSRJknQKLBJK0gIlOSvJN5N8uR1fluTxJEeSfLE99UJ7MuaLSSba+Uu7rnFHiz+f5Iau+LoWm0iytSveM4ckLbaq+lpV/X7bP1pV11bV5VV1c1X9sMV/0I4vb+ePdvW/u6p+vareW1UPd8X3V9X/1c7d3RXvmUOSFptjRElnOouEkrRwn6DzZMu0TwP3VtUocBLY1OKbgJNVdTlwb2tHkivovDr3PmAd8Nk2qDwL+AxwI3AFcGtrO1cOSZIkvT04RpR0RrNIKEkLkGQV8HvA59tx6EzY/2Brshu4qe2vb8e082ta+/XAA1X1w6r6DjABXNs+E+0pmR/RWQxg/Tw5JEmStMgcI0paCiwSStLC/BnwJ8A/tePzgVfb/FnQWZFzZdtfCbwI0M6/1tr/JD6jz2zxuXK8RZLNScaTjE9NTQ36N0qSJGlhHCNKOuNZJJSkPiX5feB4VT3ZHe7RtOY5d7riPxus2lFVY1U1NjIy0quJJEmSTiPHiJKWimWL/QUk6QzyQeAjST4M/DJwLp27xsuTLGt3cVcBx1r7SeBiYDLJMuA9wImu+LTuPr3i35sjhyRJkhaXY0RJS4JPEkpSn6rqjqpaVVWX0plU+itV9YfAV4GPtmYbgYfa/r52TDv/laqqFr+lrWx3GTAKfB14Ahhtq9Sd3XLsa31myyFJkqRF5BhR0lJhkVCSTt2ngNuTTNCZG2Zni+8Ezm/x24GtAFX1LLAXeA54BNhSVT9ud4A/DhygszLe3tZ2rhySJEl6e3KMKOmM4uvGkjSAqvoa8LW2f5TOqnMz2/wAuHmW/ncDd/eI7wf294j3zCFJkqS3D8eIks5kPkkoSZIkSZIkDTmLhJIkSZIkSdKQs0goSZIkSZIkDTmLhJIkSZIkSdIHsTMtAAAgAElEQVSQs0goSZIkSZIkDbl5i4RJfjnJ15P8XZJnk/yHFr8syeNJjiT5YpKzW/yd7Xiinb+061p3tPjzSW7oiq9rsYkkW7viPXNIkiRJkiRJOn36eZLwh8CHqur9wFXAuiSrgU8D91bVKHAS2NTabwJOVtXlwL2tHUmuAG4B3gesAz6b5KwkZwGfAW4ErgBubW2ZI4ckSZIkSZKk02TeImF1/O92+I72KeBDwIMtvhu4qe2vb8e082uSpMUfqKofVtV3gAng2vaZqKqjVfUj4AFgfeszWw5JkiRJkiRJp0lfcxK2J/6eAo4DB4FvA69W1ZutySSwsu2vBF4EaOdfA87vjs/oM1v8/DlySJIkSZIkSTpN+ioSVtWPq+oqYBWdJ/9+s1ezts0s505X/Gck2ZxkPMn41NRUryaSJEmSJEmSZrGg1Y2r6lXga8BqYHmSZe3UKuBY258ELgZo598DnOiOz+gzW/x7c+SY+b12VNVYVY2NjIws5E+SJEmSJEmShl4/qxuPJFne9s8Bfhc4DHwV+GhrthF4qO3va8e081+pqmrxW9rqx5cBo8DXgSeA0baS8dl0FjfZ1/rMlkOSJEmSJEnSabJs/iZcBOxuqxD/ErC3qr6c5DnggST/EfgmsLO13wn81yQTdJ4gvAWgqp5Nshd4DngT2FJVPwZI8nHgAHAWsKuqnm3X+tQsOSRJkiRJkiSdJvMWCavqaeADPeJH6cxPODP+A+DmWa51N3B3j/h+YH+/OSRJkiRJkiSdPguak1CSJEmSJEnS0mORUJIkSZIkSRpyFgklSZIkSZKkIWeRUJIkSZIkSRpyFgklSZIkSZKkIWeRUJIkSZIkSRpyFgklSZIkSZKkIWeRUJIkSZIkSRpyFgklSZIkSZKkIWeRUJIkSQuW5JeTfD3J3yV5Nsl/aPHLkjye5EiSLyY5u8Xf2Y4n2vlLu651R4s/n+SGrvi6FptIsrUr3jOHJEmSBmeRUJIkSYP4IfChqno/cBWwLslq4NPAvVU1CpwENrX2m4CTVXU5cG9rR5IrgFuA9wHrgM8mOSvJWcBngBuBK4BbW1vmyCFJkqQBWSSUJEnSglXH/26H72ifAj4EPNjiu4Gb2v76dkw7vyZJWvyBqvphVX0HmACubZ+JqjpaVT8CHgDWtz6z5ZAkSdKALBJKkiRpIO2Jv6eA48BB4NvAq1X1ZmsyCaxs+yuBFwHa+deA87vjM/rMFj9/jhySJEkakEVCSZIkDaSqflxVVwGr6Dz595u9mrVtZjl3uuJvkWRzkvEk41NTU72+viRJkrpYJJQkSdIpqapXga8Bq4HlSZa1U6uAY21/ErgYoJ1/D3CiOz6jz2zx782Ro/s77aiqsaoaGxkZOdU/UZIkacmzSChJfXIlT0n6qSQjSZa3/XOA3wUOA18FPtqabQQeavv72jHt/Feqqlr8lvabeRkwCnwdeAIYbb9/Z9NZ3GRf6zNbDkn6hXOMKGmpsEgoSf1zJU9J+qmLgK8meZpOQe9gVX0Z+BRwe5IJOvMH7mztdwLnt/jtwFaAqnoW2As8BzwCbGmvMb8JfBw4QKf4uLe1ZY4ckrQYHCNKWhKWzd9EkgSdlTyB2Vby/IMW3w38KbCdzoqdf9riDwL/ZeZKnsB32j+517Z2E1V1FCDJ9Eqeh+fIIUmLoqqeBj7QI36Un/6mdcd/ANw8y7XuBu7uEd8P7O83hyQtBseIkpYKnySUpAVwJU9JkiTN5BhR0lJgkVCSFuDtvJInuJqnJEnSYnCMKGkpsEgoSQN4O67k2b6Xq3lKkiQtEseIks5kFgklqU+u5ClJkqSZHCNKWipcuESS+ncRsLutMPdLdFba/HKS54AHkvxH4Ju8dSXP/9omnT5BZ0BHVT2bZHolzzdpK3kCJJleyfMsYNeMlTx75ZAkSdLicowoaUmwSChJfXIlT0mSJM3kGFHSUuHrxpIkSZIkSdKQs0goSZIkSZIkDTmLhJIkSZIkSdKQs0goSZIkSZIkDTmLhJIkSZIkSdKQs0goSZIkSZIkDTmLhJIkSZIkSdKQs0goSZIkSZIkDTmLhJIkSZIkSdKQs0goSZIkSZIkDTmLhJIkSZIkSdKQs0goSZIkSZIkDTmLhJIkSZIkSdKQs0goSZIkSZIkDbl5i4RJLk7y1SSHkzyb5BMtfl6Sg0mOtO2KFk+S+5JMJHk6ydVd19rY2h9JsrErfk2SZ1qf+5JkrhySJEmSJEmSTp9+niR8E/h3VfWbwGpgS5IrgK3AoaoaBQ61Y4AbgdH22Qxsh07BD9gGXAdcC2zrKvptb22n+61r8dlySJIkSZIkSTpN5i0SVtVLVfWNtv86cBhYCawHdrdmu4Gb2v56YE91PAYsT3IRcANwsKpOVNVJ4CCwrp07t6oeraoC9sy4Vq8ckiRJkiRJkk6TBc1JmORS4APA48CFVfUSdAqJwAWt2Urgxa5uky02V3yyR5w5csz8XpuTjCcZn5qaWsifJEmSJEmSJA29vouESf4Z8N+BT1bV9+dq2iNWA8T7VlU7qmqsqsZGRkYW0lWSJEmSJEkaen0VCZO8g06B8C+r6q9b+OX2qjBte7zFJ4GLu7qvAo7NE1/VIz5XDkmSJEmSJEmnST+rGwfYCRyuqv/cdWofML1C8Ubgoa74hrbK8Wrgtfaq8AFgbZIVbcGStcCBdu71JKtbrg0zrtUrhyRJkiRJkqTTZFkfbT4I/CvgmSRPtdi/B+4B9ibZBLwA3NzO7Qc+DEwAbwAfA6iqE0nuAp5o7e6sqhNt/zbgfuAc4OH2YY4ckiRJkiRJkk6TeYuEVfW39J43EGBNj/YFbJnlWruAXT3i48CVPeKv9MohSZIkSZIk6fRZ0OrGkiRJkiRJkpYei4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJElasCQXJ/lqksNJnk3yiRY/L8nBJEfadkWLJ8l9SSaSPJ3k6q5rbWztjyTZ2BW/Jskzrc99STJXDkmSJA3OIqEkSZIG8Sbw76rqN4HVwJYkVwBbgUNVNQocascANwKj7bMZ2A6dgh+wDbgOuBbY1lX0297aTvdb1+Kz5ZAkSdKALBJKkiRpwarqpar6Rtt/HTgMrATWA7tbs93ATW1/PbCnOh4Dlie5CLgBOFhVJ6rqJHAQWNfOnVtVj1ZVAXtmXKtXDkmSJA3IIqEkSZJOSZJLgQ8AjwMXVtVL0CkkAhe0ZiuBF7u6TbbYXPHJHnHmyCFJkqQBWSSUpD45/5Yk/awk/wz478Anq+r7czXtEasB4v1+r81JxpOMT01N9dtNkhbMMaKkpcIioST1z/m3JKlLknfQKRD+ZVX9dQu/3F4Vpm2Pt/gkcHFX91XAsXniq3rE58rxE1W1o6rGqmpsZGRk8D9SkubnGFHSkmCRUJL65PxbkvRT7SmWncDhqvrPXaf2AdNPv2wEHuqKb2hP0KwGXmuvCh8A1iZZ0f4ZXgscaOdeT7K65dow41q9ckjSL5xjRElLxbLF/gKSdCaaa/6tJD/3+be6csz8Xpvp3GXmkksuGfCvk6S+fBD4V8AzSZ5qsX8P3APsTbIJeAG4uZ3bD3wYmADeAD4GUFUnktwFPNHa3VlVJ9r+bcD9wDnAw+3DHDkkaVE5RpR0JrNIKEkLNHP+rTYlTM+mPWI/t/m3oPN6HbADYGxsbEF9JWkhqupv6f27BbCmR/sCtsxyrV3Arh7xceDKHvFXeuWQpMXkGFHSmc7XjSVpAd7O829JkiRpcThGlLQUWCSUpD45/5YkSZJmcowoaanwdWNJ6p/zb0mSJGkmx4iSlgSLhJLUJ+ffkiRJ0kyOESUtFb5uLEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA05i4SSJEmSJEnSkLNIKEmSJEmSJA25eYuESXYlOZ7kW12x85IcTHKkbVe0eJLcl2QiydNJru7qs7G1P5JkY1f8miTPtD73JclcOSRJkiRJkiSdXv08SXg/sG5GbCtwqKpGgUPtGOBGYLR9NgPboVPwA7YB1wHXAtu6in7bW9vpfuvmySFJkiRJkiTpNJq3SFhV/xM4MSO8Htjd9ncDN3XF91THY8DyJBcBNwAHq+pEVZ0EDgLr2rlzq+rRqipgz4xr9cohSZIkSZIk6TQadE7CC6vqJYC2vaDFVwIvdrWbbLG54pM94nPlkCRJkiRJknQane6FS9IjVgPEF5Y02ZxkPMn41NTUQrtLkiRJkiRJQ23QIuHL7VVh2vZ4i08CF3e1WwUcmye+qkd8rhw/o6p2VNVYVY2NjIwM+CdJkiRJkiRJw2nQIuE+YHqF4o3AQ13xDW2V49XAa+1V4QPA2iQr2oIla4ED7dzrSVa3VY03zLhWrxySJElaZEl2JTme5FtdsfOSHExypG1XtHiS3JdkIsnTSa7u6rOxtT+SZGNX/Jokz7Q+97Wx4qw5JEmSdGrmLRIm+QLwKPDeJJNJNgH3ANcnOQJc344B9gNHgQngc8AfAVTVCeAu4In2ubPFAG4DPt/6fBt4uMVnyyFJkqTFdz+wbkZsK3CoqkaBQ+0Y4EZgtH02A9uhU/ADtgHXAdcC27qKfttb2+l+6+bJIUmSpFPQz+rGt1bVRVX1jqpaVVU7q+qVqlpTVaNte6K1raraUlW/XlX/oqrGu66zq6oub5+/6IqPV9WVrc/H2yrHzJZDkhaTT85IUkdV/U9g5vhsPbC77e8GbuqK72ljxceA5W06mRuAg1V1oqpOAgeBde3cuVX1aBsb7plxrV45JGlROD6UtFSc7oVLJGmpux+fnJGk2VzYppOhbS9o8ZXAi13tJltsrvhkj/hcOSRpsdyP40NJS4BFQklaAJ+ckaSBpEesBoj3nzDZnGQ8yfjU1NRCukrSgjg+lLRUWCSUpFPnkzOS1PFy+4eWtj3e4pPAxV3tVgHH5omv6hGfK8dbVNWOqhqrqrGRkZFT+qMkaQCODyWdcSwSStLPj0/OSBo2+4DpebQ2Ag91xTe0ubhWA6+1f2gPAGuTrGiv1a0FDrRzrydZ3ebe2jDjWr1ySNKZ4Bc+PgTHiJL6Y5FQkk6dT85IGjpJvgA8Crw3yWSSTcA9wPVJjgDXt2OA/cBRYAL4HPBHAG1huruAJ9rnzq7F6m4DPt/6fBt4uMVnyyFJbydvm/EhOEaU1B+LhJJ06nxyRtLQqapbq+qiqnpHVa2qqp1V9UpVramq0bY90dpWVW2pql+vqn9RVeNd19lVVZe3z190xcer6srW5+NtLi5myyFJbzOODyWdcZYt9heQpDNJe3Lm/wZ+NckknVXo7gH2tqdoXgBubs33Ax+m8xTMG8DHoPPkTJLpJ2fgZ5+cuR84h85TM91PzvTKIUmSpEXk+FDSUmGRUPr/2bv/aMnK8k703+eCGPNDQW29DOBgYscb4kwUeymZTHIdCQhMRsxcXQuTFXoZ7uKO4p0kzqwRb9YaMsmYpTOZmDFjSFCJkKUiMXHkOijpizqZH4q2iiAS0i0y0sJAK0hMjCbE9/5Rb9PVhzrnVHWfOlV99uezVq3a9dTe+33rx3nOfp/9o2AGrbWXr/LUmRPmbUkuWWU9Vya5ckJ8d5JnTYh/dVIbAAAslu1DYKtwujEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAzc0hcJq+qcqrqjqvZW1aWL7g/AIsmJACPyIcCIfAhslKUuElbVMUnekuTcJKcleXlVnbbYXgEshpwIMCIfAozIh8BGWuoiYZLnJdnbWruztfZXSa5Jcv6C+wSwKHIiwIh8CDAiHwIb5thFd2AdJyW5e+zxviTPX1BfABZtU3Piu2760rrz/NTznzav5gHWYhsRYGTT8+HKbUTbg7B1LHuRsCbE2qNmqro4ycX94Z9X1R1Trv/JSb4yHvjpmbq34R7VnwXTn9UtU1+S4fTnb89hnUeTdXPiEeTDA2b67OaUMxf9fV50+/qgD9O0Lx8+2kbmw0Pe9wVvH87bor/jm2UorzMZ5msdck7c9DHzSpuYI5ftu71M/VmmviTL1Z9l6ksy//4cUT5c9iLhviSnjD0+Ock9K2dqrV2R5IpZV15Vu1trOw6/extLf9a2TP1Zpr4k+jMg6+bEw82HByzDZ7foPiy6fX3Qh2Vqf4nNNR8O6X0fymsdyutMvNYBGsyYeZn6kixXf5apL8ly9WeZ+pIsX39WWvZrEn4yyfaqenpVHZfkgiTXLbhPAIsiJwKMyIcAI/IhsGGW+kjC1trDVfXqJDckOSbJla212xbcLYCFkBMBRuRDgBH5ENhIS10kTJLW2vVJrp/T6g/7lLw50Z+1LVN/lqkvif4MxpxzYrIcn92i+7Do9hN9OEAfFt/+0hrYNuI8DeW1DuV1Jl7r4AwoHy5TX5Ll6s8y9SVZrv4sU1+S5evPIaq1R13TFAAAAAAYkGW/JiEAAAAAMGeDLRJW1TlVdUdV7a2qSzdwvadU1Ueq6vaquq2qfq7Hf6mqvlxVN/fbeWPLvK73446qetF6fewXpb2pqvZU1Xv6BWrX6tNdVXVrb3d3jz2xqnb1deyqqhN6vKrqzb3NW6rq9LH17Ozz76mqnWPx5/b17+3L1hp9eebYe3BzVf1ZVf38Zr4/VXVlVd1fVZ8bi839/ZjUxip9+bdV9Se9vfdV1fE9fmpV/eXYe/Tbh9PmWq9rlf7M/bOpqsf2x3v786eu9h1iPlb7zObc5sz5ck79mDpHzqn9mfPiBrW7Iblwg9ufOf/NoQ8z57w59OE9Y+3fVVU39/hc3gcOWkQu3Ciz5LK1/qZrA7b35vDalmbbbQGvc0tuh9Xq2wBb7nM9mm1kTlymv+Ml+/79r1X1iar6bO/Lv+rzzfz3WhuXE46pqs9U1QeWoC8L+d+2yvfm+Kp6b422VW+vqh9eVF8yT621wd0yuqDrF5J8b5Ljknw2yWkbtO4Tk5zep78nyZ8mOS3JLyX55xPmP623/9gkT+/9OmatPia5NskFffq3k7xynT7dleTJK2L/JsmlffrSJG/s0+cl+WCSSnJGkpt6/IlJ7uz3J/TpE/pzn0jyw32ZDyY5d4bP4X8m+dub+f4k+bEkpyf53Ga+H5PaWKUvZyc5tk+/cawvp47Pt+I1Td3mOq9rUn/m/tkkeVWS3+7TFyR5z6LzxJBua31mc253pnw5x37clSlz5CZ9FmvmxQ1s64hz4Rzanzn/zaEPM+W8efRhxfP/Lsm/nOf74PbIe72QXLiB/Z86l632N505bO9t0Gtbmm23BbzOmXLSWt/jLNF2WFbfBthyn+vRelvru7SB3+9FjcGW6vuX5Lv748ckuam3MdPfazY2J7wmybuSfGCd+TajL3dlAf/bVvmcrkryf/bYcUmOX1Rf5vq3v+jks4hbf+NvGHv8uiSvm1Nb709yVlb/B39I2xn9KtUPr9bH/oX5Sg4Oog6Zb5U+TPrDuiPJiX36xCR39OnfSfLylfMleXmS3xmL/06PnZjkT8bih8y3Tr/OTvLf+vSmvj9ZMdDajPdjjTYO6cuKfv5kkneuNd9htjnxda3y3sz9szmwbJ8+ts9X8/ibdJv4Pdu0nLhOP9bMl3Ns965MmSM3oS/r5sUNbu+IcuFGt7/iuXXz35zeg5ly3jz6MBavJHcn2T7v98FteXLhEfR/6ly22t905rC9t4Gv74jy1eG8tkX8LzjSnLTa9zhLvh2Wg9sAW/JzPRpv88iJy/p3vCzfvyTfmeTTSZ4/69/rys8nh5kTkpyc5MYkL0zygdXm24y+9Om7soD/bRPa2JPki1mRGxf9nZnHbainG5+U0Ub3Aft6bEP1w22fk9HegCR5dT/U9MqxQ0RX68tq8Scl+Vpr7eEZ+t6S/FFVfaqqLu6xp7bW7k2Sfv+Uw+zPSX16ZXwaFyR599jjRb0/yea8H6u1sZafzWgvwgFP74d+/+eq+tGxPs7a5qx/A/P+bB5Zpj//UJ+fzbEpOXEtU+bLeZklR87bNHlxnjYqZ2yEafLfvMyS8+bpR5Pc11rbMxbbzPdhaBaeC4/Qsm7vzcuybrvNw5beDluxDTCkz3XZbUZOXPjnvQzfvxqd3ntzkvuT7MroaLtZ/143Kif8RpJ/keTbPX44uWMj89Oi/retbOOpSfYn+d2+Hfa2qvquBfVlrjlrqEXCSddQaRvaQNV3J/mDJD/fWvuzJJcn+b4kz05yb0anD63Vl1nja/mR1trpSc5NcklV/dhaXd+E/qRfY+DFSX6/hxb5/qzZ1UW1X1W/mOThJO/soXuTPK219pz0Q8Cr6vGH2eYsy2zGZzP3v0nWtND3f4Z8OS+z5Mi5mSEvLsKmfkdmyH/zMGvOm6eX59Ci8Wa+D0N0tP8vWrrtvQXZaq9tS2+HTdgGWHXWCbGj+XM9GizyPdysMelSfP9aa3/TWnt2RkfxPS/JD6yx/Eb1ZVL8u5Pc31r71FjscHLHRr5fy/S/7fQkl/ftsL/I6NTfRfVlboZaJNyX5JSxxycnuWejVl5Vj8ko2byztfaHSdJau6//8X87yVsz+uNfqy+rxb+S5PiqOnbavrfW7un39yd5X2/7vqo6sff3xIz2WhxOf/b16ZXx9Zyb5NOttft63xb2/nSb8X6s1saj9AuY/kSSn279uOLW2rdaa1/t05/KaA/T9x9mm1P/DWzSZ/PIMv35JyR5YFJ/mIu55sS1zJgv52LGHDlP0+bFeTrinHGkZsx/G+4wct5c9Fz4j5O8Z6xvm/Y+DNTCcuFGWNLtvXlaqm23ednK22GTtgEykM/1KLEZOXFhn/cyfv9aa19L8tGMrmE369/rRuSEbyd5cVXdleSajE45/o0F9eXA/7RF/W+b1Ma+1tqBs57em1HRcMvlrKEWCT+ZZHuNfkHnuIxO77puI1ZcVZXk7Ulub639+lj8xLHZfjLJgV91ui7JBTX6ZaCnJ9me0QUrJ/axD5g+kuSlffmdGV1DYbX+fFdVfc+B6Yyud/W53u7OCeu4LsmFNXJGkof6Ia03JDm7Rr/qc0Jfzw39ua9X1Rn9tV+4Vn/GHHJ0xKLenzGb8X6s1sYhquqcJK9N8uLW2jfG4tuq6pg+/b39vbjzMNtc7XVN6s9mfDbj/Xxpkg8fKA6wKeaWE9dyGPlyHn2YNUfO07R5cZ6OOGcciVnz30a339c/a86blx/P6No0j5x6spnvw0AtJBduhCXe3punpdl2m6etuh222jZABvK5HiU2Iycu5PNesu/fH1XV8UlSVY/L6P//7Zn973UjcsKvtdZObq2d2uf7cGvtpxfUl/cv+H/byjb+MMndVfXMHjszyecX1Jf55qw2xwseLvMto1+b+dOM9sL/4gau9+9ndFjoLUlu7rfzkvxeklt7/LqMXfA9yS/2ftyRsV+KW62PGf0a0CeS7M3otLTHrtGf783oV4M+m+S2A+vJ6Lz/GzO6AOeNSZ7Y45XkLb3NW5PsGFvXz/Y29yZ5xVh8R0Z/rF9I8h+StS90nNEFWb+a5AljsU17fzIahN+b5K8zqthftBnvx6Q2VunL3oyuU3Dg+3PgF6P+j/4ZfjajC9r+o8Npc63XtUp/5v7ZJPmO/nhvf/57F50jhnZb7TObc5sz58s59GGmHDnHfsyUFzeozQ3JhRvc/sz5bw59mDnnbXQfevwdSf7Jinnn8j64HfIeb3ou3KB+L9323ga/vqXZdlvA69yS22FZfRtgy32uR/Ntte/SBn6/FzUGW6bv399P8pnel88l+Zd9vpn/XrOB4+YkL8jBXzdeSF+ywP9tk9rI6LIPu/tn9R8z+nXiLZezDjQKAAAAAAzUUE83BgAAAAA6RUIAAAAAGDhFQgAAAAAYOEVCAAAAABg4RUIAAAAAGDhFQgAAAAAYOEVCjipVdWpVfa5P76iqN/fpF1TV3zvMdT6xqnZV1Z5+f8JG9hlgHuaUD19WVbdV1berasdG9hdgXuaUD/9tVf1JVd1SVe+rquM3ss8A8zKnnPhLVfXlqrq5387byD6zPBQJOWq11na31v5pf/iCJIeV8JJcmuTG1tr2JDf2xwBHjQ3Mh59L8o+T/PFG9Atgs21gPtyV5Fmttb+b5E+TvG4DugewqTYwJybJm1prz+6364+8dywjRUI2TVX9YlXdUVX/X1W9u6r+eVV99MDRKlX15Kq6q0+fWlX/pao+3W+PSmZ9T8gHqurUJP8kyS/0vRo/WlVfrKrH9PkeX1V3HXg8wflJrurTVyV5yYa+cIAVljUfttZub63dMaeXDfAoS5wP/6i19nB/+PEkJ2/4iwdYYVlzIsNx7KI7wDBU1XOTXJDkORl97z6d5FNrLHJ/krNaa9+squ1J3p1k4qlvrbW7quq3k/x5a+3XensfTfIPk/zH3u4ftNb+epW2ntpau7ev696qesqsrw9gWkueDwE2zVGUD382yXumelEAh+koyImvrqoLk+xO8s9aaw/O8vo4OsohsJMAACAASURBVDiSkM3yo0ne11r7Rmvtz5Jct878j0ny1qq6NcnvJzltxvbeluQVffoVSX53xuUB5kU+BBhZ+nxYVb+Y5OEk75yxLYBZLXNOvDzJ9yV5dpJ7k/y7GdviKOFIQjZTmxB7OAeL1d8xFv+FJPcl+aH+/Ddnaqi1/9YPv/7fkxzTWvvcGrPfV1Un9qMIT8xojwzAPC1rPgTYbEubD6tqZ5KfSHJma21SPwE22lLmxNbafQemq+qtST4wS1scPRxJyGb54yQ/WVWPq6rvSfKPevyuJM/t0y8dm/8JSe5trX07yc8kOWad9X89yfesiF2d0SHX6+0lvi7Jzj69M8n715kf4Egscz4E2ExLmw+r6pwkr03y4tbaN9ZpB2AjLHNOPHHs4U9m9GN3bEGKhGyK1tqnM7qWy81J/iDJf+lP/VqSV1bVf0/y5LFFfivJzqr6eJLvT/IX6zTx/2aUUG+uqh/tsXcmOSGjpLeWNyQ5q6r2JDmrPwaYi2XOh1X1k1W1L8kPJ/lPVXXD9K8MYDbLnA+T/IeMBtO7+vK/PeXLAjgsS54T/01V3VpVtyT5BxkdxcgWVI6cZxGq6pcydtHUObXx0iTnt9Z+Zl5tABwp+RBgRD4EOEhOZBFck5Atqap+M8m5Sc5bdF8AFkk+BBiRDwEOkhOZxJGEDEZVvSXJj6wI//vWmmt0AYMiHwKMyIcAB8mJKBICAAAAwMD54RIAAAAAGDhFQgAAAAAYOEVCAAAAABg4RUIAAAAAGDhFQgAAAAAYOEVCAAAAABg4RUIAAAAAGDhFQgAAAAAYOEVCAAAAABg4RUIAAAAAGDhFQgAAAAAYuGMX3YGN9uQnP7mdeuqpi+4GMAef+tSnvtJa27bofhwt5EPYuuTD2ciHsLXJibORE2HrOtJ8uOWKhKeeemp279696G4Ac1BV/2PRfTiayIewdcmHs5EPYWuTE2cjJ8LWdaT50OnGAAAAADBwioQAAAAAMHCKhAAAAAAwcIqEAAAAADBwioQAAAAAMHCKhAAAAAAwcIqEAAAAADBwioQAAAAAMHCKhAAAAAAwcIqEAAAAADBwioQAAAAAMHCKhAAAAAAwcIqEAAAAADBwioQAAAAAMHDHLroDi/Sum770qNhPPf9pC+gJwGLJhwAHrcyJ8iEwVLYRYVgcSQgAAAAAA6dICDCDqvqFqrqtqj5XVe+uqu+oqqdX1U1Vtaeq3lNVx/V5H9sf7+3Pnzq2ntf1+B1V9aKx+Dk9treqLh2LT2wDAAAANoIiIcCUquqkJP80yY7W2rOSHJPkgiRvTPKm1tr2JA8muagvclGSB1trz0jypj5fquq0vtwPJjknyW9V1TFVdUyStyQ5N8lpSV7e580abQAAAMARm6pI6MgZgEccm+RxVXVsku9Mcm+SFyZ5b3/+qiQv6dPn98fpz59ZVdXj17TWvtVa+2KSvUme1297W2t3ttb+Ksk1Sc7vy6zWBgAAAByxdYuEjpwBGGmtfTnJryX5UkbFwYeSfCrJ11prD/fZ9iU5qU+flOTuvuzDff4njcdXLLNa/ElrtAEAAABHbNrTjR05AwxeVZ2QUS57epK/leS7MtrBsVI7sMgqz21UfFIfL66q3VW1e//+/ZNmAQAAgEdZt0joyBmAR/x4ki+21va31v46yR8m+XtJju87UZLk5CT39Ol9SU5Jkv78E5I8MB5fscxq8a+s0cYhWmtXtNZ2tNZ2bNu27UheK8C6XJIGYEQ+BLaCaU43duQMwMiXkpxRVd/Zj3Y+M8nnk3wkyUv7PDuTvL9PX9cfpz//4dZa6/EL+gbi05NsT/KJJJ9Msr1v7B2X0SUaruvLrNYGwEK4JA3AiHwIbBXTnG7syBmAJK21mzK6BMKnk9yaUQ69Islrk7ymqvZmdBT02/sib0/ypB5/TZJL+3puS3JtRgXGDyW5pLX2N/3I6VcnuSHJ7Umu7fNmjTYAFsklaQBG5EPgqHfs+rMcPHImyV9mdOTM7hw8quWaTD5y5mMZO3Kmqq5L8q6q+vWMjkg8cORMpR85k+TLGe05+am+zGptACxEa+2yJJetCN+Z0cbbynm/meRlq6zn9UlePyF+fZLrJ8QntgGwKK21L1fVgUvS/GWSP8oMl6SpqvFL0nx8bNXjy6y8JM3z45I0wJKRD4GtYpprEjpyBgCAQyz7JWlcjgbYLMueD3sf5URgXdMcSejIGQAAVnrkkjRJUlWHXJKm7wiedEmafVNekiarxB+5JM2ENh7RWrsiox3b2bFjx8RBM8AGWep8mMiJwHSmuSYhAACs5MecAEbkQ2BLUCQEAGBmLkkDMCIfAlvFVKcbAwDASi5JAzAiHwJbgSMJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBplRVz6yqm8duf1ZVP19VT6yqXVW1p9+f0OevqnpzVe2tqluq6vSxde3s8++pqp1j8edW1a19mTdXVfX4xDYAAABgIygSAkyptXZHa+3ZrbVnJ3lukm8keV+SS5Pc2FrbnuTG/jhJzk2yvd8uTnJ5Mir4JbksyfOTPC/JZWNFv8v7vAeWO6fHV2sDAAAAjti6RUJHzgBMdGaSL7TW/keS85Nc1eNXJXlJnz4/ydVt5ONJjq+qE5O8KMmu1toDrbUHk+xKck5/7vGttY+11lqSq1esa1IbAAAAcMTWLRI6cgZgoguSvLtPP7W1dm+S9Pun9PhJSe4eW2Zfj60V3zchvlYbAAAAcMRmPd3YkTPA4FXVcUlenOT315t1QqwdRnyWvl1cVburavf+/ftnWRQAAIABm7VI6MgZgNER059urd3XH9/Xd3ik39/f4/uSnDK23MlJ7lknfvKE+FptHKK1dkVrbUdrbce2bdsO8+UBrM8laQBG5ENgq5i6SOjIGYBHvDwHd5gkyXVJDmzE7Uzy/rH4hX1D8IwkD/UdHjckObuqTugbcmcnuaE/9/WqOqNv+F24Yl2T2gBYCJekARiRD4GtYpYjCR05AwxeVX1nkrOS/OFY+A1JzqqqPf25N/T49UnuTLI3yVuTvCpJWmsPJPmVJJ/st1/usSR5ZZK39WW+kOSD67QBsAxckgZgRD4EjlrHzjDvakfOvCGPPnLm1VV1TUZ7QB5qrd1bVTck+dWxPSFnJ3lda+2Bqvp6P8rmpoyOnPnNddoAWIjW2jeSPGlF7KsZbRCunLcluWSV9VyZ5MoJ8d1JnjUhPrENgCWx6iVpqmrul6QZa+MRVXVxRkfd5GlPe9rhvzKA2SxdPkzkRGA6Ux1J6MgZAAAmWdZL0jjTBNhsy5oPEzkRmM5URxI6cgYAgFVMvCRNP6Jl2kvSvGBF/KOZ4pI0E9oAWCT5EDiqzfrrxgAAMM6POQGMyIfAUW2WaxICAMAjxi5J83+Nhd+Q5NqquijJl5K8rMevT3JeRpeX+UaSVySjS9JU1YFL0iSPviTNO5I8LqPL0YxfkmZSGwALIR8CW4EiIQAAh8UlaQBG5ENgK3C6MQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiEAAAAADJwiIQAAAAAMnCIhAAAAAAycIiHADKrq+Kp6b1X9SVXdXlU/XFVPrKpdVbWn35/Q562qenNV7a2qW6rq9LH17Ozz76mqnWPx51bVrX2ZN1dV9fjENgAAAGAjTFUkNCgGeMS/T/Kh1tr/luSHktye5NIkN7bWtie5sT9OknOTbO+3i5NcnoxyW5LLkjw/yfOSXDaW3y7v8x5Y7pweX60NAAAAOGLTHkloUAwMXlU9PsmPJXl7krTW/qq19rUk5ye5qs92VZKX9Onzk1zdRj6e5PiqOjHJi5Lsaq090Fp7MMmuJOf05x7fWvtYa60luXrFuia1AQAAAEds3SKhQTHAI743yf4kv1tVn6mqt1XVdyV5amvt3iTp90/p85+U5O6x5ff12FrxfRPiWaONQ1TVxVW1u6p279+///BfKcAUnG0CMCIfAlvBNEcSLv2gGGCTHJvk9CSXt9aek+QvsvYRzjUh1g4jPrXW2hWttR2ttR3btm2bZVGAw+FsE4AR+RA46k1TJFz6QbEjZ4BNsi/JvtbaTf3xezPKj/f1o6LT7+8fm/+UseVPTnLPOvGTJ8SzRhsAC+FsE4AR+RDYKqYpEi79oNiRM8BmaK39zyR3V9Uze+jMJJ9Pcl2SA6eD7Ezy/j59XZIL+yklZyR5qB8VfUOSs6vqhL53+OwkN/Tnvl5VZ/RTSC5csa5JbQAsirNNAEbkQ2BLWLdIaFAMcIj/O8k7q+qWJM9O8qtJ3pDkrKrak+Ss/jhJrk9yZ5K9Sd6a5FVJ0lp7IMmvJPlkv/1yjyXJK5O8rS/zhSQf7PHV2gBYlKU+28SZJsAmWup8mMiJwHSOnXK+A4Pi4zIa8L4iowLjtVV1UZIvJXlZn/f6JOdlNMD9Rp83rbUHqurAoDh59KD4HUkel9GAeHxQPKkNgIVord2cZMeEp86cMG9Lcskq67kyyZUT4ruTPGtC/KuT2gBYoElnm1yafiZIa+3eGc42ecGK+EczxdkmE9p4RGvtiiRXJMmOHTtmGkwDzGip82EiJwLTmeZ047TWbu6n8/7d1tpLWmsPtta+2lo7s7W2vd8/0OdtrbVLWmvf11r7O33Ae2A9V7bWntFvvzsW391ae1Zf5tV9YJ3V2gAAYLGcbQIwIh8CW8W0RxICAMBKzjYBGJEPgaOeIiEAAIfFJRgARuRDYCuY6nRjAAAAAGDrUiQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBJhBVd1VVbdW1c1VtbvHnlhVu6pqT78/ocerqt5cVXur6paqOn1sPTv7/HuqaudY/Ll9/Xv7srVWGwAAALARpioSGhQDHOIftNae3Vrb0R9fmuTG1tr2JDf2x0lybpLt/XZxksuTUW5LclmS5yd5XpLLxvLb5X3eA8uds04bAAAAcMRmOZLQoBhgsvOTXNWnr0rykrH41W3k40mOr6oTk7woya7W2gOttQeT7EpyTn/u8a21j7XWWpKrV6xrUhsAAABwxI7kdGODYmCIWpI/qqpPVdXFPfbU1tq9SdLvn9LjJyW5e2zZfT22VnzfhPhabRyiqi6uqt1VtXv//v2H+RIBpuNsE4AR+RDYCqYtEi71oBhgE/1Ia+30jI6avqSqfmyNeWtCrB1GfGqttStaaztaazu2bds2y6IAh8vZJgAj8iFwVJu2SLjUg2JHzgCbpbV2T7+/P8n7MtqAu68fFZ1+f3+ffV+SU8YWPznJPevET54QzxptACwbZ5sAjMiHwFFlqiLhsg+KHTkDbIaq+q6q+p4D00nOTvK5JNclOXA6yM4k7+/T1yW5sJ9SckaSh/pR0TckObuqTuh7h89OckN/7utVdUY/heTCFeua1AbAIjnbBGBkqfOhA2uAaaxbJDQoBnjEU5P816r6bJJPJPlPrbUPJXlDkrOqak+Ss/rjJLk+yZ1J9iZ5a5JXJUlr7YEkv5Lkk/32yz2WJK9M8ra+zBeSfLDHV2sDYJGW9mwTA2Jgky1tPkwcWANM59gp5nlqkvf166Iem+RdrbUPVdUnk1xbVRcl+VKSl/X5r09yXkYD3G8keUUyGhRX1YFBcfLoQfE7kjwuowHx+KB4UhsAm661dmeSH5oQ/2qSMyfEW5JLVlnXlUmunBDfneRZ07YBsEjjZ5tU1SFnm7TW7p3hbJMXrIh/NFOcbTKhjfG+XZHkiiTZsWPHTINpgFktcz4EmNa6RxK21u5srf1Qv/1ga+31Pf7V1tqZrbXt/f6BHm+ttUtaa9/XWvs7fcB7YF1Xttae0W+/Oxbf3Vp7Vl/m1X1gvWobAAAslrNNAEbkQ2CrmOZIQgAAWMnZJgAj8iGwJSgSAgAwM5dgABiRD4GtYqpfNwYAAAAAti5FQgAAAAAYOEVCAAAAABg4RUIAAAAAGDhFQgAAAAAYOEVCAAAAABg4RUIAAAAAGDhFQgAAAAAYOEVCAAAAABg4RUIAAAAAGDhFQgAAAAAYOEVCAAAAABg4RUIAAAAAGDhFQgAAAAAYOEVCAAAAABg4RUIAAAAAGDhFQgAAAAAYOEVCAAAAABg4RUIAAAAAGDhFQgAAAAAYOEVCAAAAABg4RUIAAAAAGDhFQgAAAAAYOEVCAAAAABg4RUIAAAAAGDhFQgAAAAAYOEVCAAAAABg4RUKAGVXVMVX1mar6QH/89Kq6qar2VNV7quq4Hn9sf7y3P3/q2Dpe1+N3VNWLxuLn9Njeqrp0LD6xDQAAANgIUxcJDYoBHvFzSW4fe/zGJG9qrW1P8mCSi3r8oiQPttaekeRNfb5U1WlJLkjyg0nOSfJbPccek+QtSc5NclqSl/d512oDAAAAjtgsRxIaFAODV1UnJ/mHSd7WH1eSFyZ5b5/lqiQv6dPn98fpz5/Z5z8/yTWttW+11r6YZG+S5/Xb3tbana21v0pyTZLz12kDYGHsRAY4SE4EjnZTFQkNigEe8RtJ/kWSb/fHT0rytdbaw/3xviQn9emTktydJP35h/r8j8RXLLNafK02DlFVF1fV7qravX///sN9jQDTshMZ4CA5ETiqTXsk4VIPigE2Q1X9RJL7W2ufGg9PmLWt89xGxR8dbO2K1tqO1tqObdu2TZoFYEPYiQxwkJwIbAXrFgmPhkGxI2eATfIjSV5cVXdltHH2wox2ohxfVcf2eU5Ock+f3pfklCTpzz8hyQPj8RXLrBb/yhptACyKncgAB8mJwFFvmiMJl35Q7MgZYDO01l7XWju5tXZqRqeCfLi19tNJPpLkpX22nUne36ev64/Tn/9wa631+AX9ejRPT7I9ySeSfDLJ9n5tmeN6G9f1ZVZrA2DT2YkMcJCcCGwV6xYJDYoB1vXaJK+pqr0Z7dF9e4+/PcmTevw1SS5NktbabUmuTfL5JB9Kcklr7W/6XuBXJ7kho+vZXNvnXasNgEWwExngIDkR2BJm+XXjlQyKgcFqrX20tfYTffrO1trzWmvPaK29rLX2rR7/Zn/8jP78nWPLv7619n2ttWe21j44Fr++tfb9/bnXj8UntgGwCHYiAxwkJwJbxbHrz3JQa+2jST7ap+/M6AKqK+f5ZpKXrbL865O8fkL8+iTXT4hPbAMAgKX02iTXVNW/TvKZHLoT+ff6jt8HMhrgprV2W1Ud2In8cPpO5CSpqgM7kY9JcuWKnciT2gBYNnIicFSZqUgIAADj7EQGOEhOBI5mR3K6MQAAAACwBSgSAgAAAMDAKRICAAAAwMApEgIAAADAwCkSAgAAAMDAKRICAAAAwMApEgIAAADAwCkSAgAAAMDAKRICAAAAwMApEgIAAADAwCkSAgAAAMDAKRICAAAAwMApEgIAAADAwCkSAgAAAMDAKRICAAAAwMApEgIAAADAwCkSAgAAAMDAKRICAAAAwMApEgIAAADAwCkSAgAAAMDAKRICAAAAwMApEgIAAADAwCkSAgAAAMDAKRICAAAAwMApEgIAAADAwCkSAgAAAMDAKRICAAAAwMApEgIAAADAwCkSAkypqr6jqj5RVZ+tqtuq6l/1+NOr6qaq2lNV76mq43r8sf3x3v78qWPrel2P31FVLxqLn9Nje6vq0rH4xDYAAABgI6xbJDQoBnjEt5K8sLX2Q0meneScqjojyRuTvKm1tj3Jg0ku6vNflOTB1tozkrypz5eqOi3JBUl+MMk5SX6rqo6pqmOSvCXJuUlOS/LyPm/WaAMAAACO2DRHEhoUAyRpI3/eHz6m31qSFyZ5b49fleQlffr8/jj9+TOrqnr8mtbat1prX0yyN8nz+m1va+3O1tpfJbkmyfl9mdXaAFgIO5IBRuRDYKtYt0hoUAxwUN+5cXOS+5PsSvKFJF9rrT3cZ9mX5KQ+fVKSu5OkP/9QkieNx1css1r8SWu0AbAodiQDjMiHwJYw1TUJDYoBRlprf9Nae3aSkzPayfEDk2br97XKcxsVf5SquriqdlfV7v3790+aBWBD2JEMMCIfAlvFVEVCg2KAQ7XWvpbko0nOSHJ8VR3bnzo5yT19el+SU5KkP/+EJA+Mx1css1r8K2u0sbJfV7TWdrTWdmzbtu1IXiLAuuxIBhiRD4GtYKZfNzYoBoasqrZV1fF9+nFJfjzJ7Uk+kuSlfbadSd7fp6/rj9Of/3BrrfX4Bf16NE9Psj3JJ5J8Msn2fm2Z4zI63eS6vsxqbQAszDLvSLYTGdhMy5wPEzkRmM40v25sUAwwcmKSj1TVLRnlrl2ttQ8keW2S11TV3oz26L69z//2JE/q8dckuTRJWmu3Jbk2yeeTfCjJJX3D8uEkr05yQ0Z59to+b9ZoA2DhlnFHsp3IwCIsYz7s/ZITgXUdu/4sOTHJVf1iqf9LRoPWD1TV55NcU1X/Oslncuig+Pf6QPaBjIp+aa3dVlUHBsUPpw+Kk6SqDgyKj0ly5YpB8aQ2ADZda+2WJM+ZEL8zoz3GK+PfTPKyVdb1+iSvnxC/Psn107YBsChVtS3JX7fWvja2I/mNObiT95pM3pH8sYztSK6q65K8q6p+PcnfysEdyZW+IznJlzPapvypvsxqbQBsOvkQ2CrWLRIaFAMAMIEdyQAj8iGwJUxzJCEAABzCjmSAEfkQ2Cpm+uESAAAAAGDrUSQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEAAAAgIFTJAQAAACAgVMkBAAAAICBUyQEmFJVnVJVH6mq26vqtqr6uR5/YlXtqqo9/f6EHq+qenNV7a2qW6rq9LF17ezz76mqnWPx51bVrX2ZN1dVrdUGAAAAbIR1i4QGxQCPeDjJP2ut/UCSM5JcUlWnJbk0yY2tte1JbuyPk+TcJNv77eIklyej3JbksiTPT/K8JJeN5bfL+7wHljunx1drAwCABTJmBraKaY4kNCgGSNJau7e19uk+/fUktyc5Kcn5Sa7qs12V5CV9+vwkV7eRjyc5vqpOTPKiJLtaaw+01h5MsivJOf25x7fWPtZaa0muXrGuSW0ALIRBMcAjjJmBLWHdIqFBMcCjVdWpSZ6T5KYkT22t3ZuMcmaSp/TZTkpy99hi+3psrfi+CfGs0QbAohgUA8SYGdg6Zrom4bIOiqvq4qraXVW79+/fP8tLAphZVX13kj9I8vOttT9ba9YJsXYY8Vn6Jh8Cm8KgGODRlnXMDDCNqYuEyzwobq1d0Vrb0VrbsW3btlkWBZhJVT0mo1z4ztbaH/bwfX0wm35/f4/vS3LK2OInJ7lnnfjJE+JrtXEI+RBYhGUcFNtpAmy2ZR4zy4nANKYqEi77oBhgM/RrYb09ye2ttV8fe+q6JAeuobUzyfvH4hf263CdkeShPpi9IcnZVXVCP6Xu7CQ39Oe+XlVn9LYuXLGuSW0ALNSyDortNAE207KPmeVEYBrT/LqxQTHAyI8k+ZkkL6yqm/vtvCRvSHJWVe1JclZ/nCTXJ7kzyd4kb03yqiRprT2Q5FeSfLLffrnHkuSVSd7Wl/lCkg/2+GptACzMsg+KATaDMTOwVRw7xTwHBsW3VtXNPfb/ZDRAvbaqLkrypSQv689dn+S8jAa430jyimQ0KK6qA4Pi5NGD4nckeVxGA+LxQfGkNgA2XWvtv2bykS1JcuaE+VuSS1ZZ15VJrpwQ353kWRPiX53UBsCiTDEofkMePSh+dVVdk9GPlDzUWru3qm5I8qtjP1ZydpLX9W3Hr/cB9E0ZDYp/c502ABbBmBnYEtYtEhoUAwAwgUExQIyZga1jmiMJAQDgEAbFAABby9S/bgwAAAAAbE2KhAAAAAAwcIqEAAAAADBwioQAAAAAMHCKhAAAAAAwcIqEAAAAADBwioQAAAAAMHCKhAAAAAAwcIqEAAAAADBwioQAAAAAMHCKhAAAAAAwcIqEAAAAADBwioQAAAAAMHCKhAAAAAAwcIqEAAAAADBwioQAAAAAMHCKhAAAAAAwcIqEAAAAADBwioQAAAAAMHCKhAAAAAAwcIqEAAAAADBwioQAAAAAMHCKhAAAAAAwcIqEAAAAADBwioQAAAAAMHCKhAAA9vFGEgAAIABJREFUAAAwcIqEAAAAADBwioQAAAAAMHCKhAAzqKorq+r+qvrcWOyJVbWrqvb0+xN6vKrqzVW1t6puqarTx5bZ2effU1U7x+LPrapb+zJvrqpaqw0AAADYCOsWCQ2IAQ7xjiTnrIhdmuTG1tr2JDf2x0lybpLt/XZxksuTUX5LclmS5yd5XpLLxnLc5X3eA8uds04bAAthGxFgRD4EtoppjiR8RwyIAZIkrbU/TvLAivD5Sa7q01cleclY/Oo28vEkx1fViUlelGRXa+2B1tqDSXYlOac/9/jW2sdaay3J1SvWNakNgEV5R2wjAiTyIbBFrFskNCAGWNdTW2v3Jkm/f0qPn5Tk7rH59vXYWvF9E+JrtQGwELYRAUbkQ2CrONxrEi7VgLiqLq6q3VW1e//+/Yf5kgA2XE2ItcOIT9+gfAgs1lJtIwIskHwIHHU2+odLNn1AnCSttStaaztaazu2bds26+IAR+q+vpc3/f7+Ht+X5JSx+U5Ocs868ZMnxNdq4xDyIbCk7DQBGFnImFlOBKZxuEXCpRkQAyyB65IcuLj0ziTvH4tf2C9QfUaSh/pe3huSnF1VJ/RrzZyd5Ib+3Ner6ox+QeoLV6xrUhsAy2RpthHtNAEWbGnyYSInAtM53CKhATEwSFX17iQfS/LMqtpXVRcleUOSs6pqT5Kz+uMkuT7JnUn2JnlrklclSWvtgSS/kuST/fbLPZYkr0zytr7MF5J8sMdXawNgmdhGBBiRD4GjzrHrzdAHxC9I8uSq2pfRLy69Icm1fXD8pSQv67Nfn+S8jAa330jyimQ0IK6qAwPi5NED4nckeVxGg+HxAfGkNgAWprX28lWeOnPCvC3JJaus58okV06I707yrAnxr05qA2BRbCMCjMiHwFaxbpHQgBgAgJVsIwKMyIfAVrHRP1wCAAAAABxlFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAAAAYOAUCQEAAABg4BQJAQAAAGDgFAkBAACA/5+9+4+zrK7vPP96p1sUjQhi68OhYcC1xwTdiNAPaOPGMaDQkIzNzMIujI/Qa9jtrMGMP2Y2wmZ32eiQh2adIWFXyRBBmzyMgERDjwOSXpSdyYz8aBD5KekSDVQg0NqAJjzUYD77x/0WXIpb1bdu3aq63ef1fDzu457zOd9zvt9Tt+pbpz51zvcrqeNMEkqSJEmSJEkdN/FJwiQbk9yfZCrJuSvdHklaSfaJktRjfyhJPfaHksZl9Uo3YD5JVgGfAN4BTAO3JtlWVfeubMskafktd5/4xzc/+Jz1f37cYUtRjSQtmNeIktRjfyhpnCY6SQgcC0xV1QMASa4ANgF2eNJeaHbSCUw8LZB9oiT12B9KUo/9oaSxmfQk4SHAQ33r08Bxswsl2QJsaat/k+T+IY//CuC7/YF3jdDIJfC8dk2ISWzXJLYJJrNdk9gm3rWwdv3DpWzLXmCPfeI4+8PZlrh/XMnvz67WvdL1e+6LY3+4dP0hzPqMVvD6cKV/TmZMSjtgctpiO55rpdvR5T6xq38zj9NKf/8uh339HPf184Phz3FR/eGkJwkzIFbPC1RdAlyy4IMnO6pq/SgNW0q2a3iT2CaYzHZNYptgcts1ofbYJ+6t/eFK1t/Vule6fs/dfm+Rlqw/hMn5jGzH801KW2zHZLajozr5N/M4eY57v339/GD5znHSJy6ZBg7tW18LPLxCbZGklWafKEk99oeS1GN/KGlsJj1JeCuwLskRSfYDzgC2rXCbJGml2CdKUo/9oST12B9KGpuJfty4qp5O8l7gemAVcFlV3TPGKkZ6BGUZ2K7hTWKbYDLbNYltgslt18RZ4j5xpT+Hlay/q3WvdP2eu0bWoWtE2/F8k9IW2/Fck9KOzulQf7iUPMe9375+frBM55iq5w1XIEmSJEmSJKlDJv1xY0mSJEmSJElLzCShJEmSJEmS1HGdTRIm2Zjk/iRTSc5d5rovS/JYkrv7Yi9Psj3JzvZ+UIsnyUWtnXcmOXqJ2nRokq8muS/JPUneNyHtelGSW5J8o7Xrt1v8iCQ3t3Zd2QbpJckL2/pU2374UrSr1bUqydeTfGmC2vSdJHcluSPJjhZb6c/wwCRXJ/lm+/5680q3Sc+1FP3huPq5JJtb+Z1JNg9Z99j6sxHrH1u/leS8Fr8/yUnD1N/2W3T/NErd4+qDRvm6t/3G0t8stP4kr2vnPPP6fpL3L+e5azyyjNeHmbBrr3H0G2Nqx0RcNyT5QPtc7k7yufT69mX5mmQFf4cO0Y7/q302dyb5YpID+7YN/L2xnD9XGq9J/+yW+mclyTHpXddMtX0zXx1LdI5Lfl27kueZZbhunuv7eK46lkqW8Pp8rOdYVZ170RvQ9VvAa4D9gG8ARy5j/W8Fjgbu7ov9LnBuWz4X+FhbPgW4DgiwAbh5idr0auDotvxS4C+AIyegXQF+ui2/ALi51XcVcEaL/wHwnrb868AftOUzgCuX8HP8IPDHwJfa+iS06TvAK2bFVvoz3Ar8j215P+DAlW6Tr+d8PkvSH46jnwNeDjzQ3g9qywcNUfdY+rNF1D+Wfqu1+RvAC4Ej2ue0asiv/6L6p1HrZgx90Khf97bvovubxdTf9zP118A/XO66fS3uxTJfHzJh116L7TfG2I4Vv24ADgG+Dezf97X4H5bra8IK/g4doh0nAqvb8sf62jHw98Zy/1z5Gt9rb/jslvpnBbgFeHPb5zrg5PnqWKJzXPLr2pU8T5b4unm+7+O56ljCz3JJrs/HfY4r/oO9Eq/2A3B93/p5wHnL3IbDeW5ndj/w6rb8auD+tvzvgDMHlVvi9l0DvGOS2gW8GLgdOA74Ls9eoDzzedKb1evNbXl1K5claMta4AbgeOBLrXNb0Ta143+H5/+BvmKfIXAAvYvsTEqbfD3vM1qy/nCx/RxwJvDv+uLPKbeAdozUn42j/sX0W7M/i/5ye6hz0f3TIupedB806td9XP3NYj93en9A/+eV/J73NdqLFb4+ZAWvvcbRb4ypHRNx3UAvSfgQvT+mV7evyUnL+TVhcn6HPqcds7b9U+CzbXng742V/rnytajvwb3is1uqn5W27Zt98WfKzVXHMp3vWK9rJ+k8WYLr5rm+j5nn99wSnduSXZ+P+xy7+rjxzC/+GdMttpJeVVWPALT3V7b4sre13c76JnpZ/BVvV7st9w7gMWA7vSz5E1X19IC6n2lX2/4kcPASNOv3gN8E/r6tHzwBbQIo4M+S3JZkS4ut5Gf4GmAX8Ol2a/Wnkrxkhduk51rOr/lCP/dFt22R/dnI9Y+p3xq1/nH0T6PWPY4+aNS6x9XfLPb77gzgc2152b/ntSgr9vWfgGuvSbmumYjrhqr6K+DjwIPAI/TO8TZW9lpvEvuTX6V319FKt0NLY2/97Mb1s3JIW54dn6+OJbVE17Urfp5LfN08V3y+33NLYSmvz8d6jl1NEmZArJa9FcNZ1rYm+WngT4D3V9X35ys6ILYk7aqqn1TVUfSy78cCPztP3UveriS/DDxWVbf1h1eyTX3eUlVHAycD5yR56zxll6Ndq+k9AnBxVb0J+Ft6t6qvZJv0XJPwNZ+rDYtq2xj6s5HrH1O/teD6x9g/jXru4+iDRq17XP3NyJ97G+flncDn91R03HVrLFbk67/S114Tdl0zEdcNbdytTfQe5/oHwEvo9Wtz1bWSP7sr0p8k+S3gaeCzK9kOLal97bNb6PfoRJ3/El7Xrvh5LvF184qf9zJcn4/1HLuaJJwGDu1bXws8vEJtmfFoklcDtPfHWnzZ2prkBfQ6ns9W1RcmpV0zquoJ4EZ6YxQcmGT1gLqfaVfb/jJg95ib8hbgnUm+A1xB75bh31vhNgFQVQ+398eAL9LrZFfyM5wGpqvq5rZ+Nb2L/4n5vtKyfs0X+rmP3LYx9WeL/tosst8apf5x9U8jnfuY+qBRv+7j6m8W87mfDNxeVY+29WX/ntOiLPvXf0KuvSbpumZSrhveDny7qnZV1d8BXwB+npW91puY/iS9CQ9+GXhXtWfYVqIdWnJ762c3rp+V6bY8Oz5fHUtiia9rJ+Y8l+i6ea74d+epY9yW+vp8rOfY1SThrcC6NtPLfvQeDdq2wm3aBmxuy5vpjTUwEz8rPRuAJ2du+R2nJAEuBe6rqn87Qe1akzZrWpL96V203Qd8FThtjnbNtPc04Ct9Fy9jUVXnVdXaqjqc3vfOV6rqXSvZJoAkL0ny0plleuNi3c0KfoZV9dfAQ0le10InAPeuZJv0PMvZHy70c78eODHJQe2ujhNbbF5j7M9GrX9c/dY24Iz0Zjg7AlhHb2DpOY2xf1pw3WPsg0b6uo+xvxmp/uZMnn3UeKaO5apbi7es14eTcu01Sdc1E3Td8CCwIcmL2+c0046VvNabiP4kyUbgQ8A7q+qpWe0b9HtjEv/u0nD21s9uLD8rbdsPkmxo/cBZDP6Z769j7Jb6unalz3MZrpsHfh+3feaqY6yW4fp8vOdYyzTA5qS96M368xf0nnf/rWWu+3P0xjf5O3pZ37PpPS9+A7Czvb+8lQ3widbOu4D1S9Sm/4berad3Ane01ykT0K6fA77e2nU38H+0+GvaD8QUvce6XtjiL2rrU237a5b4s3wbz85OtKJtavV/o73umfm+noDP8ChgR/sM/5TebFor2iZfz/uMxt4fjqufozfe0VR7vXvIusfWn41Y/9j6LeC3Wrvup800t4DPYFH900LrZox90Chf97bfWPqbET/3FwPfA17WF1u2c/c1nhfLeH3IBF57LbbfGFMbJuK6Afht4Jv0+vE/ojeb5LJ8TVjB36FDtGOK3thXM9+zf9BXfuDvjeX8ufI13tekf3ZL/bMCrG99wLeA/wd6ExLNVccSneOSX9eu5HmyDNfNc30fz1XHEn/Pvo0luD4f5znOfPiSJEmSJEmSOqqrjxtLkiRJkiRJakwSSpIkSZIkSR1nklCSJEmSJEnqOJOEkiRJkiRJUseZJJQkSZIkSZI6ziShJEmSJEmS1HEmCbVXSXJ4krvb8vokF7XltyX5+UUc9zeS3J/kniS/O672StJSWYr+MMmVSe5or+8kuWOcbZakpbBE/eFRSW5q/eGOJMeOs82StFSWqE98Y5KvJbkryb9PcsA426zJsXqlGyCNqqp2ADva6tuAvwH+y0KPk+QXgU3Az1XVj5K8cmyNlKRlMK7+sKr++5nlJP8GeHIc7ZOk5TKu/hD4XeC3q+q6JKe09beNo42StFzG2Cd+CvhXVfX/JflV4H8B/vexNFITxTsJtWyS/Fa7W+//TfK5JP8qyY1J1rftr0jynbZ8eJL/lOT29nrefzzaf0K+lORw4H8GPtD+2/sLSb6d5AWt3AHtjpgXzNG09wAfraofAVTVY2M/eUnqM8H94czxAvx3wOfGeuKSNMsE94cFzNwp8zLg4bGeuCQNMMF94uuA/9iWtwP/7VhPXBPDOwm1LJIcA5wBvIne993twG3z7PIY8I6q+mGSdfT+UF0/qGBVfSfJHwB/U1Ufb/XdCPwS8Ket3j+pqr+bo65/BPxCkguAH9L7D8mtCzxFSRrKhPeHM34BeLSqdg59YpK0QBPeH74fuD7Jx+ndWDHysDaSNIwJ7xPvBt4JXAOcDhy6sLPT3sI7CbVcfgH4YlU9VVXfB7btofwLgD9MchfweeDIBdb3KeDdbfndwKfnKbsaOAjYQO+26avaXTSStBQmuT+ccSbeRShp6U1yf/ge4ANVdSjwAeDSBdYlSQs1yX3irwLnJLkNeCnw4wXWpb2EdxJqOdWA2NM8m6x+UV/8A8CjwBvb9h8uqKKq/9xuv/7HwKqqunue4tPAF6qqgFuS/D3wCmDXQuqUpAWY1P6QJKuBfwYcs5B6JGlEk9ofbgbe15Y/T++PaUlaahPZJ1bVN4ETAZL8I3p3IGof5J2EWi7/EfinSfZP8lLgn7T4d3j2D9HT+sq/DHikqv4e+BVg1R6O/wN6/9Hodzm9O2H2dNfMnwLHwzMd3n7Ad/ewjySNapL7Q4C3A9+squkhykrSYkxyf/gw8I/b8vGAwy9IWmoT2yemTe6Z5KeA/w34gz3Upb2USUIti6q6HbgSuAP4E+A/tU0fB96T5L/Qu3tvxieBzUluojdm4N/uoYp/T69DvSPJL7TYZ+k9RrynR+YuA16T3jTxVwCb212FkjR2E94fQm9MGh81lrTkJrw//J+Af5PkG8DvAFuGOytJGs2E94lnJvkL4Jv0/okyzD+etReKuRCthCT/J32Dpi5RHacBm6rqV5aqDklaLPtDSeqxP5SkZ9knaiU4JqH2SUn+b+Bk4JSVboskrST7Q0nqsT+UpGfZJ2oQ7yRUZyT5BPCWWeHfrypvlZbUKfaHktRjfyhJz7JPlElCSZIkSZIkqeOcuESSJEmSJEnqOJOEkiRJkiRJUseZJJQkSZIkSZI6ziShJEmSJEmS1HEmCSVJkiRJkqSOM0koSZIkSZIkdZxJQkmSJEmSJKnjTBJKkiRJkiRJHWeSUJIkSZIkSeo4k4SSJEmSJElSx5kklKQhJXldkjv6Xt9P8v4kL0+yPcnO9n5QK58kFyWZSnJnkqP7jrW5ld+ZZHNf/Jgkd7V9LkqSFh9YhyRJkiRJ45CqWuk2jNUrXvGKOvzww1e6GZKWwG233fbdqlqz0u0ASLIK+CvgOOAcYHdVfTTJucBBVfWhJKcAvwGc0sr9flUdl+TlwA5gPVDAbcAxVfV4kluA9wE3AdcCF1XVdUl+d1Ad87XR/lDad01Sf7g3sD+U9m32iZI0HqtXugHjdvjhh7Njx46VboakJZDkL1e6DX1OAL5VVX+ZZBPwthbfCtwIfAjYBFxevf/G3JTkwCSvbmW3V9VugCTbgY1JbgQOqKqvtfjlwKnAde1Yg+qYk/2htO+asP5w4tkfSvs2+0RJGg8fN5ak0ZwBfK4tv6qqHgFo769s8UOAh/r2mW6x+eLTA+Lz1fEcSbYk2ZFkx65du0Y8NUmSJElS15gklKQFSrIf8E7g83sqOiBWI8SHVlWXVNX6qlq/Zo1P3UiSJEmShmOSUJIW7mTg9qp6tK0/2h4jpr0/1uLTwKF9+60FHt5DfO2A+Hx1SJIkSZK0aCYJJWnhzuTZR40BtgEzMxRvBq7pi5/VZjneADzZHhW+HjgxyUFtluITgevbth8k2dBmNT5r1rEG1SFJkiRJ0qLtcxOXSNJSSvJi4B3Ar/WFPwpcleRs4EHg9Ba/lt7MxlPAU8C7Aapqd5KPALe2ch+emcQEeA/wGWB/ehOWXLeHOiRJkiRJWjSThJK0AFX1FHDwrNj36M12PLtsAefMcZzLgMsGxHcAbxgQH1iHJEmSJEnj4OPGkiRJkiRJUseZJJQkSZIkSZI6ziShJEmSJEmS1HEmCSVJkiRJkqSOM0koSZKkkST5QJJ7ktyd5HNJXpTkiCQ3J9mZ5Mok+7WyL2zrU2374X3HOa/F709yUl98Y4tNJTm3Lz6wDkmSJI3OJKEkSZIWLMkhwL8A1lfVG4BVwBnAx4ALq2od8DhwdtvlbODxqnotcGErR5Ij236vBzYCn0yyKskq4BPAycCRwJmtLPPUIUmSpBGZJJQkSdKoVgP7J1kNvBh4BDgeuLpt3wqc2pY3tXXa9hOSpMWvqKofVdW3gSng2PaaqqoHqurHwBXAprbPXHVIkiRpRCYJJUmStGBV9VfAx4EH6SUHnwRuA56oqqdbsWngkLZ8CPBQ2/fpVv7g/visfeaKHzxPHZIkSRrR6pVuwEr645sffF7snx932Aq0RJL2TrP7UftQqTuSHETvLsAjgCeAz9N7NHi2mtlljm1zxQf9M3u+8rPbtwXYAnDYYQvrm+zbJElSF3knoSRJkkbxduDbVbWrqv4O+ALw88CB7fFjgLXAw215GjgUoG1/GbC7Pz5rn7ni352njmdU1SVVtb6q1q9Zs2ax5ypJkrTPM0koSZKkUTwIbEjy4jZO4AnAvcBXgdNamc3ANW15W1unbf9KVVWLn9FmPz4CWAfcAtwKrGszGe9Hb3KTbW2fueqQJEnSiEwSSpIkacGq6mZ6k4fcDtxF77ryEuBDwAeTTNEbP/DStsulwMEt/kHg3Hace4Cr6CUYvwycU1U/aWMOvhe4HrgPuKqVZZ46JEmSNKJOj0koSZKk0VXV+cD5s8IP0JuZeHbZHwKnz3GcC4ALBsSvBa4dEB9YhyRJkkbnnYSSJEmSJElSxw2VJEzygST3JLk7yeeSvKiND3Nzkp1JrmxjxdDGk7kyyVTbfnjfcc5r8fuTnNQX39hiU0nO7YsPrEOSJEmSJEnS+OwxSZjkEOBfAOur6g3AKnoDR38MuLCq1gGPA2e3Xc4GHq+q1wIXtnIkObLt93pgI/DJJKuSrAI+AZwMHAmc2coyTx2SJEmSJEmSxmTYx41XA/snWQ28GHgEOJ7eYNUAW4FT2/Kmtk7bfkKb8W4TcEVV/aiqvg1M0RtL5lhgqqoeqKofA1cAm9o+c9UhSZIkSZIkaUz2mCSsqr8CPg48SC85+CRwG/BEm3UOYBo4pC0fAjzU9n26lT+4Pz5rn7niB89ThyRJkiRJkqQxGeZx44Po3QV4BPAPgJfQezR4tprZZY5t44oPauOWJDuS7Ni1a9egIpIkSZIkSZLmMMzjxm8Hvl1Vu6rq74AvAD8PHNgePwZYCzzclqeBQwHa9pcBu/vjs/aZK/7deep4jqq6pKrWV9X6NWvWDHFKkiRJkiRJkmYMkyR8ENiQ5MVtnMATgHuBrwKntTKbgWva8ra2Ttv+laqqFj+jzX58BLAOuAW4FVjXZjLej97kJtvaPnPVIUmSJEmSJGlMhhmT8GZ6k4fcDtzV9rkE+BDwwSRT9MYPvLTtcilwcIt/EDi3Hece4Cp6CcYvA+dU1U/amIPvBa4H7gOuamWZpw5JkiRJkiRJY7J6z0Wgqs4Hzp8VfoDezMSzy/4QOH2O41wAXDAgfi1w7YD4wDokSZIkSZIkjc8wjxtLkiRJkiRJ2oeZJJQkSZIkSZI6ziShJEmSJEmS1HEmCSVJkiRJkqSOM0koSZIkSZIkdZxJQkmSJEmSJKnjTBJKkiRJkiRJHWeSUJIkSZIkSeo4k4SSJEmSJElSx5kklCRJkiRJkjrOJKEkSZIkSZLUcSYJJUmSJEmSpI4zSShJkiRJkiR1nElCSZIkSZIkqeNMEkqSJEmSJEkdZ5JQkhYgyYFJrk7yzST3JXlzkpcn2Z5kZ3s/qJVNkouSTCW5M8nRfcfZ3MrvTLK5L35MkrvaPhclSYsPrEOSJEmSpHEwSShJC/P7wJer6meANwL3AecCN1TVOuCGtg5wMrCuvbYAF0Mv4QecDxwHHAuc35f0u7iVndlvY4vPVYckSZIkSYtmklCShpTkAOCtwKUAVfXjqnoC2ARsbcW2Aqe25U3A5dVzE3BgklcDJwHbq2p3VT0ObAc2tm0HVNXXqqqAy2cda1AdkiRJkiQtmklCSRrea4BdwKeTfD3Jp5K8BHhVVT0C0N5f2cofAjzUt/90i80Xnx4QZ546JEmSJElaNJOEkjS81cDRwMVV9Sbgb5n/sd8MiNUI8aEl2ZJkR5Idu3btWsiukiRJkqQOM0koScObBqar6ua2fjW9pOGj7VFh2vtjfeUP7dt/LfDwHuJrB8SZp47nqKpLqmp9Va1fs2bNSCcpSZIkSeoek4SSNKSq+mvgoSSva6ETgHuBbcDMDMWbgWva8jbgrDbL8Qbgyfao8PXAiUkOahOWnAhc37b9IMmGNqvxWbOONagOSVoRSV6X5I6+1/eTvN8Z3yVJkvZOJgklaWF+A/hskjuBo4DfAT4KvCPJTuAdbR3gWuABYAr4Q+DXAapqN/AR4Nb2+nCLAbwH+FTb51vAdS0+Vx2StCKq6v6qOqqqjgKOAZ4CvogzvkuSJO2VVq90AyRpb1JVdwDrB2w6YUDZAs6Z4ziXAZcNiO8A3jAg/r1BdUjShDgB+FZV/WWSTcDbWnwrcCPwIfpmfAduSjIz4/vbaDO+AySZmfH9RtqM7y0+M+P7de1Yg+qQJEnSiLyTUJIkSYt1BvC5tuyM75IkSXshk4SSJEkaWZL9gHcCn99T0QGxJZvx3dneJUmSFsYkoSRJkhbjZOD2qnq0rU/EjO/O9i5JkrQwJgklSZK0GGfy7KPG4IzvkiRJeyUnLpEkSdJIkryY3ozrv9YX/ihwVZKzgQeB01v8WuAUerO3PwW8G3ozvieZmfEdnj/j+2eA/elNWNI/4/ugOiRJkjQik4SSJEkaSVU9BRw8KzZwNnZnfJckSZpse3zcOMnrktzR9/p+kvcneXmS7Ul2tveDWvkkuSjJVJI7kxzdd6zNrfzOJJv74sckuavtc1F7pIS56pAkSZIkSZI0PntMElbV/VV1VFUdBRxD7/GQLwLnAjdU1TrghrYOvcGr17XXFuBi6CX8gPOB44BjgfP7kn4Xt7Iz+21s8bnqkCRJkiRJkjQmC5245ATgW1X1l8AmYGuLbwVObcubgMur5ybgwDbr3EnA9qraXVWPA9uBjW3bAVX1tfYYyuWzjjWoDkmSJEmSJEljstAk4Rk8O3vdq9qsc7T3V7b4IcBDfftMt9h88ekB8fnqeI4kW5LsSLJj165dCzwlSZIkSZIkqduGThIm2Q94J/D5PRUdEKsR4kOrqkuqan1VrV+zZs1CdpUkSZJvOmcrAAAgAElEQVQkSZI6byF3Ep4M3F5Vj7b1R9ujwrT3x1p8Gji0b7+1wMN7iK8dEJ+vDkmSJEmSJEljspAk4Zk8+6gxwDZgZobizcA1ffGz2izHG4An26PC1wMnJjmoTVhyInB92/aDJBvarMZnzTrWoDokSZIkSZIkjcnqYQoleTHwDuDX+sIfBa5KcjbwIHB6i18LnAJM0ZsJ+d0AVbU7yUeAW1u5D1fV7rb8HuAzwP7Ade01Xx2SJEmSJEmSxmSoJGFVPQUcPCv2PXqzHc8uW8A5cxznMuCyAfEdwBsGxAfWIUmSJEmSJGl8Fjq7sSRJkiRJkqR9jElCSZIkSZIkqeNMEkqSJEmSJEkdZ5JQkiRJkiRJ6jiThJIkSZIkSVLHmSSUJEmSJEmSOs4koSRJkiRJktRxJgklSZIkSZKkjjNJKEmSJEmSJHWcSUJJkiRJkiSp40wSSpIkSZIkSR1nklCSJEmSJEnqOJOEkiRJkiRJUseZJJQkSZIkSZI6ziShJEmSJEmS1HEmCSVJkiRJkqSOM0koSZIkSZIkdZxJQkmSJEmSJKnjTBJKkiRJkiRJHWeSUJIkSZIkSeo4k4SSJEmSJElSx5kklCRJkiRJkjrOJKEkSZJGkuTAJFcn+WaS+5K8OcnLk2xPsrO9H9TKJslFSaaS3Jnk6L7jbG7ldybZ3Bc/JsldbZ+LkqTFB9YhSZKk0ZkklCRJ0qh+H/hyVf0M8EbgPuBc4IaqWgfc0NYBTgbWtdcW4GLoJfyA84HjgGOB8/uSfhe3sjP7bWzxueqQJEnSiEwSStICJPlOu6vljiQ7Wsy7ZiR1TpIDgLcClwJU1Y+r6glgE7C1FdsKnNqWNwGXV89NwIFJXg2cBGyvqt1V9TiwHdjYth1QVV+rqgIun3WsQXVIkiRpRCYJJWnhfrGqjqqq9W3du2YkddFrgF3Ap5N8PcmnkrwEeFVVPQLQ3l/Zyh8CPNS3/3SLzRefHhBnnjokSZI0IpOEkrR43jUjqYtWA0cDF1fVm4C/Zf5/YGRArEaIDyXJliQ7kuzYtWvXsLtJkiR1lklCSVqYAv4syW1JtrTYxNw14x/FkpbRNDBdVTe39avpJQ0fbf/0oL0/1lf+0L791wIP7yG+dkCceep4RlVdUlXrq2r9mjVrRj5JSZKkrjBJKEkL85aqOpreo8TnJHnrPGWX9a4Z8I9iScunqv4aeCjJ61roBOBeYBswM9bqZuCatrwNOKuN17oBeLL90+N64MQkB7WhF04Erm/bfpBkQxuf9axZxxpUhyRJkkY0VJIwyYFJrk7yzST3JXmzA/VL6qKqeri9PwZ8kd6YghNx14wkrYDfAD6b5E7gKOB3gI8C70iyE3hHWwe4FngAmAL+EPh1gKraDXwEuLW9PtxiAO8BPtX2+RZwXYvPVYckSZJGNOydhL8PfLmqfgZ4I3AfDtQvqWOSvCTJS2eW6d3tcjfeNSOpo6rqjnb38s9V1alV9XhVfa+qTqiqde19dytbVXVOVf1XVfVfV9WOvuNcVlWvba9P98V3VNUb2j7vbeO1MlcdkiRJGt0ek4RJDgDeClwKUFU/rqoncKB+Sd3zKuDPk3wDuAX4D1X1ZbxrRpIkSZK0l1s9RJnXALuATyd5I3Ab8D5mDaKfZMkH6u+rQ5KWXVU9QO9u6tnx79Ebi2t2vIBz5jjWZcBlA+I7gDcMW4ckSZIkSeMwzOPGq+nNVHdxVb0J+Fvmf+x32QfqdzZPSZIkSZIkaXTDJAmngemqurmtX00vaTgxA/U7m6ckSZIkSZI0uj0mCavqr4GHkryuhU4A7sWB+iVJkiRJkqR9wjBjEgL8BvDZJPvRG4T/3fQSjFclORt4EDi9lb0WOIXeoPtPtbJU1e4kMwP1w/MH6v8MsD+9Qfr7B+ofVIckSZIkSZKkMRkqSVhVdwDrB2xyoH5JkiRJkiRpLzfMmISSJEmSJEmS9mEmCSVJkiRJkqSOM0koSZIkSZIkdZxJQkmSJEmSJKnjTBJKkiRJkiRJHWeSUJIkSZIkSeo4k4SSJEmSJElSx5kklCRJkiRJkjrOJKEkSZIkSZLUcSYJJUmSJEmSpI4zSShJkiRJkiR1nElCSZIkSZIkqeNMEkqSJEmSJEkdZ5JQkiRJkiRJ6jiThJIkSZIkSVLHmSSUJEmSJEmSOs4koSRJkiRJktRxJgklSZIkSZKkjjNJKEmSJEmSJHWcSUJJkiRJkiSp40wSSpIkSZIkSR1nklCSJEmSJEnqOJOEkiRJkiRJUseZJJQkSZIkSZI6ziShJEmSRpLkO0nuSnJHkh0t9vIk25PsbO8HtXiSXJRkKsmdSY7uO87mVn5nks198WPa8afavpmvDkmSJI3OJKEkSZIW4xer6qiqWt/WzwVuqKp1wA1tHeBkYF17bQEuhl7CDzgfOA44Fji/L+l3cSs7s9/GPdQhSZKkEZkklCRJ0jhtAra25a3AqX3xy6vnJuDAJK8GTgK2V9Xuqnoc2A5sbNsOqKqvVVUBl8861qA6JEmSNCKThJIkSRpVAX+W5LYkW1rsVVX1CEB7f2WLHwI81LfvdIvNF58eEJ+vDkmSJI1o9Uo3QJIkSXutt1TVw0leCWxP8s15ymZArEaID6UlLbcAHHbYYcPuJkmS1FneSShJkqSRVNXD7f0x4Iv0xhR8tD0qTHt/rBWfBg7t230t8PAe4msHxJmnjv62XVJV66tq/Zo1axZzmpIkSZ0wVJLQmeskSZLUL8lLkrx0Zhk4Ebgb2AbMXOdtBq5py9uAs9q14gbgyfao8PXAiUkOatd6JwLXt20/SLKhXRueNetYg+qQJEnSiBZyJ6Ez10mSJGnGq4A/T/IN4BbgP1TVl4GPAu9IshN4R1sHuBZ4AJgC/hD4dYCq2g18BLi1vT7cYgDvAT7V9vkWcF2Lz1WHJEmSRrSYMQk3AW9ry1uBG4EP0TdzHXBTkpmZ695Gm7kOIMnMzHU30maua/GZmeuum6cOSZIkraCqegB444D494ATBsQLOGeOY10GXDYgvgN4w7B1SJIkaXTD3knozHWS1CRZleTrSb7U1o9IcnMbGuHKJPu1+Avb+lTbfnjfMc5r8fuTnNQX39hiU0nO7YsPrEOSJEmSpHEYNkn4lqo6mt6jxOckees8ZZd15jrozV6XZEeSHbt27VrIrpI0ivcB9/Wtfwy4sA2N8DhwdoufDTxeVa8FLmzlSHIkcAbwenrDK3yyJR5XAZ+g19ceCZzZys5XhyRJkiRJizZUknCSZ65r7XL2OknLIsla4JfojZFFG0z/eODqVmQrvSEToDdkwta2fDVwQiu/Cbiiqn5UVd+mN9bWse01VVUPVNWPgSuATXuoQ5IkSZKkRdtjktCZ6yTpOX4P+E3g79v6wcATVfV0W+8fMuGZYRba9idb+YUOyzBfHZIkSZIkLdowE5e8CvhiL3/HauCPq+rLSW4FrkpyNvAgcHorfy1wCr07Y54C3g29meuSzMxcB8+fue4zwP70Jizpn7luUB2StOyS/DLwWFXdluRtM+EBRWsP2+aKD/rHzYKGZWjjxm4BOOywwwYVkSRJkiTpefaYJHTmOkl6xluAdyY5BXgRcAC9OwsPTLK63enXP2TCzDAL00lWAy8DdjP38AvMEf/uPHU8R1VdAlwCsH79+gWN7ypJkiRJ6q5hJy6RpM6rqvOqam1VHU5v4pGvVNW7gK8Cp7Vis4dfmBky4bRWvlr8jDb78RHAOuAWendar2szGe/X6tjW9pmrDkmSJEmSFs0koSQt3oeADyaZojd+4KUtfilwcIt/EDgXoKruAa4C7gW+DJxTVT9pdwm+l94YrvcBV7Wy89UhSZIkSdKiDTMmoSRplqq6EbixLT9Ab2bi2WV+yBxjqVbVBcAFA+LX0hvbdXZ8YB2SJEmSJI2DdxJKkiRJkiRJHWeSUJIkSZIkSeo4k4SSJEmSJElSx5kklCRJkiRJkjrOJKEkSZIkSZLUcSYJJUmSJEmSpI4zSShJkiRJkiR1nElCSZIkSZIkqeNMEkqSJEmSJEkdZ5JQkiRJkiRJ6jiThJIkSZIkSVLHmSSUJEmSJEmSOs4koSRJkiRJktRxJgklSZIkSZKkjjNJKEmSJEmSJHWcSUJJkiRJkiSp40wSSpIkSZIkSR1nklCSJEmSJEnqOJOEkiRJkiRJUseZJJQkSZIkSZI6ziShJEmSJEmS1HEmCSVJkiRJkqSOM0koSZKkkSRZleTrSb7U1o9IcnOSnUmuTLJfi7+wrU+17Yf3HeO8Fr8/yUl98Y0tNpXk3L74wDokSZK0OCYJJUmSNKr3Aff1rX8MuLCq1gGPA2e3+NnA41X1WuDCVo4kRwJnAK8HNgKfbInHVcAngJOBI4EzW9n56pAkSdIimCSUJEnSgiVZC/wS8Km2HuB44OpWZCtwalve1NZp209o5TcBV1TVj6rq28AUcGx7TVXVA1X1Y+AKYNMe6pAkSdIimCSUJEnSKH4P+E3g79v6wcATVfV0W58GDmnLhwAPAbTtT7byz8Rn7TNXfL46niPJliQ7kuzYtWvXqOcoSZLUGSYJJUmStCBJfhl4rKpu6w8PKFp72Dau+PODVZdU1fqqWr9mzZpBRSRJktRn6CShA1NLkiSpeQvwziTfofco8PH07iw8MMnqVmYt8HBbngYOBWjbXwbs7o/P2meu+HfnqUOSJEmLsJA7CR2YWpIkSVTVeVW1tqoOp3d995WqehfwVeC0VmwzcE1b3tbWadu/UlXV4me0fzIfAawDbgFuBda1fxjv1+rY1vaZqw5JkiQtwlBJQgemliRJ0hA+BHwwyRS98QMvbfFLgYNb/IPAuQBVdQ9wFXAv8GXgnKr6SRtz8L3A9fT+SX1VKztfHZIkSVqE1XsuAjw7MPVL2/rQA1Mn6R+Y+qa+Y/bvM3tg6uP2UMdzJNkCbAE47LDDhjwlSZIkLVZV3Qjc2JYfoPcP4NllfgicPsf+FwAXDIhfC1w7ID6wDkmSJC3OHu8kdGBqSZIkSZIkad82zJ2EMwNTnwK8CDiAvoGp251+gwamnh5yYGrmiD8zMPWAOiRJkiRJkiSNyR7vJHRgakmSJEmSJGnftpDZjWdzYGpJkiRJkiRpHzDsxCWAA1NLkiRJkiRJ+6LF3EkoSZIkSZIkaR9gklCSJEmSJEnqOJOEkiRJkiRJUseZJJSkISV5UZJbknwjyT1JfrvFj0hyc5KdSa5sM7XTZnO/MslU235437HOa/H7k5zUF9/YYlNJzu2LD6xDkiRJkqRxMEkoScP7EXB8Vb0ROArYmGQD8DHgwqpaBzwOnN3Knw08XlWvBS5s5UhyJHAG8HpgI/DJJKuSrAI+AZwMHAmc2coyTx2SJEmSJC2aSUJJGlL1/E1bfUF7FXA8cHWLbwVObcub2jpt+wlJ0uJXVNWPqurbwBS9mdyPBaaq6oGq+jFwBbCp7TNXHZIkSZIkLZpJQklagHbH3x3AY8B24FvAE1X1dCsyDRzSlg8BHgJo258EDu6Pz9pnrvjB89Qxu31bkuxIsmPXrl2LOVVJkiRJUoeYJJSkBaiqn1TVUcBaenf+/eygYu09c2wbV3xQ+y6pqvVVtX7NmjWDikiSJEmS9DwmCSVpBFX1BHAjsAE4MMnqtmkt8HBbngYOBWjbXwbs7o/P2meu+HfnqUOSJEmSpEUzSShJQ0qyJsmBbXl/4O3AfcBXgdNasc3ANW15W1unbf9KVVWLn9FmPz4CWAfcAtwKrGszGe9Hb3KTbW2fueqQJEmSJGnRVu+5iCSpeTWwtc1C/FPAVVX1pST3Alck+dfA14FLW/lLgT9KMkXvDsIzAKrqniRXAfcCTwPnVNVPAJK8F7geWAVcVlX3tGN9aI46JEmSJElaNJOEkjSkqroTeNOA+AP0xiecHf8hcPocx7oAuGBA/Frg2mHrkCRJkiRpHHzcWJIkSZIkSeo4k4SSJEmSJElSx5kklCRJkiRJkjrOJKEkSZIkSZLUcSYJJUmSJEmSpI4zSShJkiRJkiR1nElCSZIkSZIkqeNMEkqSJEmSJEkdZ5JQkiRJkiRJ6jiThJIkSZIkSVLHmSSUJEmSJEmSOs4koSRJkiRJktRxJgklSZIkSZKkjjNJKEmSJEmSJHWcSUJJkiQtWJIXJbklyTeS3JPkt1v8iCQ3J9mZ5Mok+7X4C9v6VNt+eN+xzmvx+5Oc1Bff2GJTSc7tiw+sQ5IkSaMzSShJkqRR/Ag4vqreCBwFbEyyAfgYcGFVrQMeB85u5c8GHq+q1wIXtnIkORI4A3g9sBH4ZJJVSVYBnwBOBo4EzmxlmacOSZIkjcgkoSRJkhasev6mrb6gvQo4Hri6xbcCp7blTW2dtv2EJGnxK6rqR1X1bWAKOLa9pqrqgar6MXAFsKntM1cdkiRJGtEek4Q+SiJJkqRB2h1/dwCPAduBbwFPVNXTrcg0cEhbPgR4CKBtfxI4uD8+a5+54gfPU0d/27Yk2ZFkx65duxZ7qpIkSfu8Ye4k9FESSZIkPU9V/aSqjgLW0rvz72cHFWvvmWPbuOKz23ZJVa2vqvVr1qwZ1HxJkiT12WOS0EdJJEmSNJ+qegK4EdgAHJhkddu0Fni4LU8DhwK07S8DdvfHZ+0zV/y789QhSZKkEQ01JuEkP0oiSZKk5ZdkTZID2/L+wNuB+4CvAqe1YpuBa9rytrZO2/6VqqoWP6MNWXMEsA64BbgVWNeGn9mP3hMp29o+c9UhSZKkEa3ec5HeoyTAUe1C8IuM91GSQYnKoR8lgd6YM8AWgMMOO2xQEUmSJI3Xq4GtbeiYnwKuqqovJbkXuCLJvwa+Dlzayl8K/FGSKXp3EJ4BUFX3JLkKuBd4GjinXXuS5L3A9cAq4LKquqcd60Nz1CFJkqQRDZUknFFVTyS5kb5HSdqdfoMeJZke8lES5og/8yjJgDpmt+sS4BKA9evXD0wkSpIkaXyq6k7gTQPiD9AbTmZ2/IfA6XMc6wLgggHxa4Frh61DkiRJoxtmdmMfJZEkSZIkSZL2YcPcSeijJJIkSZIkSdI+bI9JQh8lkSRJkiRJkvZtQ81uLEmSJEmSJGnfZZJQkiRJkiRJ6jiThJIkSZIkSVLHmSSUJEmSJEmSOs4koSRJkiRJktRxJgklSZIkSZKkjjNJKEmSJEmSJHWcSUJJkiRJkiSp40wSSpIkSZIkSR1nklCSJEmSJEnqOJOEkiRJkiRJUseZJJQkSZIkSZI6ziShJA0pyaFJvprkviT3JHlfi788yfYkO9v7QS2eJBclmUpyZ5Kj+461uZXfmWRzX/yYJHe1fS5KkvnqkCRJkiRpHEwSStLwngb+ZVX9LLABOCfJkcC5wA1VtQ64oa0DnAysa68twMXQS/gB5wPHAccC5/cl/S5uZWf229jic9UhSZIkSdKimSSUpCFV1SNVdXtb/gFwH3AIsAnY2optBU5ty5uAy6vnJuDAJK8GTgK2V9Xuqnoc2A5sbNsOqKqvVVUBl8861qA6JEmSJElaNJOEkjSCJIcDbwJuBl5VVY9AL5EIvLIVOwR4qG+36RabLz49IM48dUiSJEmStGgmCSVpgZL8NPAnwPur6vvzFR0QqxHiC2nbliQ7kuzYtWvXQnaVJEmSJHWYSUJJWoAkL6CXIPxsVX2hhR9tjwrT3h9r8Wng0L7d1wIP7yG+dkB8vjqeo6ouqar1VbV+zZo1o52kJEmSJKlzTBJK0pDaTMOXAvdV1b/t27QNmJmheDNwTV/8rDbL8Qbgyfao8PXAiUkOahOWnAhc37b9IMmGVtdZs441qA5JkiRJkhZt9Uo3QJL2Im8BfgW4K8kdLfa/Ah8FrkpyNvAgcHrbdi1wCjAFPAW8G6Cqdif5CHBrK/fhqtrdlt8DfAbYH7iuvZinDkmSJEmSFs0koSQNqar+nMHjBgKcMKB8AefMcazLgMsGxHcAbxgQ/96gOiRJkiRJGgcfN5YkSZIkSZI6ziShJEmSJEmS1HEmCSVJkiRJkqSOM0koSZIkSZIkdZxJQkmSJEmSJKnjTBJKkiRJkiRJHWeSUJIkSZIkSeo4k4SSJElasCSHJvlqkvuS3JPkfS3+8iTbk+xs7we1eJJclGQqyZ1Jju471uZWfmeSzX3xY5Lc1fa5KEnmq0OSJEmjM0koSZKkUTwN/Muq+llgA3BOkiOBc4EbqmodcENbBzgZWNdeW4CLoZfwA84HjgOO/f/bu/dgy8ryzuPfX4H3iEAAozQJmiFWoVWJ2AWoY4aSoWlIYuuMVmEy0jFOMV6oGp2yJjBWRkerUjjjOBPUwUHSETIK3pUxOG3HmDIXQFsEAQmhQSJHEFrbIGrFaHzmj/Ue3Zze+9z35Zz1/VSt2nu/6/K8716r37P6efdaC3jjQNLvkrbs/HrbW/moGJIkSVqlJZOEjhJLkiRpoaq6r6puaO8fAm4DjgV2AJe3xS4HXtje7wCuqM51wOFJngScCeypqgNV9W1gD7C9zTusqq6tqgKuWLCtYTEkSZK0Ssv5JaGjxJIkSRopyfHAM4HrgSdW1X3QJRKBY9pixwL3DKw218oWK58bUs4iMQbrdF6SvUn27t+/fy3NkyRJ6oUlk4SOEkuSJGmUJD8DfAR4bVV9Z7FFh5TVKsqXpaouraqtVbX16KOPXu5qkiRJvbWiexLO4iixJEmSpiPJI+gShO+rqo+24vvbIDDt9YFWPgccN7D6FuDeJcq3DClfLIYkSZJWadlJwlkdJW5183ISSZKkCWr3kP5D4LaqevvArKuB+XtP7wQ+MVB+brt/9anAg20QeDewLckR7VY024Ddbd5DSU5tsc5dsK1hMSRJkrRKy0oSzvoosZeTSJIkTdxzgZcBz09yY5vOBi4CzkhyB3BG+wxwDXAXsA94D/BqgKo6ALwF+EKb3tzKAF4FXNbWuRP4VCsfFUOSJEmrdOhSCyxjlPgiDh4lPj/JVXQPKXmwqu5Lshv4/YGHlWwDLqyqA0keaiPK19ONEr9jiRiSJEmaoqr6S4ZfEQJw+pDlC3jNiG3tAnYNKd8LPGNI+beGxZAkSdLqLZkk5KejxDcnubGV/Se6xN0Hk7wC+BrwkjbvGuBsuhHf7wMvh26UOMn8KDEcPEr8XuAxdCPEg6PEw2JIkiRJkiRJWidLJgkdJZakze/913/toLLfPOXnp1ATSZIkSdI0rOjpxpIkSZIkSZI2H5OEkiRJkiRJUs+ZJJQkSZIkSZJ6ziShJEmSJEmS1HMmCSVJkiRJkqSeM0koSZIkSZIk9ZxJQkmSJEmSJKnnTBJKkiRJkiRJPWeSUJIkSZIkSeo5k4SSJEmSJElSz5kklCRJkiRJknrOJKEkSZIkSZLUcyYJJUmSJEmSpJ4zSShJkiRJkiT1nElCSZIkSZIkqedMEkqSJEmSJEk9Z5JQkiRJkiRJ6jmThJIkSZIkSVLPmSSUJEmSJEmSes4koSRJkiRJktRzJgklSZIkSZKknjNJKEkrkGRXkgeS3DJQdmSSPUnuaK9HtPIkuTjJviRfTnLSwDo72/J3JNk5UP6sJDe3dS5OksViSJIkSZK0HkwSStLKvBfYvqDsAuAzVXUC8Jn2GeAs4IQ2nQdcAl3CD3gjcApwMvDGgaTfJW3Z+fW2LxFDkiRJkqQ1M0koSStQVZ8DDiwo3gFc3t5fDrxwoPyK6lwHHJ7kScCZwJ6qOlBV3wb2ANvbvMOq6tqqKuCKBdsaFkOSJEmSpDUzSShJa/fEqroPoL0e08qPBe4ZWG6ulS1WPjekfLEYD5PkvCR7k+zdv3//mholSZIkSeoPk4SSND4ZUlarKF+2qrq0qrZW1dajjz56JatKkiRJknrMJKEkrd397VJh2usDrXwOOG5guS3AvUuUbxlSvlgMSZIkSZLWzCShJK3d1cD8E4p3Ap8YKD+3PeX4VODBdqnwbmBbkiPaA0u2AbvbvIeSnNqeanzugm0NiyFJkiRJ0pqZJJSkFUhyJXAt8LQkc0leAVwEnJHkDuCM9hngGuAuYB/wHuDVAFV1AHgL8IU2vbmVAbwKuKytcyfwqVY+KoYkTUWSXUkeSHLLQNmRSfYkuaO9HtHKk+TiJPuSfDnJSQPr7GzL35Fk50D5s5Lc3Na5uA2ejIwhSZKktTl02hWQpI2kql46YtbpQ5Yt4DUjtrML2DWkfC/wjCHl3xoWQ5Km6L3AO+mexD7vAuAzVXVRkgva598FzgJOaNMpwCXAKUmOBN4IbKW7B+sXk1zdnvx+CXAecB3doMt2uoGTUTEkSZK0Bkv+ktBRYkmSJC1UVZ8DDiwo3gFc3t5fDrxwoPyK6lwHHN7ur3omsKeqDrTE4B5ge5t3WFVd2wZcrliwrWExJEmStAbLudz4vXQjt4PmR3BPAD7TPsPDR4nPoxsBZmCU+BTgZOCNA0m/+VHi+fW2LxFDkiRJs+mJ7f6qtNdjWvmxwD0Dy821ssXK54aULxZDkiRJa7BkktBRYkmSJK1RhpTVKsqXHzA5L8neJHv379+/klUlSZJ6abUPLpmpUWJPAiVJkmbC/W0QmPb6QCufA44bWG4LcO8S5VuGlC8W42Gq6tKq2lpVW48++ug1NUqSJKkP1vvpxhMfJQZPAiVJkmbE1cD8vad3Ap8YKD+33b/6VODBNgi8G9iW5Ih2K5ptwO4276Ekp7b7VZ+7YFvDYkiSJGkNVpsknJlRYkmSJE1ekiuBa4GnJZlL8grgIuCMJHcAZ7TP0D2d+C5gH/Ae4NUAVXUAeAvwhTa9uZUBvAq4rK1zJ92TjVkkhiRJktbg0FWuNz+CexEHjxKfn+QquoeUPFhV9yXZDfz+wMNKtgEXVtWBJA+1EeXr6UaJ37FEDEmSJE1ZVb10xKzThyxbwGtGbGcXsGtI+V7gGUPKvzUshiRJktZmySRhGyU+DTgqyRzdU4ovAj7YRoy/BrykLX4NcDbdiO/3gZdDN4wrN4gAAA+8SURBVEqcZH6UGA4eJX4v8Bi6EeLBUeJhMSRJkiRJkiStoyWThI4SS5IkSZIkSZvbej+4RJIkSZIkSdIGY5JQkiRJkiRJ6jmThJIkSZIkSVLPmSSUJEmSJEmSes4koSRJkiRJktRzJgklSZIkSZKknjNJKEmSJEmSJPWcSUJJkiRJkiSp50wSSpIkSZIkST1nklCSJEmSJEnqOZOEkiRJkiRJUs+ZJJQkSZIkSZJ6ziShJEmSJEmS1HMmCSVJkiRJkqSeM0koSZIkSZIk9ZxJQkmSJEmSJKnnTBJKkiRJkiRJPWeSUJIkSZIkSeo5k4SSJEmSJElSz5kklCRJkiRJknrOJKEkSZIkSZLUcyYJJUmSJEmSpJ4zSShJkiRJkiT1nElCSZIkSZIkqedMEkqSJEmSJEk9d+i0KyBJkiRtdO+//msHlf3mKT8/hZpIkiStjr8klCRJkiRJknrOJKEkSZIkSZLUcyYJJUmSJEmSpJ6b+SRhku1Jbk+yL8kF066PJE2TfaIkdewPJUmS1tdMJwmTHAK8CzgLOBF4aZITp1srSZoO+0RJ6tgfSpIkrb9Zf7rxycC+qroLIMlVwA7gK1OtlSRNh32iJHU2bX/oU5IlSdK0zHqS8FjgnoHPc8Ap4wy48MTMkzJJM2TifeK42NdKWqNN0x+uF/tVSZK0VrOeJMyQsjpooeQ84Lz28btJbl/m9o8CvrnYAr+1zA1tAEu2dROxrZvTUcAvTLsSU7Zkn7iG/vAgK+j/fnIcrrbPHFNfO6v/PmaxXrNYJ7Bei7E/PNh69ocP28dT6NvWHH+N/eq0j/Fpx5+FOhh/ZfH73idK0rqY9SThHHDcwOctwL0LF6qqS4FLV7rxJHurauvqq7dx2NbNqYdtPX7a9ZiyJfvE1faHazGrx6H1Wr5ZrBNYLy1qrP3htPex8af/b2zadTD+9I8BSeqjmX5wCfAF4IQkT0nySOAc4Oop10mSpsU+UZI69oeSJEnrbKZ/SVhVP0pyPrAbOATYVVW3TrlakjQV9omS1LE/lCRJWn8znSQEqKprgGvGtPmJXpI3ZbZ1c7KtPTPmPnG1ZnXfWK/lm8U6gfXSIjb5OaLxp2/adTC+JGniUnXQc0AkSZIkSZIk9cis35NQkiRJkiRJ0pj1NkmYZHuS25PsS3LBtOuzmCR3J7k5yY1J9rayI5PsSXJHez2ilSfJxa1dX05y0sB2drbl70iyc6D8WW37+9q6WSzGOrdtV5IHktwyUDa1ti0WY4ztfVOSr7f9e2OSswfmXdjqcnuSMwfKhx6/7Qbu17d2faDdzJ0kj2qf97X5xy8VY43tPC7JZ5PcluTWJP++lW/afdsHo467gfkjj7Mx1mnosbZgmdOSPDjwb+w/j7teLe5BffeC+RM9JpM8beA7uDHJd5K8dsEyE/muRvSFy/qbM6pPGGO9/luSv2n76GNJDh+x7qL7WxvDUv3cBOIv2adNqB6HJPlSkk9OIfbhST7c/t3dluTZE47/uvbd35LkyiSPnkDMVfeJY4y/rL5vXPEH5r0+SSU5alzxJUkDqqp3E90Nru8Engo8ErgJOHHa9VqkvncDRy0o+6/ABe39BcBb2/uzgU8BAU4Frm/lRwJ3tdcj2vsj2rzPA89u63wKOGuxGOvctl8FTgJumYW2jYox5va+CXj9kGVPbMfmo4CntGP2kMWOX+CDwDnt/buBV7X3rwbe3d6fA3xgsRjr0M4nASe1948H/rbF2rT7drNPix13A8sMPc7GXK+hx9qCZU4DPjmF7+xuFvTdC+ZP7Zhs+/MbwC9M47sa0Rcu+TdnsT5hjPXaBhza3r91WL2Ws7+dZn9aTj83gTos2adNqB7/AXj/lPrOy4F/294/Ejh8grGPBb4KPKZ9/iDw2xOIu6o+cczxl9X3jSt+Kz+O7uFEf2f/6uTk5DSZqa+/JDwZ2FdVd1XVPwJXATumXKeV2kF3EkV7feFA+RXVuQ44PMmTgDOBPVV1oKq+DewBtrd5h1XVtVVVwBULtjUsxrqpqs8BB2aobaNijLO9o+wArqqqH1TVV4F9dMfu0OM3SYDnAx9u6y9s13x7Pwyc3pYfFWNNquq+qrqhvX8IuI3uxHvT7tseWE6/Oeo4G5tFjrWNYJrH5OnAnVX1dxOK9zAr7PsHDe0Txlmvqvp0Vf2ofbwO2LJe8TRzpn5+OAt9WpItwK8Bl00ybot9GF3C6A8Bquofq+rvJ1yNQ4HHJDkUeCxw77gDrqFPHFv8SfZ9i5wf/w/gPwLeRF+SJqSvScJjgXsGPs8x2/+pLODTSb6Y5LxW9sSqug+6E0rgmFY+qm2Llc8NKV8sxrhNs23TOjbOb5dz7Bq4nGSl7f1Z4O8HTugG6/6Tddr8B9vyY29vu+T0mcD19HPfbhbL+f5GHWcTseBYW+jZSW5K8qkkT59QlYb13YOmeUyeA1w5Yt40vitY3t+caf87/h26X38Os9T+1uyb9vH1MEv0aeP0P+kSMz+ecFzofsW5H/ijdrnzZUkeN6ngVfV14G3A14D7gAer6tOTir/AtM7Dh1ms7xuLJC8Avl5VN00yriT1XV+ThMN+2TLLI1TPraqTgLOA1yT51UWWHdW2lZbPokm0bRrfxyXALwK/QndC+t+XqMtq2juV/Z/kZ4CPAK+tqu8stuiIemz0fbuZLOf7m9p3vMSxdgPdZbW/DLwD+Pgk6sTSffdUvq909yp9AfChIbOn9V0t1zSPsTcAPwLeN2KRlfyt1myamb8TK/j7ud5xfx14oKq+OKmYCxxKd9npJVX1TOB7dJfaTkQbqN1BdwuWJwOPS/JvJhV/Fi2j7xtHzMcCbwAmcg9hSdJP9TVJOEd3j4t5W5jApQSrVVX3ttcHgI/RXQ5z//xlae31gbb4qLYtVr5lSDmLxBi3abZt4sdGVd1fVf9UVT8G3sNPL/ddaXu/SXe54qFD6v6Tddr8J9Bd1jG29iZ5BN1/cN5XVR9txb3at5vMcr6/UcfZWI041n6iqr5TVd9t768BHjGJG6CP6LsHTeuYPAu4oaruXzhjWt9Vs5y/OVP5ztI9IOXXgd9qtzg4yDL2t2bfTPydWKpPG7PnAi9Icjfd5dbPT/J/Jhh/DpirqvlfT36YLmk4Kf8S+GpV7a+qHwIfBZ4zwfiDpnUe/hPL6fvG5BfpErU3tWNxC3BDkp+bYB0kqZf6miT8AnBCuifBPpLusqurp1ynoZI8Lsnj59/T3UT4Frr6zj/VcSfwifb+auDcdE6lu0ziPrqb/m5LckQbJd0G7G7zHkpyart32LkLtjUsxrhNs22jYozNgnuQvYhu/87X5Zx0T4x9CnAC3cM6hh6/7eTts8CLR7Rrvr0vBv6sLT8qxlrbFLr7Cd1WVW8fmNWrfbvJLKffHHWcjc0ix9rgMj/XliPJyXR/+7415nqN6rsHTeuYfCkjLjWexnc1YDl/c4b2CeOsVJLtwO8CL6iq749YZjn7W7Nv6ueHy+nTxqmqLqyqLVV1PF37/6yqJvZLuqr6BnBPkqe1otOBr0wqPt1lxqcmeWzbF6fT3RdyGqZ1Hg4sr+8bl6q6uaqOqarj27E4R/dAn29Msh6S1Es1A09PmcZE91TJv6V7it0bpl2fRer5VLqn690E3DpfV7r7fH0GuKO9HtnKA7yrtetmYOvAtn6H7sEU+4CXD5RvpfvPzJ3AO4EsFmOd23cl3SW2P6Q7AXjFNNu2WIwxtvePW6wv050QPmlg+Te0utxOe3rvYsdvO14+376HDwGPauWPbp/3tflPXSrGGtv5z+ku0foycGObzt7M+7YP07DjDngz3X8gFj3OxlinUcfaK4FXtmXOp+s/b6K7+fpzJlCvUX33YL0mfkzS3YT/W8ATBsom/l2xsr5/K3DZwLpD+4Qx1msf3X3q5o+v+Sd4Pxm4ZrH97bTxpmH93ITjD+3TpvRdnMZ0nm78K8De9h18nHV8gvky4/8X4G/ozjH+mHYuNeaYy+4TJxh/aN83qfgL5t+NTzd2cnJymsg0/59qSZIkSZIkST3V18uNJUmSJEmSJDUmCSVJkiRJkqSeM0koSZIkSZIk9ZxJQkmSJEmSJKnnTBJKkiRJkiRJPWeSUJIkSZIkSeo5k4SaaUmOT3JLe781ycXt/WlJnrPKbb4kya1Jfpxk64J5FybZl+T2JGeuvQWStH4m2Scm+dkkn03y3STvXJ8WSNL6mHB/eEaSLya5ub0+f31aIUnSbDl02hWQlquq9gJ728fTgO8Cf72KTd0C/Cvgfw8WJjkROAd4OvBk4E+T/FJV/dNq6yxJ4zLuPhH4B+D3gGe0SZJm0gT6w28Cv1FV9yZ5BrAbOHZ1tZUkaXb5S0KNTZI3tF/k/WmSK5O8Psmfz4/MJjkqyd3t/fFJ/iLJDW06aAS4jQx/MsnxwCuB1yW5Mcnzknw1ySPacocluXv+80JVdVtV3T5k1g7gqqr6QVV9FdgHnLwOX4Ukbbg+saq+V1V/SZcslKR1swH7wy9V1b3t463Ao5M8ah2+CkmSZoq/JNRYJHkW3a/ynkl3nN0AfHGRVR4Azqiqf0hyAnAlsHXYglV1d5J3A9+tqre1eH8O/Brw8Rb3I1X1wxVW+1jguoHPczhKLGkdbNA+UZLW3SboD/818KWq+sEatiFJ0kzyl4Qal+cBH6uq71fVd4Crl1j+EcB7ktwMfAg4cYXxLgNe3t6/HPijFa4PkCFltYrtSNJCG7FPlKRx2LD9YZKnA28F/t1qtyFJ0izzl4Qap2EJth/x0+T0owfKXwfcD/xym7+iy9uq6q/a5Sj/Ajikqm5ZRX3ngOMGPm8B7h2xrCSt1EbrEyVpXDZcf5hkC/Ax4NyqunM125Akadb5S0KNy+eAFyV5TJLHA7/Ryu8GntXev3hg+ScA91XVj4GXAYcssf2HgMcvKLuC7hKU1Y4QXw2ck+RRSZ4CnAB8fpXbkqRBG7FPlKRx2HD9YZLDgT8BLqyqv1rNNiRJ2ghMEmosquoG4APAjcBHgL9os94GvCrJXwNHDazyv4CdSa4Dfgn43hIh/i/dCeaNSZ7Xyt4HHEF3EjhSkhclmQOeDfxJkt2tzrcCHwS+Avw/4DU+2VjSetiIfWKbdzfwduC3k8y1p8BL0qpt0P7wfOCfAb/XtntjkmOW0VxJkjaUVHnLNY1fkjcxcBPpMcV4MbCjql42rhiStB7sEyWpY38oSdLs8J6E2hSSvAM4Czh72nWRpGmzT5Skjv2hJEnL5y8JtWkleRfw3AXFf1BV3p9LUu/YJ0pSx/5QkqThTBJKkiRJkiRJPeeDSyRJkiRJkqSeM0koSZIkSZIk9ZxJQkmSJEmSJKnnTBJKkiRJkiRJPWeSUJIkSZIkSeq5/w+vKDcZxCRDEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1296x1152 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_col = ['quality_' + str(i) for i in range(3)] + ['quality_' + str(i) for i in range(5, 13)]\n",
    "qual_ = new_train_qual[num_col].copy()\n",
    "\n",
    "fig = plt.figure(figsize=(18,16))\n",
    "for index,col in enumerate(num_col):\n",
    "    plt.subplot(3,4,index+1)\n",
    "    sns.distplot(qual_.loc[:,col].dropna(), kde=False)\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0     0.811259\n",
       "-1     0.185462\n",
       " 1     0.002930\n",
       " 2     0.000245\n",
       " 3     0.000060\n",
       " 4     0.000023\n",
       " 5     0.000010\n",
       " 6     0.000006\n",
       " 14    0.000001\n",
       " 9     0.000001\n",
       " 8     0.000001\n",
       " 7     0.000001\n",
       "Name: quality_11, dtype: float64"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "new_train_qual['quality_11'].value_counts() / np.float(len(new_train_qual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1080 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14,15))\n",
    "for index,col in enumerate(num_col):\n",
    "    plt.subplot(3,4,index+1)\n",
    "    sns.boxplot(y=col, data=qual_.dropna())\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix - train_qual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4b468d6ef0>"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "correlation = qual_.corr()\n",
    "sns.heatmap(correlation, mask = correlation <0.8, linewidth=0.5, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying relationship between Numerical Predictor and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>10001</td>\n",
       "      <td>20201113190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>10004</td>\n",
       "      <td>20201104120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>10005</td>\n",
       "      <td>20201113120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>10006</td>\n",
       "      <td>20201110170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4243</th>\n",
       "      <td>10008</td>\n",
       "      <td>20201124130000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id            time\n",
       "1116    10001  20201113190000\n",
       "492     10004  20201104120000\n",
       "3857    10005  20201113120000\n",
       "414     10006  20201110170000\n",
       "4243    10008  20201124130000"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_prob = train_prob.sort_values(by='time').drop_duplicates(subset='user_id')\n",
    "new_train_prob = new_train_prob.sort_values(by='user_id')\n",
    "new_train_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fwver</th>\n",
       "      <th>time</th>\n",
       "      <th>quality_0</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_6</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "      <th>quality_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       fwver            time  quality_0  quality_1  quality_2  \\\n",
       "0    10000  05.15.2138  20201129090000        0.0          0        0.0   \n",
       "1    10000  05.15.2138  20201129090000        0.0          0        0.0   \n",
       "2    10000  05.15.2138  20201129090000        0.0          0        0.0   \n",
       "3    10000  05.15.2138  20201129090000        0.0          0        0.0   \n",
       "4    10000  05.15.2138  20201129090000        0.0          0        0.0   \n",
       "\n",
       "   quality_5  quality_6  quality_7  quality_8  quality_9  quality_10  \\\n",
       "0        0.0          0        0.0        0.0        0.0         4.0   \n",
       "1        0.0          0        0.0        0.0        0.0         4.0   \n",
       "2        0.0          0        0.0        0.0        0.0         4.0   \n",
       "3        0.0          0        0.0        0.0        0.0         4.0   \n",
       "4        0.0          0        0.0        0.0        0.0         4.0   \n",
       "\n",
       "   quality_11  quality_12  \n",
       "0           0           0  \n",
       "1           0           0  \n",
       "2           0           0  \n",
       "3           0           0  \n",
       "4           0           0  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_qual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fwver</th>\n",
       "      <th>quality_0</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_6</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "      <th>quality_12</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       fwver  quality_0  quality_1  quality_2  quality_5  quality_6  \\\n",
       "0    10000  05.15.2138        0.0          0        0.0        0.0          0   \n",
       "1    10000  05.15.2138        0.0          0        0.0        0.0          0   \n",
       "2    10000  05.15.2138        0.0          0        0.0        0.0          0   \n",
       "3    10000  05.15.2138        0.0          0        0.0        0.0          0   \n",
       "4    10000  05.15.2138        0.0          0        0.0        0.0          0   \n",
       "\n",
       "   quality_7  quality_8  quality_9  quality_10  quality_11  quality_12  \\\n",
       "0        0.0        0.0        0.0         4.0           0           0   \n",
       "1        0.0        0.0        0.0         4.0           0           0   \n",
       "2        0.0        0.0        0.0         4.0           0           0   \n",
       "3        0.0        0.0        0.0         4.0           0           0   \n",
       "4        0.0        0.0        0.0         4.0           0           0   \n",
       "\n",
       "             DateTime  \n",
       "0 2020-11-29 09:00:00  \n",
       "1 2020-11-29 09:00:00  \n",
       "2 2020-11-29 09:00:00  \n",
       "3 2020-11-29 09:00:00  \n",
       "4 2020-11-29 09:00:00  "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnew_train_qual = new_train_qual.copy()\n",
    "nnew_train_qual['DateTime'] = pd.to_datetime(nnew_train_qual['time'].astype(str), format='%Y%m%d%H%M%S')\n",
    "del nnew_train_qual['time']\n",
    "nnew_train_qual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>10001</td>\n",
       "      <td>2020-11-13 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>10004</td>\n",
       "      <td>2020-11-04 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>10005</td>\n",
       "      <td>2020-11-13 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>10006</td>\n",
       "      <td>2020-11-10 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4243</th>\n",
       "      <td>10008</td>\n",
       "      <td>2020-11-24 13:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id            DateTime\n",
       "1116    10001 2020-11-13 19:00:00\n",
       "492     10004 2020-11-04 12:00:00\n",
       "3857    10005 2020-11-13 12:00:00\n",
       "414     10006 2020-11-10 17:00:00\n",
       "4243    10008 2020-11-24 13:00:00"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnew_train_prob = new_train_prob.copy()\n",
    "nnew_train_prob['DateTime'] = pd.to_datetime(nnew_train_prob['time'].astype(str), format='%Y%m%d%H%M%S')\n",
    "del nnew_train_prob['time']\n",
    "nnew_train_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fwver</th>\n",
       "      <th>quality_0</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_6</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "      <th>quality_12</th>\n",
       "      <th>DateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       fwver  quality_0  quality_1  quality_2  quality_5  quality_6  \\\n",
       "0    10000  05.15.2138        0.0          0        0.0        0.0          0   \n",
       "1    10000  05.15.2138        0.0          0        0.0        0.0          0   \n",
       "2    10000  05.15.2138        0.0          0        0.0        0.0          0   \n",
       "3    10000  05.15.2138        0.0          0        0.0        0.0          0   \n",
       "4    10000  05.15.2138        0.0          0        0.0        0.0          0   \n",
       "\n",
       "   quality_7  quality_8  quality_9  quality_10  quality_11  quality_12  \\\n",
       "0        0.0        0.0        0.0         4.0           0           0   \n",
       "1        0.0        0.0        0.0         4.0           0           0   \n",
       "2        0.0        0.0        0.0         4.0           0           0   \n",
       "3        0.0        0.0        0.0         4.0           0           0   \n",
       "4        0.0        0.0        0.0         4.0           0           0   \n",
       "\n",
       "             DateTime  \n",
       "0 2020-11-29 09:00:00  \n",
       "1 2020-11-29 09:00:00  \n",
       "2 2020-11-29 09:00:00  \n",
       "3 2020-11-29 09:00:00  \n",
       "4 2020-11-29 09:00:00  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnew_train_qual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fwver</th>\n",
       "      <th>quality_0</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_6</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "      <th>quality_12</th>\n",
       "      <th>DateTime_x</th>\n",
       "      <th>DateTime_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       fwver  quality_0  quality_1  quality_2  quality_5  quality_6  \\\n",
       "0    10000  05.15.2138        0.0        0.0        0.0        0.0        0.0   \n",
       "1    10000  05.15.2138        0.0        0.0        0.0        0.0        0.0   \n",
       "2    10000  05.15.2138        0.0        0.0        0.0        0.0        0.0   \n",
       "3    10000  05.15.2138        0.0        0.0        0.0        0.0        0.0   \n",
       "4    10000  05.15.2138        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   quality_7  quality_8  quality_9  quality_10  quality_11  quality_12  \\\n",
       "0        0.0        0.0        0.0         4.0         0.0         0.0   \n",
       "1        0.0        0.0        0.0         4.0         0.0         0.0   \n",
       "2        0.0        0.0        0.0         4.0         0.0         0.0   \n",
       "3        0.0        0.0        0.0         4.0         0.0         0.0   \n",
       "4        0.0        0.0        0.0         4.0         0.0         0.0   \n",
       "\n",
       "           DateTime_x DateTime_y  \n",
       "0 2020-11-29 09:00:00        NaT  \n",
       "1 2020-11-29 09:00:00        NaT  \n",
       "2 2020-11-29 09:00:00        NaT  \n",
       "3 2020-11-29 09:00:00        NaT  \n",
       "4 2020-11-29 09:00:00        NaT  "
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge = pd.merge(nnew_train_qual, nnew_train_prob, how='outer', on='user_id')\n",
    "train_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((828624, 14), (5000, 2))"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnew_train_qual.shape, nnew_train_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(828624, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fwver</th>\n",
       "      <th>quality_0</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_6</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "      <th>quality_12</th>\n",
       "      <th>DateTime_x</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-29 09:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       fwver  quality_0  quality_1  quality_2  quality_5  quality_6  \\\n",
       "0    10000  05.15.2138        0.0        0.0        0.0        0.0        0.0   \n",
       "1    10000  05.15.2138        0.0        0.0        0.0        0.0        0.0   \n",
       "2    10000  05.15.2138        0.0        0.0        0.0        0.0        0.0   \n",
       "3    10000  05.15.2138        0.0        0.0        0.0        0.0        0.0   \n",
       "4    10000  05.15.2138        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   quality_7  quality_8  quality_9  quality_10  quality_11  quality_12  \\\n",
       "0        0.0        0.0        0.0         4.0         0.0         0.0   \n",
       "1        0.0        0.0        0.0         4.0         0.0         0.0   \n",
       "2        0.0        0.0        0.0         4.0         0.0         0.0   \n",
       "3        0.0        0.0        0.0         4.0         0.0         0.0   \n",
       "4        0.0        0.0        0.0         4.0         0.0         0.0   \n",
       "\n",
       "           DateTime_x  prob  \n",
       "0 2020-11-29 09:00:00     0  \n",
       "1 2020-11-29 09:00:00     0  \n",
       "2 2020-11-29 09:00:00     0  \n",
       "3 2020-11-29 09:00:00     0  \n",
       "4 2020-11-29 09:00:00     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_merge['prob_a'] = train_merge['DateTime_y'].isnull() != True \n",
    "train_merge['prob_b'] = train_merge['DateTime_x'] > train_merge['DateTime_y']\n",
    "train_merge['prob'] = train_merge['prob_a'] & train_merge['prob_b']\n",
    "train_merge['prob'] = train_merge['prob'].astype('int')\n",
    "\n",
    "del train_merge['prob_a']\n",
    "del train_merge['prob_b']\n",
    "del train_merge['DateTime_y']\n",
    "\n",
    "train_merge = train_merge[:828624]\n",
    "\n",
    "print(train_merge.shape)\n",
    "display(train_merge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_merge.set_index(['prob', 'fwver']).loc[0].index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_merge.set_index(['prob', 'fwver']).loc[1].index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_merge['fwver'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>quality_0</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_6</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "      <th>quality_12</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fwver</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>03.11.1149</th>\n",
       "      <td>20034.941176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.009804</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.269608</td>\n",
       "      <td>-0.009804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>3.352941</td>\n",
       "      <td>-0.009804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03.11.1167</th>\n",
       "      <td>17646.546952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.108951</td>\n",
       "      <td>8.602863</td>\n",
       "      <td>32.112647</td>\n",
       "      <td>0.828120</td>\n",
       "      <td>11.500058</td>\n",
       "      <td>0.255214</td>\n",
       "      <td>104.796981</td>\n",
       "      <td>386.914391</td>\n",
       "      <td>-0.106675</td>\n",
       "      <td>0.282521</td>\n",
       "      <td>0.134117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.16.3345</th>\n",
       "      <td>23726.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.833333</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.16.3439</th>\n",
       "      <td>20813.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.16.3553</th>\n",
       "      <td>17455.935069</td>\n",
       "      <td>-0.172872</td>\n",
       "      <td>-0.157845</td>\n",
       "      <td>-0.064637</td>\n",
       "      <td>49.769608</td>\n",
       "      <td>3.354995</td>\n",
       "      <td>42.334298</td>\n",
       "      <td>0.180221</td>\n",
       "      <td>1.299046</td>\n",
       "      <td>599.309761</td>\n",
       "      <td>-0.172703</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.182471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.16.3571</th>\n",
       "      <td>17367.145161</td>\n",
       "      <td>-0.165771</td>\n",
       "      <td>-0.152330</td>\n",
       "      <td>-0.165771</td>\n",
       "      <td>8.394713</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>2.806452</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.725806</td>\n",
       "      <td>-0.165771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.327957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.22.1442</th>\n",
       "      <td>23842.000000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.22.1656</th>\n",
       "      <td>19831.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.083333</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.22.1666</th>\n",
       "      <td>19592.000000</td>\n",
       "      <td>-0.003145</td>\n",
       "      <td>-0.001572</td>\n",
       "      <td>-0.003145</td>\n",
       "      <td>3.073899</td>\n",
       "      <td>-0.003145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.924528</td>\n",
       "      <td>-0.003145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.22.1684</th>\n",
       "      <td>13341.564912</td>\n",
       "      <td>-0.003216</td>\n",
       "      <td>-0.002924</td>\n",
       "      <td>-0.003216</td>\n",
       "      <td>6.439766</td>\n",
       "      <td>1.128070</td>\n",
       "      <td>13.575439</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.315789</td>\n",
       "      <td>-0.003216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.22.1750</th>\n",
       "      <td>17647.996705</td>\n",
       "      <td>-0.193625</td>\n",
       "      <td>-0.186437</td>\n",
       "      <td>-0.193625</td>\n",
       "      <td>116.878478</td>\n",
       "      <td>0.974358</td>\n",
       "      <td>14.015799</td>\n",
       "      <td>0.086262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1404.786161</td>\n",
       "      <td>-0.193506</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.201504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.22.1778</th>\n",
       "      <td>17863.565448</td>\n",
       "      <td>-0.198594</td>\n",
       "      <td>-0.183896</td>\n",
       "      <td>-0.198594</td>\n",
       "      <td>130.867314</td>\n",
       "      <td>0.401084</td>\n",
       "      <td>7.196133</td>\n",
       "      <td>0.176371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1572.568423</td>\n",
       "      <td>-0.197213</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>0.384190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.33.1125</th>\n",
       "      <td>23952.083333</td>\n",
       "      <td>-0.347222</td>\n",
       "      <td>-0.340278</td>\n",
       "      <td>-0.347222</td>\n",
       "      <td>-0.027778</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>-0.347222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.33.1149</th>\n",
       "      <td>16860.820896</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.159204</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>9.007463</td>\n",
       "      <td>2.360697</td>\n",
       "      <td>30.328358</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.089552</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.731343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.33.1185</th>\n",
       "      <td>17153.824064</td>\n",
       "      <td>-0.190007</td>\n",
       "      <td>-0.181828</td>\n",
       "      <td>-0.190007</td>\n",
       "      <td>80.396756</td>\n",
       "      <td>0.973797</td>\n",
       "      <td>13.965649</td>\n",
       "      <td>0.098146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>967.026536</td>\n",
       "      <td>-0.188023</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.109051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.33.1261</th>\n",
       "      <td>17460.899132</td>\n",
       "      <td>-0.216827</td>\n",
       "      <td>-0.201378</td>\n",
       "      <td>-0.216827</td>\n",
       "      <td>67.633706</td>\n",
       "      <td>1.632298</td>\n",
       "      <td>22.189493</td>\n",
       "      <td>0.185381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>814.187848</td>\n",
       "      <td>-0.215037</td>\n",
       "      <td>0.021471</td>\n",
       "      <td>0.371128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.73.2237</th>\n",
       "      <td>16874.500000</td>\n",
       "      <td>-0.218750</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>-0.218750</td>\n",
       "      <td>95.765625</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>3.187500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1151.812500</td>\n",
       "      <td>-0.218750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.73.2571</th>\n",
       "      <td>22880.000000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.82.1684</th>\n",
       "      <td>18283.896552</td>\n",
       "      <td>-0.261494</td>\n",
       "      <td>-0.246169</td>\n",
       "      <td>-0.261494</td>\n",
       "      <td>7.192529</td>\n",
       "      <td>3.125479</td>\n",
       "      <td>40.643678</td>\n",
       "      <td>0.183908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.448276</td>\n",
       "      <td>-0.261494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.82.1778</th>\n",
       "      <td>17932.166667</td>\n",
       "      <td>-0.189815</td>\n",
       "      <td>-0.175926</td>\n",
       "      <td>-0.189815</td>\n",
       "      <td>0.412037</td>\n",
       "      <td>-0.087963</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.222222</td>\n",
       "      <td>-0.189815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2114</th>\n",
       "      <td>23476.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.729167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>416.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2120</th>\n",
       "      <td>19183.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>7.178571</td>\n",
       "      <td>86.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2122</th>\n",
       "      <td>19278.000000</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.200000</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>17769.448578</td>\n",
       "      <td>17.910338</td>\n",
       "      <td>-0.169681</td>\n",
       "      <td>17.908335</td>\n",
       "      <td>85.623251</td>\n",
       "      <td>4.598955</td>\n",
       "      <td>57.360362</td>\n",
       "      <td>0.136735</td>\n",
       "      <td>217.072925</td>\n",
       "      <td>1029.651915</td>\n",
       "      <td>-0.179715</td>\n",
       "      <td>0.016320</td>\n",
       "      <td>0.191869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.66.3237</th>\n",
       "      <td>14926.673913</td>\n",
       "      <td>-0.289855</td>\n",
       "      <td>-0.278986</td>\n",
       "      <td>-0.289855</td>\n",
       "      <td>0.563406</td>\n",
       "      <td>0.300725</td>\n",
       "      <td>7.086957</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.239130</td>\n",
       "      <td>-0.289855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.66.3571</th>\n",
       "      <td>18191.375000</td>\n",
       "      <td>-0.104167</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.104167</td>\n",
       "      <td>4.791667</td>\n",
       "      <td>2.510417</td>\n",
       "      <td>31.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.750000</td>\n",
       "      <td>-0.104167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09.17.1431</th>\n",
       "      <td>20287.613475</td>\n",
       "      <td>4.463948</td>\n",
       "      <td>-0.245272</td>\n",
       "      <td>4.463948</td>\n",
       "      <td>137.572104</td>\n",
       "      <td>0.267139</td>\n",
       "      <td>6.964539</td>\n",
       "      <td>0.815603</td>\n",
       "      <td>57.326241</td>\n",
       "      <td>1654.624113</td>\n",
       "      <td>-0.310875</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>0.170213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id  quality_0  quality_1  quality_2   quality_5  \\\n",
       "fwver                                                                   \n",
       "03.11.1149  20034.941176        NaN  -0.009804   0.068627    0.269608   \n",
       "03.11.1167  17646.546952        NaN  -0.108951   8.602863   32.112647   \n",
       "04.16.3345  23726.000000   0.000000   0.000000   0.000000    0.000000   \n",
       "04.16.3439  20813.000000   0.000000   0.083333   0.000000    0.166667   \n",
       "04.16.3553  17455.935069  -0.172872  -0.157845  -0.064637   49.769608   \n",
       "04.16.3571  17367.145161  -0.165771  -0.152330  -0.165771    8.394713   \n",
       "04.22.1442  23842.000000  -0.166667  -0.166667  -0.166667    0.119048   \n",
       "04.22.1656  19831.000000   0.000000   0.000000   0.000000    0.000000   \n",
       "04.22.1666  19592.000000  -0.003145  -0.001572  -0.003145    3.073899   \n",
       "04.22.1684  13341.564912  -0.003216  -0.002924  -0.003216    6.439766   \n",
       "04.22.1750  17647.996705  -0.193625  -0.186437  -0.193625  116.878478   \n",
       "04.22.1778  17863.565448  -0.198594  -0.183896  -0.198594  130.867314   \n",
       "04.33.1125  23952.083333  -0.347222  -0.340278  -0.347222   -0.027778   \n",
       "04.33.1149  16860.820896  -0.166667  -0.159204  -0.166667    9.007463   \n",
       "04.33.1185  17153.824064  -0.190007  -0.181828  -0.190007   80.396756   \n",
       "04.33.1261  17460.899132  -0.216827  -0.201378  -0.216827   67.633706   \n",
       "04.73.2237  16874.500000  -0.218750  -0.187500  -0.218750   95.765625   \n",
       "04.73.2571  22880.000000  -0.083333  -0.083333  -0.083333    0.416667   \n",
       "04.82.1684  18283.896552  -0.261494  -0.246169  -0.261494    7.192529   \n",
       "04.82.1778  17932.166667  -0.189815  -0.175926  -0.189815    0.412037   \n",
       "05.15.2114  23476.000000   0.000000   0.000000   0.000000   34.729167   \n",
       "05.15.2120  19183.142857   0.000000   0.000000   0.000000    0.547619   \n",
       "05.15.2122  19278.000000  -0.033333  -0.033333  -0.033333    4.066667   \n",
       "05.15.2138  17769.448578  17.910338  -0.169681  17.908335   85.623251   \n",
       "05.66.3237  14926.673913  -0.289855  -0.278986  -0.289855    0.563406   \n",
       "05.66.3571  18191.375000  -0.104167  -0.083333  -0.104167    4.791667   \n",
       "09.17.1431  20287.613475   4.463948  -0.245272   4.463948  137.572104   \n",
       "\n",
       "            quality_6   quality_7  quality_8   quality_9   quality_10  \\\n",
       "fwver                                                                   \n",
       "03.11.1149  -0.009804    0.000000   0.000000    0.941176     3.352941   \n",
       "03.11.1167   0.828120   11.500058   0.255214  104.796981   386.914391   \n",
       "04.16.3345  59.833333  718.000000   0.000000    0.000000     0.000000   \n",
       "04.16.3439   0.416667    5.000000   1.000000    0.000000     2.000000   \n",
       "04.16.3553   3.354995   42.334298   0.180221    1.299046   599.309761   \n",
       "04.16.3571   0.068100    2.806452   0.161290    0.000000   102.725806   \n",
       "04.22.1442  -0.166667    0.000000   0.000000    0.000000     3.428571   \n",
       "04.22.1656   8.083333   97.000000   0.000000    0.000000     0.000000   \n",
       "04.22.1666  -0.003145    0.000000   0.018868    0.000000    36.924528   \n",
       "04.22.1684   1.128070   13.575439   0.003509    0.000000    77.315789   \n",
       "04.22.1750   0.974358   14.015799   0.086262    0.000000  1404.786161   \n",
       "04.22.1778   0.401084    7.196133   0.176371    0.000000  1572.568423   \n",
       "04.33.1125  -0.062500    3.416667   0.083333    0.000000     3.833333   \n",
       "04.33.1149   2.360697   30.328358   0.089552    0.000000   110.089552   \n",
       "04.33.1185   0.973797   13.965649   0.098146    0.000000   967.026536   \n",
       "04.33.1261   1.632298   22.189493   0.185381    0.000000   814.187848   \n",
       "04.73.2237   0.046875    3.187500   0.375000    0.000000  1151.812500   \n",
       "04.73.2571  -0.083333    0.000000   0.000000    0.000000     6.000000   \n",
       "04.82.1684   3.125479   40.643678   0.183908    0.000000    89.448276   \n",
       "04.82.1778  -0.087963    1.222222   0.166667    0.000000     7.222222   \n",
       "05.15.2114   0.000000    0.000000   0.000000    0.000000   416.750000   \n",
       "05.15.2120   7.178571   86.142857   0.000000    0.000000     6.571429   \n",
       "05.15.2122  -0.033333    0.000000   0.000000    0.000000    49.200000   \n",
       "05.15.2138   4.598955   57.360362   0.136735  217.072925  1029.651915   \n",
       "05.66.3237   0.300725    7.086957   0.130435    0.000000    10.239130   \n",
       "05.66.3571   2.510417   31.375000   0.250000    0.000000    58.750000   \n",
       "09.17.1431   0.267139    6.964539   0.815603   57.326241  1654.624113   \n",
       "\n",
       "            quality_11  quality_12      prob  \n",
       "fwver                                         \n",
       "03.11.1149   -0.009804    0.000000  0.000000  \n",
       "03.11.1167   -0.106675    0.282521  0.134117  \n",
       "04.16.3345    0.000000    0.000000  0.000000  \n",
       "04.16.3439    0.000000    0.000000  0.000000  \n",
       "04.16.3553   -0.172703    0.001929  0.182471  \n",
       "04.16.3571   -0.165771    0.000000  0.327957  \n",
       "04.22.1442   -0.166667    0.000000  0.142857  \n",
       "04.22.1656    0.000000    0.000000  0.000000  \n",
       "04.22.1666   -0.003145    0.000000  0.000000  \n",
       "04.22.1684   -0.003216    0.000000  0.028070  \n",
       "04.22.1750   -0.193506    0.001436  0.201504  \n",
       "04.22.1778   -0.197213    0.016575  0.384190  \n",
       "04.33.1125   -0.347222    0.000000  0.083333  \n",
       "04.33.1149   -0.166667    0.000000  0.731343  \n",
       "04.33.1185   -0.188023    0.023810  0.109051  \n",
       "04.33.1261   -0.215037    0.021471  0.371128  \n",
       "04.73.2237   -0.218750    0.000000  0.187500  \n",
       "04.73.2571   -0.083333    0.000000  1.000000  \n",
       "04.82.1684   -0.261494    0.000000  0.137931  \n",
       "04.82.1778   -0.189815    0.000000  0.444444  \n",
       "05.15.2114    0.000000    0.000000  0.000000  \n",
       "05.15.2120    0.000000    0.000000  0.000000  \n",
       "05.15.2122   -0.033333    0.000000  0.000000  \n",
       "05.15.2138   -0.179715    0.016320  0.191869  \n",
       "05.66.3237   -0.289855    0.000000  0.630435  \n",
       "05.66.3571   -0.104167    0.000000  0.000000  \n",
       "09.17.1431   -0.310875    0.028369  0.170213  "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge.groupby('fwver').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(828624, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality_0</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_6</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "      <th>quality_12</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quality_0  quality_1  quality_2  quality_5  quality_6  quality_7  \\\n",
       "0        0.0          0        0.0        0.0          0        0.0   \n",
       "1        0.0          0        0.0        0.0          0        0.0   \n",
       "2        0.0          0        0.0        0.0          0        0.0   \n",
       "3        0.0          0        0.0        0.0          0        0.0   \n",
       "4        0.0          0        0.0        0.0          0        0.0   \n",
       "\n",
       "   quality_8  quality_9  quality_10  quality_11  quality_12  prob  \n",
       "0        0.0        0.0         4.0           0           0     0  \n",
       "1        0.0        0.0         4.0           0           0     0  \n",
       "2        0.0        0.0         4.0           0           0     0  \n",
       "3        0.0        0.0         4.0           0           0     0  \n",
       "4        0.0        0.0         4.0           0           0     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lb_qual = qual_.copy()\n",
    "lb_qual['prob'] = train_merge['prob']\n",
    "print(lb_qual.shape)\n",
    "display(lb_qual.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prob</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_10</th>\n",
       "      <td>0.018618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_12</th>\n",
       "      <td>0.018515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_5</th>\n",
       "      <td>0.011245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_8</th>\n",
       "      <td>0.001630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_2</th>\n",
       "      <td>-0.003624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_0</th>\n",
       "      <td>-0.004585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_6</th>\n",
       "      <td>-0.005557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_7</th>\n",
       "      <td>-0.006409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_9</th>\n",
       "      <td>-0.007089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_1</th>\n",
       "      <td>-0.016090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_11</th>\n",
       "      <td>-0.028564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                prob\n",
       "prob        1.000000\n",
       "quality_10  0.018618\n",
       "quality_12  0.018515\n",
       "quality_5   0.011245\n",
       "quality_8   0.001630\n",
       "quality_2  -0.003624\n",
       "quality_0  -0.004585\n",
       "quality_6  -0.005557\n",
       "quality_7  -0.006409\n",
       "quality_9  -0.007089\n",
       "quality_1  -0.016090\n",
       "quality_11 -0.028564"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation = lb_qual.corr()\n",
    "correlation[['prob']].sort_values(['prob'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "for index in range(len(lb_qual.columns)):\n",
    "    plt.subplot(3,4,index+1)\n",
    "    sns.regplot(x=lb_qual.iloc[:, index], y=lb_qual['prob'], fit_reg=False)\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Redundant Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features with multicollinearity - from correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((144432, 14), (40113, 14))"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_qual[new_train_qual['quality_0'].isnull()].shape, new_train_qual[new_train_qual['quality_2'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 14), (0, 14))"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_qual[new_train_qual['quality_6'].isnull()].shape, new_train_qual[new_train_qual['quality_7'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fwver</th>\n",
       "      <th>time</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_9</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "      <th>quality_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       fwver            time  quality_1  quality_2  quality_5  \\\n",
       "0    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "1    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "2    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "3    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "4    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "\n",
       "   quality_7  quality_8  quality_9  quality_10  quality_11  quality_12  \n",
       "0        0.0        0.0        0.0         4.0           0           0  \n",
       "1        0.0        0.0        0.0         4.0           0           0  \n",
       "2        0.0        0.0        0.0         4.0           0           0  \n",
       "3        0.0        0.0        0.0         4.0           0           0  \n",
       "4        0.0        0.0        0.0         4.0           0           0  "
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del new_train_qual['quality_0']\n",
    "del new_train_qual['quality_6']\n",
    "new_train_qual.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4aa3d07b38>"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(25,8))\n",
    "plt.title('Number of missing rows')\n",
    "missing_count = pd.DataFrame(new_train_qual.isnull().sum(), columns=['sum']).sort_values(by=['sum'],ascending=False).head(20).reset_index()\n",
    "missing_count.columns = ['features','sum']\n",
    "sns.barplot(x='features',y='sum', data = missing_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40113, 40080)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_qual['quality_2'].isnull().sum(), new_train_qual['fwver'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing features that have mostly just 1 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0      0.808895\n",
      "-1      0.185427\n",
      " 1      0.003098\n",
      " 2      0.001376\n",
      " 3      0.000472\n",
      " 4      0.000244\n",
      " 5      0.000162\n",
      " 6      0.000086\n",
      " 7      0.000060\n",
      " 8      0.000042\n",
      " 9      0.000031\n",
      " 10     0.000029\n",
      " 11     0.000014\n",
      " 12     0.000008\n",
      " 13     0.000007\n",
      " 14     0.000006\n",
      " 170    0.000005\n",
      " 18     0.000005\n",
      " 20     0.000005\n",
      " 21     0.000005\n",
      " 16     0.000004\n",
      " 17     0.000004\n",
      " 15     0.000004\n",
      " 169    0.000002\n",
      " 23     0.000002\n",
      " 171    0.000001\n",
      " 19     0.000001\n",
      " 35     0.000001\n",
      " 40     0.000001\n",
      " 88     0.000001\n",
      " 117    0.000001\n",
      "Name: quality_1, dtype: float64\n",
      " 0.0        0.763276\n",
      "-1.0        0.174255\n",
      " 1.0        0.003544\n",
      " 2.0        0.001295\n",
      " 3.0        0.000700\n",
      " 4.0        0.000549\n",
      " 5.0        0.000515\n",
      " 6.0        0.000466\n",
      " 7.0        0.000407\n",
      " 9.0        0.000379\n",
      " 10.0       0.000350\n",
      " 8.0        0.000344\n",
      " 11.0       0.000298\n",
      " 13.0       0.000279\n",
      " 12.0       0.000279\n",
      " 14.0       0.000240\n",
      " 16.0       0.000223\n",
      " 15.0       0.000209\n",
      " 17.0       0.000179\n",
      " 18.0       0.000154\n",
      " 19.0       0.000148\n",
      " 20.0       0.000119\n",
      " 21.0       0.000106\n",
      " 24.0       0.000091\n",
      " 23.0       0.000087\n",
      " 25.0       0.000078\n",
      " 22.0       0.000076\n",
      " 26.0       0.000070\n",
      " 28.0       0.000068\n",
      " 29.0       0.000068\n",
      "              ...   \n",
      " 998.0      0.000001\n",
      " 236.0      0.000001\n",
      " 4009.0     0.000001\n",
      " 4021.0     0.000001\n",
      " 1006.0     0.000001\n",
      " 2016.0     0.000001\n",
      " 1007.0     0.000001\n",
      " 1009.0     0.000001\n",
      " 16218.0    0.000001\n",
      " 64928.0    0.000001\n",
      " 255.0      0.000001\n",
      " 4088.0     0.000001\n",
      " 509.0      0.000001\n",
      " 4094.0     0.000001\n",
      " 4095.0     0.000001\n",
      " 512.0      0.000001\n",
      " 1027.0     0.000001\n",
      " 4117.0     0.000001\n",
      " 258.0      0.000001\n",
      " 16557.0    0.000001\n",
      " 1038.0     0.000001\n",
      " 4156.0     0.000001\n",
      " 263.0      0.000001\n",
      " 4229.0     0.000001\n",
      " 265.0      0.000001\n",
      " 436.0      0.000001\n",
      " 267.0      0.000001\n",
      " 4279.0     0.000001\n",
      " 4289.0     0.000001\n",
      " 624.0      0.000001\n",
      "Name: quality_2, Length: 798, dtype: float64\n",
      " 0.0        0.516635\n",
      "-1.0        0.185071\n",
      " 1.0        0.067788\n",
      " 2.0        0.043419\n",
      " 3.0        0.026062\n",
      " 4.0        0.013521\n",
      " 5.0        0.010301\n",
      " 6.0        0.008250\n",
      " 7.0        0.006645\n",
      " 8.0        0.005425\n",
      " 9.0        0.004965\n",
      " 10.0       0.004188\n",
      " 11.0       0.003952\n",
      " 12.0       0.003757\n",
      " 13.0       0.003233\n",
      " 14.0       0.002978\n",
      " 15.0       0.002922\n",
      " 16.0       0.002632\n",
      " 17.0       0.002457\n",
      " 18.0       0.002383\n",
      " 19.0       0.002202\n",
      " 20.0       0.002163\n",
      " 21.0       0.002116\n",
      " 22.0       0.001939\n",
      " 23.0       0.001898\n",
      " 24.0       0.001897\n",
      " 26.0       0.001822\n",
      " 27.0       0.001769\n",
      " 25.0       0.001740\n",
      " 28.0       0.001575\n",
      "              ...   \n",
      " 2456.0     0.000001\n",
      " 4371.0     0.000001\n",
      " 17475.0    0.000001\n",
      " 5540.0     0.000001\n",
      " 4419.0     0.000001\n",
      " 1121.0     0.000001\n",
      " 4443.0     0.000001\n",
      " 71665.0    0.000001\n",
      " 4471.0     0.000001\n",
      " 4469.0     0.000001\n",
      " 2468.0     0.000001\n",
      " 17854.0    0.000001\n",
      " 4462.0     0.000001\n",
      " 8720.0     0.000001\n",
      " 4454.0     0.000001\n",
      " 3028.0     0.000001\n",
      " 4445.0     0.000001\n",
      " 17770.0    0.000001\n",
      " 4420.0     0.000001\n",
      " 4442.0     0.000001\n",
      " 4441.0     0.000001\n",
      " 4439.0     0.000001\n",
      " 1109.0     0.000001\n",
      " 4434.0     0.000001\n",
      " 4431.0     0.000001\n",
      " 1107.0     0.000001\n",
      " 4425.0     0.000001\n",
      " 4424.0     0.000001\n",
      " 17693.0    0.000001\n",
      " 16025.0    0.000001\n",
      "Name: quality_5, Length: 4744, dtype: float64\n",
      "0.0       0.914514\n",
      "1.0       0.008168\n",
      "2.0       0.004402\n",
      "5.0       0.004171\n",
      "6.0       0.003244\n",
      "3.0       0.003099\n",
      "4.0       0.002563\n",
      "10.0      0.001970\n",
      "11.0      0.001752\n",
      "7.0       0.001405\n",
      "9.0       0.001361\n",
      "8.0       0.001347\n",
      "16.0      0.001231\n",
      "12.0      0.001028\n",
      "14.0      0.000941\n",
      "13.0      0.000854\n",
      "21.0      0.000753\n",
      "41.0      0.000695\n",
      "19.0      0.000681\n",
      "18.0      0.000652\n",
      "15.0      0.000637\n",
      "26.0      0.000637\n",
      "47.0      0.000608\n",
      "31.0      0.000608\n",
      "17.0      0.000594\n",
      "24.0      0.000550\n",
      "20.0      0.000536\n",
      "25.0      0.000536\n",
      "22.0      0.000492\n",
      "92.0      0.000492\n",
      "            ...   \n",
      "1141.0    0.000014\n",
      "508.0     0.000014\n",
      "1134.0    0.000014\n",
      "283.0     0.000014\n",
      "282.0     0.000014\n",
      "4501.0    0.000014\n",
      "281.0     0.000014\n",
      "3360.0    0.000014\n",
      "744.0     0.000014\n",
      "1174.0    0.000014\n",
      "1840.0    0.000014\n",
      "4702.0    0.000014\n",
      "4927.0    0.000014\n",
      "1230.0    0.000014\n",
      "306.0     0.000014\n",
      "4861.0    0.000014\n",
      "4849.0    0.000014\n",
      "303.0     0.000014\n",
      "1209.0    0.000014\n",
      "4821.0    0.000014\n",
      "1203.0    0.000014\n",
      "4789.0    0.000014\n",
      "299.0     0.000014\n",
      "4779.0    0.000014\n",
      "297.0     0.000014\n",
      "4750.0    0.000014\n",
      "1168.0    0.000014\n",
      "1183.0    0.000014\n",
      "294.0     0.000014\n",
      "1051.0    0.000014\n",
      "Name: quality_7, Length: 884, dtype: float64\n",
      "0.0       0.950747\n",
      "1.0       0.023055\n",
      "2.0       0.010659\n",
      "3.0       0.004851\n",
      "4.0       0.003128\n",
      "5.0       0.002042\n",
      "6.0       0.001347\n",
      "7.0       0.000898\n",
      "8.0       0.000579\n",
      "9.0       0.000463\n",
      "10.0      0.000348\n",
      "11.0      0.000348\n",
      "13.0      0.000203\n",
      "12.0      0.000188\n",
      "15.0      0.000130\n",
      "17.0      0.000130\n",
      "16.0      0.000101\n",
      "18.0      0.000101\n",
      "14.0      0.000072\n",
      "21.0      0.000058\n",
      "20.0      0.000058\n",
      "23.0      0.000058\n",
      "25.0      0.000043\n",
      "27.0      0.000043\n",
      "29.0      0.000043\n",
      "22.0      0.000043\n",
      "38.0      0.000029\n",
      "42.0      0.000029\n",
      "37.0      0.000014\n",
      "35.0      0.000014\n",
      "28.0      0.000014\n",
      "31.0      0.000014\n",
      "68.0      0.000014\n",
      "47.0      0.000014\n",
      "43.0      0.000014\n",
      "26.0      0.000014\n",
      "19.0      0.000014\n",
      "32.0      0.000014\n",
      "24.0      0.000014\n",
      "1317.0    0.000014\n",
      "73.0      0.000014\n",
      "125.0     0.000014\n",
      "Name: quality_8, dtype: float64\n",
      "0.0        0.960971\n",
      "1.0        0.010890\n",
      "2.0        0.003345\n",
      "3.0        0.002172\n",
      "4.0        0.001709\n",
      "6.0        0.001419\n",
      "5.0        0.001390\n",
      "7.0        0.000681\n",
      "8.0        0.000507\n",
      "9.0        0.000478\n",
      "10.0       0.000420\n",
      "11.0       0.000304\n",
      "15.0       0.000203\n",
      "12.0       0.000203\n",
      "24.0       0.000188\n",
      "26.0       0.000174\n",
      "19.0       0.000174\n",
      "16.0       0.000159\n",
      "41.0       0.000145\n",
      "47.0       0.000145\n",
      "74.0       0.000145\n",
      "21.0       0.000145\n",
      "25.0       0.000145\n",
      "20.0       0.000145\n",
      "36.0       0.000145\n",
      "44.0       0.000145\n",
      "31.0       0.000130\n",
      "48.0       0.000130\n",
      "18.0       0.000130\n",
      "123.0      0.000116\n",
      "             ...   \n",
      "254.0      0.000014\n",
      "4079.0     0.000014\n",
      "736.0      0.000014\n",
      "1022.0     0.000014\n",
      "16353.0    0.000014\n",
      "92.0       0.000014\n",
      "258.0      0.000014\n",
      "366.0      0.000014\n",
      "247.0      0.000014\n",
      "371.0      0.000014\n",
      "62735.0    0.000014\n",
      "194.0      0.000014\n",
      "233.0      0.000014\n",
      "3733.0     0.000014\n",
      "934.0      0.000014\n",
      "234.0      0.000014\n",
      "14985.0    0.000014\n",
      "940.0      0.000014\n",
      "2096.0     0.000014\n",
      "3792.0     0.000014\n",
      "953.0      0.000014\n",
      "3824.0     0.000014\n",
      "1497.0     0.000014\n",
      "964.0      0.000014\n",
      "200.0      0.000014\n",
      "967.0      0.000014\n",
      "242.0      0.000014\n",
      "3878.0     0.000014\n",
      "237.0      0.000014\n",
      "4131.0     0.000014\n",
      "Name: quality_9, Length: 523, dtype: float64\n",
      "3.0        0.120474\n",
      "2.0        0.098636\n",
      "0.0        0.071236\n",
      "1.0        0.070179\n",
      "4.0        0.066312\n",
      "5.0        0.049253\n",
      "6.0        0.038884\n",
      "7.0        0.029007\n",
      "8.0        0.023185\n",
      "9.0        0.019015\n",
      "10.0       0.015206\n",
      "11.0       0.014380\n",
      "12.0       0.012440\n",
      "13.0       0.010383\n",
      "14.0       0.009153\n",
      "15.0       0.008892\n",
      "16.0       0.007531\n",
      "18.0       0.006980\n",
      "17.0       0.006473\n",
      "19.0       0.005793\n",
      "21.0       0.005749\n",
      "20.0       0.005416\n",
      "22.0       0.004880\n",
      "23.0       0.004808\n",
      "24.0       0.004330\n",
      "26.0       0.004098\n",
      "25.0       0.003896\n",
      "27.0       0.003693\n",
      "28.0       0.003635\n",
      "29.0       0.003476\n",
      "             ...   \n",
      "3635.0     0.000014\n",
      "24823.0    0.000014\n",
      "6207.0     0.000014\n",
      "99348.0    0.000014\n",
      "14502.0    0.000014\n",
      "14497.0    0.000014\n",
      "906.0      0.000014\n",
      "6210.0     0.000014\n",
      "3622.0     0.000014\n",
      "3646.0     0.000014\n",
      "3647.0     0.000014\n",
      "1820.0     0.000014\n",
      "1546.0     0.000014\n",
      "58671.0    0.000014\n",
      "3665.0     0.000014\n",
      "1543.0     0.000014\n",
      "3663.0     0.000014\n",
      "2856.0     0.000014\n",
      "3661.0     0.000014\n",
      "6182.0     0.000014\n",
      "58477.0    0.000014\n",
      "6199.0     0.000014\n",
      "3654.0     0.000014\n",
      "3653.0     0.000014\n",
      "1547.0     0.000014\n",
      "3651.0     0.000014\n",
      "6194.0     0.000014\n",
      "2504.0     0.000014\n",
      "24787.0    0.000014\n",
      "3985.0     0.000014\n",
      "Name: quality_10, Length: 4200, dtype: float64\n",
      " 0     0.811259\n",
      "-1     0.185462\n",
      " 1     0.002930\n",
      " 2     0.000245\n",
      " 3     0.000060\n",
      " 4     0.000023\n",
      " 5     0.000010\n",
      " 6     0.000006\n",
      " 14    0.000001\n",
      " 9     0.000001\n",
      " 8     0.000001\n",
      " 7     0.000001\n",
      "Name: quality_11, dtype: float64\n",
      "0     0.966851\n",
      "1     0.025198\n",
      "2     0.005460\n",
      "3     0.001593\n",
      "4     0.000377\n",
      "5     0.000232\n",
      "6     0.000130\n",
      "8     0.000058\n",
      "7     0.000029\n",
      "14    0.000014\n",
      "13    0.000014\n",
      "12    0.000014\n",
      "11    0.000014\n",
      "10    0.000014\n",
      "Name: quality_12, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in ['1', '2', '5', '7', '8', '9', '10', '11', '12']:\n",
    "    print(new_train_qual['quality_' + i].value_counts() / np.float(len(new_train_qual)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8088952287165229\n",
      "0.7632762266118288\n",
      "0.5166348066191663\n",
      "0.9145136998204252\n",
      "0.950747262932283\n",
      "0.12047442507096101\n",
      "0.8112593890594528\n"
     ]
    }
   ],
   "source": [
    "for i in ['1', '2', '5', '7', '8', '10', '11']:\n",
    "    print(max(new_train_qual['quality_' + i].value_counts() / np.float(len(new_train_qual))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quality 9, 12는 96% 이상 하나의 값으로 구성 -> 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(828624, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fwver</th>\n",
       "      <th>time</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       fwver            time  quality_1  quality_2  quality_5  \\\n",
       "0    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "1    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "2    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "3    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "4    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "\n",
       "   quality_7  quality_8  quality_10  quality_11  \n",
       "0        0.0        0.0         4.0           0  \n",
       "1        0.0        0.0         4.0           0  \n",
       "2        0.0        0.0         4.0           0  \n",
       "3        0.0        0.0         4.0           0  \n",
       "4        0.0        0.0         4.0           0  "
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del new_train_qual['quality_9']\n",
    "del new_train_qual['quality_12']\n",
    "print(new_train_qual.shape)\n",
    "new_train_qual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>828624.000000</td>\n",
       "      <td>8.286240e+05</td>\n",
       "      <td>828624.000000</td>\n",
       "      <td>788511.000000</td>\n",
       "      <td>828604.000000</td>\n",
       "      <td>828624.000000</td>\n",
       "      <td>828624.000000</td>\n",
       "      <td>8.286240e+05</td>\n",
       "      <td>828624.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17574.678315</td>\n",
       "      <td>2.020112e+13</td>\n",
       "      <td>-0.171782</td>\n",
       "      <td>4.751094</td>\n",
       "      <td>74.533171</td>\n",
       "      <td>26.744106</td>\n",
       "      <td>0.163732</td>\n",
       "      <td>8.965973e+02</td>\n",
       "      <td>-0.181638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4374.113554</td>\n",
       "      <td>8.863638e+06</td>\n",
       "      <td>0.692386</td>\n",
       "      <td>586.252469</td>\n",
       "      <td>2278.661590</td>\n",
       "      <td>317.874778</td>\n",
       "      <td>5.154260</td>\n",
       "      <td>1.652103e+04</td>\n",
       "      <td>0.397767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>2.020103e+13</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13685.000000</td>\n",
       "      <td>2.020111e+13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17597.000000</td>\n",
       "      <td>2.020112e+13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21423.000000</td>\n",
       "      <td>2.020112e+13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.900000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24997.000000</td>\n",
       "      <td>2.020113e+13</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>191859.000000</td>\n",
       "      <td>637385.000000</td>\n",
       "      <td>7200.000000</td>\n",
       "      <td>1317.000000</td>\n",
       "      <td>1.910175e+06</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id          time      quality_1      quality_2  \\\n",
       "count  828624.000000  8.286240e+05  828624.000000  788511.000000   \n",
       "mean    17574.678315  2.020112e+13      -0.171782       4.751094   \n",
       "std      4374.113554  8.863638e+06       0.692386     586.252469   \n",
       "min     10000.000000  2.020103e+13      -1.000000      -1.000000   \n",
       "25%     13685.000000  2.020111e+13       0.000000       0.000000   \n",
       "50%     17597.000000  2.020112e+13       0.000000       0.000000   \n",
       "75%     21423.000000  2.020112e+13       0.000000       0.000000   \n",
       "max     24997.000000  2.020113e+13     171.000000  191859.000000   \n",
       "\n",
       "           quality_5      quality_7      quality_8    quality_10  \\\n",
       "count  828604.000000  828624.000000  828624.000000  8.286240e+05   \n",
       "mean       74.533171      26.744106       0.163732  8.965973e+02   \n",
       "std      2278.661590     317.874778       5.154260  1.652103e+04   \n",
       "min        -1.000000       0.000000       0.000000  0.000000e+00   \n",
       "25%         0.000000       0.000000       0.000000  3.000000e+00   \n",
       "50%         0.000000       0.000000       0.000000  6.000000e+00   \n",
       "75%         1.000000       0.000000       0.000000  3.900000e+01   \n",
       "max    637385.000000    7200.000000    1317.000000  1.910175e+06   \n",
       "\n",
       "          quality_11  \n",
       "count  828624.000000  \n",
       "mean       -0.181638  \n",
       "std         0.397767  \n",
       "min        -1.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max        14.000000  "
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_qual.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>quality_2</th>\n",
       "      <td>40113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fwver</th>\n",
       "      <td>40080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_5</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sum\n",
       "quality_2   40113\n",
       "fwver       40080\n",
       "quality_5      20\n",
       "user_id         0\n",
       "time            0\n",
       "quality_1       0\n",
       "quality_7       0\n",
       "quality_8       0\n",
       "quality_10      0\n",
       "quality_11      0"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(new_train_qual.isnull().sum(), columns=['sum']).sort_values(by=['sum'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>2.020113e+13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>2.020112e+13</td>\n",
       "      <td>-0.020833</td>\n",
       "      <td>-0.010417</td>\n",
       "      <td>0.302083</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.875</td>\n",
       "      <td>-0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>2.020110e+13</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>-0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>2.020112e+13</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>-0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>2.020112e+13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  quality_1  quality_2  quality_5  quality_7  quality_8  \\\n",
       "user_id                                                                        \n",
       "10000    2.020113e+13   0.000000   0.000000   0.500000   0.000000        0.0   \n",
       "10002    2.020112e+13  -0.020833  -0.010417   0.302083   5.750000        0.0   \n",
       "10004    2.020110e+13  -0.083333  -0.083333   0.083333  43.500000        0.0   \n",
       "10005    2.020112e+13  -0.416667  -0.416667   0.000000  18.000000        0.0   \n",
       "10006    2.020112e+13   0.000000   0.000000   0.333333   1.333333        0.0   \n",
       "\n",
       "         quality_10  quality_11  \n",
       "user_id                          \n",
       "10000         6.000    0.000000  \n",
       "10002         3.875   -0.020833  \n",
       "10004         2.000   -0.083333  \n",
       "10005         5.000   -0.416667  \n",
       "10006         4.000    0.000000  "
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_qual.groupby('user_id').mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fwver</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">05.15.2138</th>\n",
       "      <th>20201129090000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129090000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129090000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129090000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129090000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129090000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129090000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129090000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129090000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129090000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129090000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129090000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201130210000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201130210000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201130210000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201130210000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201130210000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201130210000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201130210000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201130210000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201130210000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201130210000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201130210000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201130210000</th>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201104110000</th>\n",
       "      <td>10002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201104110000</th>\n",
       "      <td>10002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201104110000</th>\n",
       "      <td>10002</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201104110000</th>\n",
       "      <td>10002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201104110000</th>\n",
       "      <td>10002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201104110000</th>\n",
       "      <td>10002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">04.33.1261</th>\n",
       "      <th>20201129002000</th>\n",
       "      <td>24995</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129002000</th>\n",
       "      <td>24995</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129002000</th>\n",
       "      <td>24995</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129002000</th>\n",
       "      <td>24995</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129002000</th>\n",
       "      <td>24995</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201129002000</th>\n",
       "      <td>24995</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">04.22.1750</th>\n",
       "      <th>20201108230000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201108230000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201108230000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201108230000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201108230000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201108230000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201108230000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201108230000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201108230000</th>\n",
       "      <td>24997</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201108230000</th>\n",
       "      <td>24997</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201108230000</th>\n",
       "      <td>24997</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201108230000</th>\n",
       "      <td>24997</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">04.22.1778</th>\n",
       "      <th>20201124033000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201124033000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201124033000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201124033000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201124033000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201124033000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201124033000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201124033000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201124033000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201124033000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201124033000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20201124033000</th>\n",
       "      <td>24997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>828624 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user_id  quality_1  quality_2  quality_5  \\\n",
       "fwver      time                                                       \n",
       "05.15.2138 20201129090000    10000          0        0.0        0.0   \n",
       "           20201129090000    10000          0        0.0        0.0   \n",
       "           20201129090000    10000          0        0.0        0.0   \n",
       "           20201129090000    10000          0        0.0        0.0   \n",
       "           20201129090000    10000          0        0.0        0.0   \n",
       "           20201129090000    10000          0        0.0        0.0   \n",
       "           20201129090000    10000          0        0.0        4.0   \n",
       "           20201129090000    10000          0        0.0        0.0   \n",
       "           20201129090000    10000          0        0.0        0.0   \n",
       "           20201129090000    10000          0        0.0        0.0   \n",
       "           20201129090000    10000          0        0.0        0.0   \n",
       "           20201129090000    10000          0        0.0        0.0   \n",
       "           20201130210000    10000          0        0.0        0.0   \n",
       "           20201130210000    10000          0        0.0        0.0   \n",
       "           20201130210000    10000          0        0.0        0.0   \n",
       "           20201130210000    10000          0        0.0        0.0   \n",
       "           20201130210000    10000          0        0.0        0.0   \n",
       "           20201130210000    10000          0        0.0        0.0   \n",
       "           20201130210000    10000          0        0.0        0.0   \n",
       "           20201130210000    10000          0        0.0        0.0   \n",
       "           20201130210000    10000          0        0.0        0.0   \n",
       "           20201130210000    10000          0        0.0        0.0   \n",
       "           20201130210000    10000          0        0.0        8.0   \n",
       "           20201130210000    10000          0        0.0        0.0   \n",
       "           20201104110000    10002          0        0.0        0.0   \n",
       "           20201104110000    10002          0        0.0        0.0   \n",
       "           20201104110000    10002          0        1.0        0.0   \n",
       "           20201104110000    10002          0        0.0        0.0   \n",
       "           20201104110000    10002          0        0.0        0.0   \n",
       "           20201104110000    10002          0        0.0        0.0   \n",
       "...                            ...        ...        ...        ...   \n",
       "04.33.1261 20201129002000    24995          0        0.0        0.0   \n",
       "           20201129002000    24995          0        0.0        0.0   \n",
       "           20201129002000    24995          0        0.0        0.0   \n",
       "           20201129002000    24995          0        0.0        3.0   \n",
       "           20201129002000    24995          0        0.0        0.0   \n",
       "           20201129002000    24995          0        0.0        0.0   \n",
       "04.22.1750 20201108230000    24997          0        0.0        0.0   \n",
       "           20201108230000    24997          0        0.0        0.0   \n",
       "           20201108230000    24997          0        0.0        2.0   \n",
       "           20201108230000    24997          0        0.0        0.0   \n",
       "           20201108230000    24997          0        0.0        0.0   \n",
       "           20201108230000    24997          0        0.0        0.0   \n",
       "           20201108230000    24997          0        0.0        0.0   \n",
       "           20201108230000    24997          0        0.0        0.0   \n",
       "           20201108230000    24997         -1       -1.0       -1.0   \n",
       "           20201108230000    24997         -1       -1.0       -1.0   \n",
       "           20201108230000    24997         -1       -1.0       -1.0   \n",
       "           20201108230000    24997         -1       -1.0       -1.0   \n",
       "04.22.1778 20201124033000    24997          0        0.0        0.0   \n",
       "           20201124033000    24997          0        0.0        0.0   \n",
       "           20201124033000    24997          0        0.0        0.0   \n",
       "           20201124033000    24997          0        0.0        2.0   \n",
       "           20201124033000    24997          0        0.0        0.0   \n",
       "           20201124033000    24997          0        0.0        0.0   \n",
       "           20201124033000    24997          0        0.0        2.0   \n",
       "           20201124033000    24997          0        0.0        1.0   \n",
       "           20201124033000    24997          0        0.0        0.0   \n",
       "           20201124033000    24997          0        0.0        3.0   \n",
       "           20201124033000    24997          0        0.0        0.0   \n",
       "           20201124033000    24997          0        0.0        9.0   \n",
       "\n",
       "                           quality_7  quality_8  quality_10  quality_11  \n",
       "fwver      time                                                          \n",
       "05.15.2138 20201129090000        0.0        0.0         4.0           0  \n",
       "           20201129090000        0.0        0.0         4.0           0  \n",
       "           20201129090000        0.0        0.0         4.0           0  \n",
       "           20201129090000        0.0        0.0         4.0           0  \n",
       "           20201129090000        0.0        0.0         4.0           0  \n",
       "           20201129090000        0.0        0.0         4.0           0  \n",
       "           20201129090000        0.0        0.0         4.0           0  \n",
       "           20201129090000        0.0        0.0         4.0           0  \n",
       "           20201129090000        0.0        0.0         4.0           0  \n",
       "           20201129090000        0.0        0.0         4.0           0  \n",
       "           20201129090000        0.0        0.0         4.0           0  \n",
       "           20201129090000        0.0        0.0         4.0           0  \n",
       "           20201130210000        0.0        0.0         8.0           0  \n",
       "           20201130210000        0.0        0.0         8.0           0  \n",
       "           20201130210000        0.0        0.0         8.0           0  \n",
       "           20201130210000        0.0        0.0         8.0           0  \n",
       "           20201130210000        0.0        0.0         8.0           0  \n",
       "           20201130210000        0.0        0.0         8.0           0  \n",
       "           20201130210000        0.0        0.0         8.0           0  \n",
       "           20201130210000        0.0        0.0         8.0           0  \n",
       "           20201130210000        0.0        0.0         8.0           0  \n",
       "           20201130210000        0.0        0.0         8.0           0  \n",
       "           20201130210000        0.0        0.0         8.0           0  \n",
       "           20201130210000        0.0        0.0         8.0           0  \n",
       "           20201104110000        0.0        0.0         0.0           0  \n",
       "           20201104110000        0.0        0.0         0.0           0  \n",
       "           20201104110000        0.0        0.0         0.0           0  \n",
       "           20201104110000        0.0        0.0         0.0           0  \n",
       "           20201104110000        0.0        0.0         0.0           0  \n",
       "           20201104110000        0.0        0.0         0.0           0  \n",
       "...                              ...        ...         ...         ...  \n",
       "04.33.1261 20201129002000        0.0        0.0         3.0           0  \n",
       "           20201129002000        0.0        0.0         3.0           0  \n",
       "           20201129002000        0.0        0.0         3.0           0  \n",
       "           20201129002000        0.0        0.0         3.0           0  \n",
       "           20201129002000        0.0        0.0         3.0           0  \n",
       "           20201129002000        0.0        0.0         3.0           0  \n",
       "04.22.1750 20201108230000        0.0        0.0         2.0           0  \n",
       "           20201108230000        0.0        0.0         2.0           0  \n",
       "           20201108230000        0.0        0.0         2.0           0  \n",
       "           20201108230000        0.0        0.0         2.0           0  \n",
       "           20201108230000        0.0        0.0         2.0           0  \n",
       "           20201108230000        0.0        0.0         2.0           0  \n",
       "           20201108230000        0.0        0.0         2.0           0  \n",
       "           20201108230000        0.0        0.0         2.0           0  \n",
       "           20201108230000        0.0        0.0         2.0          -1  \n",
       "           20201108230000        0.0        0.0         2.0          -1  \n",
       "           20201108230000        0.0        0.0         2.0          -1  \n",
       "           20201108230000        0.0        0.0         2.0          -1  \n",
       "04.22.1778 20201124033000        0.0        0.0        17.0           0  \n",
       "           20201124033000        0.0        0.0        17.0           0  \n",
       "           20201124033000        0.0        0.0        17.0           0  \n",
       "           20201124033000        0.0        0.0        17.0           0  \n",
       "           20201124033000        0.0        0.0        17.0           0  \n",
       "           20201124033000        0.0        0.0        17.0           0  \n",
       "           20201124033000        0.0        0.0        17.0           0  \n",
       "           20201124033000        0.0        0.0        17.0           0  \n",
       "           20201124033000        0.0        0.0        17.0           0  \n",
       "           20201124033000        0.0        0.0        17.0           0  \n",
       "           20201124033000        0.0        0.0        17.0           0  \n",
       "           20201124033000        0.0        0.0        17.0           0  \n",
       "\n",
       "[828624 rows x 8 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_qual.set_index(['fwver', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8281, 8)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_qual.groupby('user_id').sum().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "case1: missing value 0으로 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fwver</th>\n",
       "      <th>time</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       fwver            time  quality_1  quality_2  quality_5  \\\n",
       "0    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "1    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "2    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "3    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "4    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "\n",
       "   quality_7  quality_8  quality_10  quality_11  \n",
       "0        0.0        0.0         4.0           0  \n",
       "1        0.0        0.0         4.0           0  \n",
       "2        0.0        0.0         4.0           0  \n",
       "3        0.0        0.0         4.0           0  \n",
       "4        0.0        0.0         4.0           0  "
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_qual_0 = new_train_qual.fillna(0)\n",
    "train_qual_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>2.020113e+13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>2.020112e+13</td>\n",
       "      <td>-0.020833</td>\n",
       "      <td>-0.010417</td>\n",
       "      <td>0.302083</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.875</td>\n",
       "      <td>-0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>2.020110e+13</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>-0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>2.020112e+13</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>-0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>2.020112e+13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  quality_1  quality_2  quality_5  quality_7  quality_8  \\\n",
       "user_id                                                                        \n",
       "10000    2.020113e+13   0.000000   0.000000   0.500000   0.000000        0.0   \n",
       "10002    2.020112e+13  -0.020833  -0.010417   0.302083   5.750000        0.0   \n",
       "10004    2.020110e+13  -0.083333  -0.083333   0.083333  43.500000        0.0   \n",
       "10005    2.020112e+13  -0.416667  -0.416667   0.000000  18.000000        0.0   \n",
       "10006    2.020112e+13   0.000000   0.000000   0.333333   1.333333        0.0   \n",
       "\n",
       "         quality_10  quality_11  \n",
       "user_id                          \n",
       "10000         6.000    0.000000  \n",
       "10002         3.875   -0.020833  \n",
       "10004         2.000   -0.083333  \n",
       "10005         5.000   -0.416667  \n",
       "10006         4.000    0.000000  "
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_qual_0.groupby('user_id').mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>5.720444e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.793709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.043016</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>9.200353e+06</td>\n",
       "      <td>0.143576</td>\n",
       "      <td>0.177396</td>\n",
       "      <td>1.037404</td>\n",
       "      <td>14.547924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.327185</td>\n",
       "      <td>0.143576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>9.658357e+05</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.282330</td>\n",
       "      <td>0.583592</td>\n",
       "      <td>44.435591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.021508</td>\n",
       "      <td>0.282330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>1.021508e+04</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>0.503610</td>\n",
       "      <td>1.179536</td>\n",
       "      <td>18.387141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.021508</td>\n",
       "      <td>0.503610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>7.376238e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.121224</td>\n",
       "      <td>1.912366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  quality_1  quality_2  quality_5  quality_7  quality_8  \\\n",
       "user_id                                                                        \n",
       "10000    5.720444e+05   0.000000   0.000000   1.793709   0.000000        0.0   \n",
       "10002    9.200353e+06   0.143576   0.177396   1.037404  14.547924        0.0   \n",
       "10004    9.658357e+05   0.282330   0.282330   0.583592  44.435591        0.0   \n",
       "10005    1.021508e+04   0.503610   0.503610   1.179536  18.387141        0.0   \n",
       "10006    7.376238e+06   0.000000   0.000000   1.121224   1.912366        0.0   \n",
       "\n",
       "         quality_10  quality_11  \n",
       "user_id                          \n",
       "10000      2.043016    0.000000  \n",
       "10002      2.327185    0.143576  \n",
       "10004      1.021508    0.282330  \n",
       "10005      1.021508    0.503610  \n",
       "10006      0.000000    0.000000  "
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_qual_0.groupby('user_id').std().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>-0.020833</td>\n",
       "      <td>-0.010417</td>\n",
       "      <td>0.302083</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.875</td>\n",
       "      <td>-0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>-0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>-0.416667</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>-0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         quality_1  quality_2  quality_5  quality_7  quality_8  quality_10  \\\n",
       "user_id                                                                      \n",
       "10000     0.000000   0.000000   0.500000   0.000000        0.0       6.000   \n",
       "10002    -0.020833  -0.010417   0.302083   5.750000        0.0       3.875   \n",
       "10004    -0.083333  -0.083333   0.083333  43.500000        0.0       2.000   \n",
       "10005    -0.416667  -0.416667   0.000000  18.000000        0.0       5.000   \n",
       "10006     0.000000   0.000000   0.333333   1.333333        0.0       4.000   \n",
       "\n",
       "         quality_11  \n",
       "user_id              \n",
       "10000      0.000000  \n",
       "10002     -0.020833  \n",
       "10004     -0.083333  \n",
       "10005     -0.416667  \n",
       "10006      0.000000  "
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qual_0 = train_qual_0.groupby('user_id').mean().loc[:, 'quality_1':'quality_11']\n",
    "qual_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.5       , ...,  0.        ,\n",
       "         6.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.02083333, -0.01041667,  0.30208333, ...,  0.        ,\n",
       "         3.875     , -0.02083333],\n",
       "       ...,\n",
       "       [-0.16666667, -0.16666667,  0.625     , ...,  0.        ,\n",
       "         9.5       , -0.16666667],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_qual_0 = np.zeros((15000, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0[qual_0.index-10000] = qual_0.loc[qual_0.index]\n",
    "full_qual_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  8., ...,  0.,  0., 24.],\n",
       "       [ 0.,  0.,  0., ..., 56.,  1.,  0.],\n",
       "       [ 0.,  0.,  2., ...,  0.,  0., 96.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  8.,  5., 24.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  4., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical features - train_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id     False\n",
       "time        False\n",
       "model_nm    False\n",
       "fwver       False\n",
       "errtype     False\n",
       "errcode      True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_err.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16554663 entries, 0 to 16554662\n",
      "Data columns (total 6 columns):\n",
      "user_id     int64\n",
      "time        int64\n",
      "model_nm    object\n",
      "fwver       object\n",
      "errtype     int64\n",
      "errcode     object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 757.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_err.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_nm의 값은 fwver에 포함 -> delete model_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>fwver</th>\n",
       "      <th>errtype</th>\n",
       "      <th>errcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101025616</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101030309</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101030309</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101050514</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101050515</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id            time       fwver  errtype errcode\n",
       "0    10000  20201101025616  05.15.2138       15       1\n",
       "1    10000  20201101030309  05.15.2138       12       1\n",
       "2    10000  20201101030309  05.15.2138       11       1\n",
       "3    10000  20201101050514  05.15.2138       16       1\n",
       "4    10000  20201101050515  05.15.2138        4       0"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_err['model_nm']\n",
    "train_err.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fwver</th>\n",
       "      <th>errtype</th>\n",
       "      <th>errcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fwver  errtype errcode\n",
       "0  05.15.2138       15       1\n",
       "1  05.15.2138       12       1\n",
       "2  05.15.2138       11       1\n",
       "3  05.15.2138       16       1\n",
       "4  05.15.2138        4       0"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_col = ['fwver', 'errtype', 'errcode']\n",
    "\n",
    "cat_train_err = train_err[cat_col].copy()\n",
    "cat_train_err.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(25,10))\n",
    "for index in range(len(cat_col)):\n",
    "    plt.subplot(3,1,index+1)\n",
    "    sns.countplot(x=cat_train_err.iloc[:,index], data=cat_train_err.dropna())\n",
    "    plt.xticks(rotation=90)\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features with a lot of missing values - train_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_train_err[cat_train_err['errcode'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2806, (16554663, 5))"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_train_err['errcode'].unique()), train_err.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1                                     5.380337e-01\n",
      "0                                     1.570025e-01\n",
      "connection timeout                    1.108811e-01\n",
      "B-A8002                               5.423626e-02\n",
      "80                                    2.017667e-02\n",
      "79                                    2.008026e-02\n",
      "14                                    1.592162e-02\n",
      "active                                1.324328e-02\n",
      "2                                     1.005046e-02\n",
      "84                                    7.845282e-03\n",
      "85                                    7.716497e-03\n",
      "standby                               6.667004e-03\n",
      "NFANDROID2                            6.290554e-03\n",
      "connection fail to establish          6.097376e-03\n",
      "3                                     5.510411e-03\n",
      "90                                    3.986309e-03\n",
      "89                                    3.914245e-03\n",
      "S-61001                               2.091918e-03\n",
      "95                                    1.416640e-03\n",
      "94                                    1.336059e-03\n",
      "4                                     1.223160e-03\n",
      "13                                    7.272875e-04\n",
      "Q-64002                               7.223947e-04\n",
      "8.0                                   5.628022e-04\n",
      "6                                     4.465207e-04\n",
      "5                                     4.430776e-04\n",
      "78                                    3.037211e-04\n",
      "81                                    2.621014e-04\n",
      "86                                    2.430131e-04\n",
      "connectionterminated by local host    2.422882e-04\n",
      "                                          ...     \n",
      "3795                                  6.040594e-08\n",
      "7793                                  6.040594e-08\n",
      "20152                                 6.040594e-08\n",
      "8152                                  6.040594e-08\n",
      "6618                                  6.040594e-08\n",
      "8974                                  6.040594e-08\n",
      "8533                                  6.040594e-08\n",
      "5300                                  6.040594e-08\n",
      "5845                                  6.040594e-08\n",
      "184457                                6.040594e-08\n",
      "4498                                  6.040594e-08\n",
      "61989                                 6.040594e-08\n",
      "5995                                  6.040594e-08\n",
      "4264                                  6.040594e-08\n",
      "8473                                  6.040594e-08\n",
      "695552                                6.040594e-08\n",
      "7694                                  6.040594e-08\n",
      "3598                                  6.040594e-08\n",
      "3580                                  6.040594e-08\n",
      "61653                                 6.040594e-08\n",
      "6695                                  6.040594e-08\n",
      "6535                                  6.040594e-08\n",
      "143915                                6.040594e-08\n",
      "7237                                  6.040594e-08\n",
      "3810                                  6.040594e-08\n",
      "4461                                  6.040594e-08\n",
      "41755                                 6.040594e-08\n",
      "4044                                  6.040594e-08\n",
      "10568                                 6.040594e-08\n",
      "7327                                  6.040594e-08\n",
      "Name: errcode, Length: 2805, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(cat_train_err['errcode'].value_counts() / np.float(len(cat_train_err)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Categorical to Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16554663/16554663 [00:45<00:00, 360574.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15000, 42)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_id_max = 24999\n",
    "train_user_id_min = 10000\n",
    "train_user_number = 15000\n",
    "\n",
    "id_error = train_err[['user_id','errtype']].values\n",
    "error = np.zeros((train_user_number,42))\n",
    "\n",
    "for person_idx, err in tqdm(id_error):\n",
    "    # person_idx - train_user_id_min 위치에 person_idx, errtype에 해당하는 error값을 +1\n",
    "    error[person_idx - train_user_id_min,err - 1] += 1\n",
    "error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000,)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem = np.zeros(15000)\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "problem[train_prob.user_id.unique()-10000] = 1 \n",
    "problem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4ab89b9588>"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "correlation = pd.DataFrame(error).corr()\n",
    "sns.heatmap(correlation, linewidth=0.5, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4aa3c1ed30>"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "correlation = pd.DataFrame(error).corr()\n",
    "sns.heatmap(correlation, mask = correlation <0.8, linewidth=0.5, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "관련된 error 지우기: 6-5 / 11-10 / 15-14 / 20-18 / 22-21 / 28 / 36 - 35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   8., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ..., 113.,  56.,   1.],\n",
       "       [  0.,   0.,   2., ...,   0.,   0.,   0.],\n",
       "       ...,\n",
       "       [  0.,   0.,   0., ...,  58.,   8.,   5.],\n",
       "       [  0.,   0.,   0., ...,   6.,   0.,   0.],\n",
       "       [  0.,   0.,   4., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = np.delete(error,(36), axis=1)\n",
    "error = np.delete(error,(28), axis=1)\n",
    "error = np.delete(error,(22), axis=1)\n",
    "error = np.delete(error,(20), axis=1)\n",
    "error = np.delete(error,(15), axis=1)\n",
    "error = np.delete(error,(11), axis=1)\n",
    "error = np.delete(error,(6), axis=1)\n",
    "\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 35)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   8., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ..., 113.,  56.,   1.],\n",
       "       [  0.,   0.,   2., ...,   0.,   0.,   0.],\n",
       "       ...,\n",
       "       [  0.,   0.,   0., ...,  58.,   8.,   5.],\n",
       "       [  0.,   0.,   0., ...,   6.,   0.,   0.],\n",
       "       [  0.,   0.,   4., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>fwver</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">10000</th>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201130210000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201130210000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">10002</th>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201104110000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201104110000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201106010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201106010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201111010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201111010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201111010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201115130000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201115130000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201118001000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201118001000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201118001000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201119141000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201119141000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201130010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201130010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201130010000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201130030000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201130030000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201130030000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">10004</th>\n",
       "      <th>04.22.1750</th>\n",
       "      <td>20201102232000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.22.1750</th>\n",
       "      <td>20201102232000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.22.1750</th>\n",
       "      <td>20201104123000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.22.1750</th>\n",
       "      <td>20201104123000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10005</th>\n",
       "      <th>04.22.1750</th>\n",
       "      <td>20201119020000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.22.1750</th>\n",
       "      <td>20201119040000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">24979</th>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201106041000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201106041000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201119152000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201119152000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201125032000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201125032000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201125032000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7998.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24981</th>\n",
       "      <th>04.22.1778</th>\n",
       "      <td>20201125025000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9558.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.22.1778</th>\n",
       "      <td>20201125025000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9558.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9558.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">24982</th>\n",
       "      <th>NaN</th>\n",
       "      <td>20201109025000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>20201109045000</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>20201109145000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>20201109145000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>20201109145000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>20201109145000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>20201109145000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>20201109145000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24984</th>\n",
       "      <th>04.16.3553</th>\n",
       "      <td>20201130103000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.16.3553</th>\n",
       "      <td>20201130103000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04.16.3553</th>\n",
       "      <td>20201130103000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <th>04.16.3553</th>\n",
       "      <td>20201107210000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">24986</th>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201105164000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201105164000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201105164000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201122224000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201123184000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201126165000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201126165000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201126165000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05.15.2138</th>\n",
       "      <td>20201126165000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83836 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              time  quality_1  quality_2  quality_5  \\\n",
       "user_id fwver                                                         \n",
       "10000   05.15.2138  20201129090000          0        0.0        0.0   \n",
       "        05.15.2138  20201129090000          0        0.0        4.0   \n",
       "        05.15.2138  20201130210000          0        0.0        0.0   \n",
       "        05.15.2138  20201130210000          0        0.0        8.0   \n",
       "10002   05.15.2138  20201104110000          0        0.0        0.0   \n",
       "        05.15.2138  20201104110000          0        1.0        0.0   \n",
       "        05.15.2138  20201106010000          0        0.0        0.0   \n",
       "        05.15.2138  20201106010000          0        0.0        2.0   \n",
       "        05.15.2138  20201111010000          0        0.0        0.0   \n",
       "        05.15.2138  20201111010000          0        0.0        1.0   \n",
       "        05.15.2138  20201111010000          0        0.0        2.0   \n",
       "        05.15.2138  20201115130000          0        0.0        0.0   \n",
       "        05.15.2138  20201115130000          0        0.0        5.0   \n",
       "        05.15.2138  20201118001000         -1       -1.0       -1.0   \n",
       "        05.15.2138  20201118001000          0        0.0        3.0   \n",
       "        05.15.2138  20201118001000          0        0.0        0.0   \n",
       "        05.15.2138  20201119141000          0        0.0        0.0   \n",
       "        05.15.2138  20201119141000          0        0.0        3.0   \n",
       "        05.15.2138  20201130010000          0        0.0        5.0   \n",
       "        05.15.2138  20201130010000          0        0.0        2.0   \n",
       "        05.15.2138  20201130010000          0        0.0        1.0   \n",
       "        05.15.2138  20201130030000          0        0.0        0.0   \n",
       "        05.15.2138  20201130030000          0        0.0        1.0   \n",
       "        05.15.2138  20201130030000          0        0.0        5.0   \n",
       "10004   04.22.1750  20201102232000          0        0.0        1.0   \n",
       "        04.22.1750  20201102232000          0        0.0        2.0   \n",
       "        04.22.1750  20201104123000          0        0.0        0.0   \n",
       "        04.22.1750  20201104123000          0        0.0        1.0   \n",
       "10005   04.22.1750  20201119020000          0        0.0        3.0   \n",
       "        04.22.1750  20201119040000          0        0.0        3.0   \n",
       "...                            ...        ...        ...        ...   \n",
       "24979   05.15.2138  20201106041000          0        0.0        0.0   \n",
       "        05.15.2138  20201106041000          0        0.0        1.0   \n",
       "        05.15.2138  20201119152000          0        0.0        0.0   \n",
       "        05.15.2138  20201119152000          0        0.0        2.0   \n",
       "        05.15.2138  20201125032000          0        0.0        0.0   \n",
       "        05.15.2138  20201125032000          0        0.0        2.0   \n",
       "        05.15.2138  20201125032000          0        0.0     7998.0   \n",
       "24981   04.22.1778  20201125025000          0        0.0        0.0   \n",
       "        04.22.1778  20201125025000          0        0.0     9558.0   \n",
       "24982   NaN         20201109025000          0        NaN       17.0   \n",
       "        NaN         20201109045000         -1        NaN        3.0   \n",
       "        NaN         20201109145000          0        NaN        0.0   \n",
       "        NaN         20201109145000          0        NaN        3.0   \n",
       "        NaN         20201109145000          0        NaN       28.0   \n",
       "        NaN         20201109145000          0        NaN        6.0   \n",
       "        NaN         20201109145000          0        NaN       15.0   \n",
       "        NaN         20201109145000          0        NaN        2.0   \n",
       "24984   04.16.3553  20201130103000         -1       -1.0       -1.0   \n",
       "        04.16.3553  20201130103000          0        0.0        0.0   \n",
       "        04.16.3553  20201130103000          0        0.0       10.0   \n",
       "24985   04.16.3553  20201107210000          0        0.0       31.0   \n",
       "24986   05.15.2138  20201105164000          0        0.0        3.0   \n",
       "        05.15.2138  20201105164000          0        0.0        5.0   \n",
       "        05.15.2138  20201105164000          0        0.0      472.0   \n",
       "        05.15.2138  20201122224000          0        0.0      408.0   \n",
       "        05.15.2138  20201123184000          0        0.0      173.0   \n",
       "        05.15.2138  20201126165000          0        0.0       33.0   \n",
       "        05.15.2138  20201126165000         -1       -1.0       -1.0   \n",
       "        05.15.2138  20201126165000          2        0.0     1507.0   \n",
       "        05.15.2138  20201126165000          0        0.0        0.0   \n",
       "\n",
       "                    quality_7  quality_8  quality_10  quality_11  \n",
       "user_id fwver                                                     \n",
       "10000   05.15.2138        0.0        0.0         4.0           0  \n",
       "        05.15.2138        0.0        0.0         4.0           0  \n",
       "        05.15.2138        0.0        0.0         8.0           0  \n",
       "        05.15.2138        0.0        0.0         8.0           0  \n",
       "10002   05.15.2138        0.0        0.0         0.0           0  \n",
       "        05.15.2138        0.0        0.0         0.0           0  \n",
       "        05.15.2138        0.0        0.0         2.0           0  \n",
       "        05.15.2138        0.0        0.0         2.0           0  \n",
       "        05.15.2138        2.0        0.0         4.0           0  \n",
       "        05.15.2138        2.0        0.0         4.0           0  \n",
       "        05.15.2138        2.0        0.0         4.0           0  \n",
       "        05.15.2138        0.0        0.0         5.0           0  \n",
       "        05.15.2138        0.0        0.0         5.0           0  \n",
       "        05.15.2138        0.0        0.0         3.0          -1  \n",
       "        05.15.2138        0.0        0.0         3.0           0  \n",
       "        05.15.2138        0.0        0.0         3.0           0  \n",
       "        05.15.2138       44.0        0.0         3.0           0  \n",
       "        05.15.2138       44.0        0.0         3.0           0  \n",
       "        05.15.2138        0.0        0.0         8.0           0  \n",
       "        05.15.2138        0.0        0.0         8.0           0  \n",
       "        05.15.2138        0.0        0.0         8.0           0  \n",
       "        05.15.2138        0.0        0.0         6.0           0  \n",
       "        05.15.2138        0.0        0.0         6.0           0  \n",
       "        05.15.2138        0.0        0.0         6.0           0  \n",
       "10004   04.22.1750        0.0        0.0         3.0           0  \n",
       "        04.22.1750        0.0        0.0         3.0           0  \n",
       "        04.22.1750       87.0        0.0         1.0           0  \n",
       "        04.22.1750       87.0        0.0         1.0           0  \n",
       "10005   04.22.1750        0.0        0.0         6.0           0  \n",
       "        04.22.1750       36.0        0.0         4.0           0  \n",
       "...                       ...        ...         ...         ...  \n",
       "24979   05.15.2138       62.0        0.0         2.0           0  \n",
       "        05.15.2138       62.0        0.0         2.0           0  \n",
       "        05.15.2138      614.0        0.0         2.0           0  \n",
       "        05.15.2138      614.0        0.0         2.0           0  \n",
       "        05.15.2138        0.0        0.0      8000.0           0  \n",
       "        05.15.2138        0.0        0.0      8000.0           0  \n",
       "        05.15.2138        0.0        0.0      8000.0           0  \n",
       "24981   04.22.1778        0.0        0.0      9558.0           0  \n",
       "        04.22.1778        0.0        0.0      9558.0           0  \n",
       "24982   NaN               0.0        0.0        52.0           0  \n",
       "        NaN               0.0        0.0        26.0          -1  \n",
       "        NaN               6.0        0.0        71.0           0  \n",
       "        NaN               6.0        0.0        71.0           0  \n",
       "        NaN               6.0        0.0        71.0           0  \n",
       "        NaN               6.0        0.0        71.0           0  \n",
       "        NaN               6.0        0.0        71.0           0  \n",
       "        NaN               6.0        0.0        71.0           0  \n",
       "24984   04.16.3553       93.0        0.0        10.0          -1  \n",
       "        04.16.3553       93.0        0.0        10.0           0  \n",
       "        04.16.3553       93.0        0.0        10.0           0  \n",
       "24985   04.16.3553        0.0        0.0        53.0           0  \n",
       "24986   05.15.2138        0.0        0.0       484.0           0  \n",
       "        05.15.2138        0.0        0.0       484.0           0  \n",
       "        05.15.2138        0.0        0.0       484.0           0  \n",
       "        05.15.2138        0.0        0.0       411.0           0  \n",
       "        05.15.2138        0.0        0.0       179.0           0  \n",
       "        05.15.2138        7.0        2.0      1540.0           0  \n",
       "        05.15.2138        7.0        2.0      1540.0          -1  \n",
       "        05.15.2138        7.0        2.0      1540.0           0  \n",
       "        05.15.2138        7.0        2.0      1540.0           0  \n",
       "\n",
       "[83836 rows x 8 columns]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_qual.set_index(['user_id', 'fwver']).sort_values(by=['user_id', 'time']).drop_duplicates(\n",
    "    subset=['quality_1', 'quality_2', 'quality_5', 'quality_7', 'quality_8', 'quality_10', 'quality_11'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 baseline에서 early stopping 100: 0.8016729648999995"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3633, number of negative: 8367\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3637\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302750 -> initscore=-0.834237\n",
      "[LightGBM] [Info] Start training from score -0.834237\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.799042\tvalid_0's pr_auc: 0.792403\n",
      "[40]\tvalid_0's auc: 0.803282\tvalid_0's pr_auc: 0.797189\n",
      "[60]\tvalid_0's auc: 0.801445\tvalid_0's pr_auc: 0.796304\n",
      "[80]\tvalid_0's auc: 0.801496\tvalid_0's pr_auc: 0.796672\n",
      "[100]\tvalid_0's auc: 0.801662\tvalid_0's pr_auc: 0.795217\n",
      "[120]\tvalid_0's auc: 0.801437\tvalid_0's pr_auc: 0.794896\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.802372\tvalid_0's pr_auc: 0.79811\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4828, number of negative: 7172\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3772\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.402333 -> initscore=-0.395752\n",
      "[LightGBM] [Info] Start training from score -0.395752\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.807197\tvalid_0's pr_auc: 0.328737\n",
      "[40]\tvalid_0's auc: 0.80918\tvalid_0's pr_auc: 0.344922\n",
      "[60]\tvalid_0's auc: 0.81111\tvalid_0's pr_auc: 0.35949\n",
      "[80]\tvalid_0's auc: 0.812514\tvalid_0's pr_auc: 0.367607\n",
      "[100]\tvalid_0's auc: 0.810576\tvalid_0's pr_auc: 0.358459\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.800401\tvalid_0's pr_auc: 0.375947\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4718, number of negative: 7282\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3878\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393167 -> initscore=-0.434021\n",
      "[LightGBM] [Info] Start training from score -0.434021\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.783045\tvalid_0's pr_auc: 0.404077\n",
      "[40]\tvalid_0's auc: 0.788263\tvalid_0's pr_auc: 0.404664\n",
      "[60]\tvalid_0's auc: 0.789467\tvalid_0's pr_auc: 0.413167\n",
      "[80]\tvalid_0's auc: 0.787768\tvalid_0's pr_auc: 0.403123\n",
      "[100]\tvalid_0's auc: 0.785055\tvalid_0's pr_auc: 0.396386\n",
      "[120]\tvalid_0's auc: 0.783529\tvalid_0's pr_auc: 0.391579\n",
      "[140]\tvalid_0's auc: 0.784599\tvalid_0's pr_auc: 0.391231\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.789601\tvalid_0's pr_auc: 0.414775\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4544, number of negative: 7456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3779\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378667 -> initscore=-0.495211\n",
      "[LightGBM] [Info] Start training from score -0.495211\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.805048\tvalid_0's pr_auc: 0.530674\n",
      "[40]\tvalid_0's auc: 0.809678\tvalid_0's pr_auc: 0.537282\n",
      "[60]\tvalid_0's auc: 0.812309\tvalid_0's pr_auc: 0.539848\n",
      "[80]\tvalid_0's auc: 0.81058\tvalid_0's pr_auc: 0.543907\n",
      "[100]\tvalid_0's auc: 0.811194\tvalid_0's pr_auc: 0.543234\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.804471\tvalid_0's pr_auc: 0.545458\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 2277, number of negative: 9723\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.189750 -> initscore=-1.451635\n",
      "[LightGBM] [Info] Start training from score -1.451635\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.799248\tvalid_0's pr_auc: 0.973752\n",
      "[40]\tvalid_0's auc: 0.805795\tvalid_0's pr_auc: 0.973963\n",
      "[60]\tvalid_0's auc: 0.806135\tvalid_0's pr_auc: 0.973979\n",
      "[80]\tvalid_0's auc: 0.804272\tvalid_0's pr_auc: 0.973843\n",
      "[100]\tvalid_0's auc: 0.801667\tvalid_0's pr_auc: 0.973981\n",
      "[120]\tvalid_0's auc: 0.800771\tvalid_0's pr_auc: 0.974197\n",
      "[140]\tvalid_0's auc: 0.797498\tvalid_0's pr_auc: 0.974037\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.8075\tvalid_0's pr_auc: 0.974327\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "\n",
    "train_x = error\n",
    "train_y = problem\n",
    "\n",
    "models     = []\n",
    "recalls    = []\n",
    "precisions = []\n",
    "auc_scores   = []\n",
    "threshold = 0.5\n",
    "# 파라미터 설정\n",
    "params =      {\n",
    "                'boosting_type' : 'gbdt',\n",
    "                'objective'     : 'binary',\n",
    "                'metric'        : 'auc',\n",
    "                'seed': 1015\n",
    "                }\n",
    "\n",
    "# 5 Kfold cross validation\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_idx, val_idx in k_fold.split(train_x):\n",
    "\n",
    "    # split train, validation set\n",
    "    X = train_x[train_idx]\n",
    "    y = train_y[train_idx]\n",
    "    valid_x = train_x[val_idx]\n",
    "    valid_y = train_y[val_idx]\n",
    "\n",
    "    d_train= lgb.Dataset(X, y)\n",
    "    d_val  = lgb.Dataset(valid_x, valid_y)\n",
    "    \n",
    "    #run traning\n",
    "    model = lgb.train(\n",
    "                        params,\n",
    "                        train_set       = d_train,\n",
    "                        num_boost_round = 1000,\n",
    "                        valid_sets      = d_val,\n",
    "                        feval           = f_pr_auc,\n",
    "                        verbose_eval    = 20, \n",
    "                        early_stopping_rounds = 100\n",
    "                       )\n",
    "    \n",
    "    # cal valid prediction\n",
    "    valid_prob = model.predict(valid_x)\n",
    "    valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "    \n",
    "    # cal scores\n",
    "    recall    = recall_score(    valid_y, valid_pred)\n",
    "    precision = precision_score( valid_y, valid_pred)\n",
    "    auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "    # append scores\n",
    "    models.append(model)\n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)\n",
    "    auc_scores.append(auc_score)\n",
    "\n",
    "    print('==========================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8008689113520724\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16532648/16532648 [00:45<00:00, 360384.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14999, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,  92.,   0.,   2.],\n",
       "       [  0.,   0.,   3., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ..., 113.,   1.,   2.],\n",
       "       ...,\n",
       "       [  0.,   0.,   0., ..., 329.,   2.,   3.],\n",
       "       [  0.,   0.,   0., ...,  30.,  49.,   0.],\n",
       "       [  0.,   0.,   0., ..., 269.,   0.,   0.]])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_err  = pd.read_csv('./data/test_err_data.csv')\n",
    "test_user_id_max = 44998\n",
    "test_user_id_min = 30000\n",
    "test_user_number = 14999\n",
    "id_error = test_err[['user_id','errtype']].values\n",
    "test_x = np.zeros((test_user_number,42))\n",
    "for person_idx, err in tqdm(id_error):\n",
    "    # person_idx - test_user_id_min 위치에 person_idx, errtype에 해당하는 error값을 +1\n",
    "    test_x[person_idx - test_user_id_min,err - 1] += 1\n",
    "test_x = test_x.reshape(test_x.shape[0],-1)\n",
    "print(test_x.shape)\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 35)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = np.delete(test_x,(36), axis=1)\n",
    "test_x = np.delete(test_x,(28), axis=1)\n",
    "test_x = np.delete(test_x,(22), axis=1)\n",
    "test_x = np.delete(test_x,(20), axis=1)\n",
    "test_x = np.delete(test_x,(15), axis=1)\n",
    "test_x = np.delete(test_x,(11), axis=1)\n",
    "test_x = np.delete(test_x,(6), axis=1)\n",
    "\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict(test_x)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.789681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.214027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.302600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.711387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.549704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.789681\n",
       "1    30001  0.214027\n",
       "2    30002  0.302600\n",
       "3    30003  0.711387\n",
       "4    30004  0.549704"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submssion.to_csv(\"test1.csv\", index = False)\n",
    "pd.read_csv('test1.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test1: error type feature 35개로 줄임, early_stopping=100 -> cross_validation score 0.8008689113520724"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3633, number of negative: 8367\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3637\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302750 -> initscore=-0.834237\n",
      "[LightGBM] [Info] Start training from score -0.834237\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.773009\tvalid_0's pr_auc: 0.778089\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4828, number of negative: 7172\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3772\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.402333 -> initscore=-0.395752\n",
      "[LightGBM] [Info] Start training from score -0.395752\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.78337\tvalid_0's pr_auc: 0.316498\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4718, number of negative: 7282\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3878\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393167 -> initscore=-0.434021\n",
      "[LightGBM] [Info] Start training from score -0.434021\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.749093\tvalid_0's pr_auc: 0.360671\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4544, number of negative: 7456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3779\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378667 -> initscore=-0.495211\n",
      "[LightGBM] [Info] Start training from score -0.495211\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.804471\tvalid_0's pr_auc: 0.545458\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 2277, number of negative: 9723\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3567\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.189750 -> initscore=-1.451635\n",
      "[LightGBM] [Info] Start training from score -1.451635\n",
      "Training until validation scores don't improve for 3 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.795973\tvalid_0's pr_auc: 0.973441\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "train_x = error\n",
    "train_y = problem\n",
    "\n",
    "models     = []\n",
    "recalls    = []\n",
    "precisions = []\n",
    "auc_scores   = []\n",
    "threshold = 0.5\n",
    "# 파라미터 설정\n",
    "params =      {\n",
    "                'boosting_type' : 'gbdt',\n",
    "                'objective'     : 'binary',\n",
    "                'metric'        : 'auc',\n",
    "                'seed': 1015\n",
    "                }\n",
    "\n",
    "# 5 Kfold cross validation\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_idx, val_idx in k_fold.split(train_x):\n",
    "\n",
    "    # split train, validation set\n",
    "    X = train_x[train_idx]\n",
    "    y = train_y[train_idx]\n",
    "    valid_x = train_x[val_idx]\n",
    "    valid_y = train_y[val_idx]\n",
    "\n",
    "    d_train= lgb.Dataset(X, y)\n",
    "    d_val  = lgb.Dataset(valid_x, valid_y)\n",
    "    \n",
    "    #run traning\n",
    "    model = lgb.train(\n",
    "                        params,\n",
    "                        train_set       = d_train,\n",
    "                        num_boost_round = 1000,\n",
    "                        valid_sets      = d_val,\n",
    "                        feval           = f_pr_auc,\n",
    "                        verbose_eval    = 20, \n",
    "                        early_stopping_rounds = 3\n",
    "                       )\n",
    "    \n",
    "    # cal valid prediction\n",
    "    valid_prob = model.predict(valid_x)\n",
    "    valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "    \n",
    "    # cal scores\n",
    "    recall    = recall_score(    valid_y, valid_pred)\n",
    "    precision = precision_score( valid_y, valid_pred)\n",
    "    auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "    # append scores\n",
    "    models.append(model)\n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)\n",
    "    auc_scores.append(auc_score)\n",
    "\n",
    "    print('==========================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7811829297500836\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16532648/16532648 [00:45<00:00, 362681.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14999, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.483474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.274291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.318271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.507457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.423353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.483474\n",
       "1    30001  0.274291\n",
       "2    30002  0.318271\n",
       "3    30003  0.507457\n",
       "4    30004  0.423353"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_err  = pd.read_csv('./data/test_err_data.csv')\n",
    "test_user_id_max = 44998\n",
    "test_user_id_min = 30000\n",
    "test_user_number = 14999\n",
    "id_error = test_err[['user_id','errtype']].values\n",
    "test_x = np.zeros((test_user_number,42))\n",
    "for person_idx, err in tqdm(id_error):\n",
    "    # person_idx - test_user_id_min 위치에 person_idx, errtype에 해당하는 error값을 +1\n",
    "    test_x[person_idx - test_user_id_min,err - 1] += 1\n",
    "test_x = test_x.reshape(test_x.shape[0],-1)\n",
    "print(test_x.shape)\n",
    "\n",
    "test_x = np.delete(test_x,(36), axis=1)\n",
    "test_x = np.delete(test_x,(28), axis=1)\n",
    "test_x = np.delete(test_x,(22), axis=1)\n",
    "test_x = np.delete(test_x,(20), axis=1)\n",
    "test_x = np.delete(test_x,(15), axis=1)\n",
    "test_x = np.delete(test_x,(11), axis=1)\n",
    "test_x = np.delete(test_x,(6), axis=1)\n",
    "\n",
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict(test_x)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test2.csv\", index = False)\n",
    "pd.read_csv('test2.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test2: error type 35, early stopping 3 -> cross_val: 0.7811829297500836 -> errortype 걍 놔두자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#id_error = train_err[['user_id','errtype']].values\n",
    "#error = np.zeros((train_user_number,42))\n",
    "\n",
    "#for person_idx, err in tqdm(id_error):\n",
    "    # person_idx - train_user_id_min 위치에 person_idx, errtype에 해당하는 error값을 +1\n",
    "#    error[person_idx - train_user_id_min,err - 1] += 1\n",
    "    \n",
    "train_prob = pd.read_csv('./data/train_problem_data.csv')\n",
    "problem = np.zeros(15000)\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "problem[train_prob.user_id.unique()-10000] = 1 \n",
    "\n",
    "#train_x = error\n",
    "train_y = problem\n",
    "    \n",
    "#train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qual_cnt = train_qual.groupby(by='user_id').count()['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.,  0., 96., ..., 24.,  0.,  0.])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qual_cnt = np.zeros(15000)\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "qual_cnt[train_qual_cnt.index-10000] = train_qual_cnt.loc[train_qual_cnt.index]\n",
    "qual_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  8., ...,  0.,  0., 24.],\n",
       "       [ 0.,  0.,  0., ..., 56.,  1.,  0.],\n",
       "       [ 0.,  0.,  2., ...,  0.,  0., 96.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  8.,  5., 24.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  4., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_ = np.concatenate((train_x, qual_cnt[:, None]), axis=1)\n",
    "train_x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3633, number of negative: 8367\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4456\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302750 -> initscore=-0.834237\n",
      "[LightGBM] [Info] Start training from score -0.834237\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.801231\tvalid_0's pr_auc: 0.794951\n",
      "[40]\tvalid_0's auc: 0.804923\tvalid_0's pr_auc: 0.798824\n",
      "[60]\tvalid_0's auc: 0.806443\tvalid_0's pr_auc: 0.799013\n",
      "[80]\tvalid_0's auc: 0.806776\tvalid_0's pr_auc: 0.800289\n",
      "[100]\tvalid_0's auc: 0.80605\tvalid_0's pr_auc: 0.800399\n",
      "[120]\tvalid_0's auc: 0.804943\tvalid_0's pr_auc: 0.800081\n",
      "[140]\tvalid_0's auc: 0.804287\tvalid_0's pr_auc: 0.799426\n",
      "[160]\tvalid_0's auc: 0.803541\tvalid_0's pr_auc: 0.799379\n",
      "[180]\tvalid_0's auc: 0.804429\tvalid_0's pr_auc: 0.80026\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.807187\tvalid_0's pr_auc: 0.801067\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4828, number of negative: 7172\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4609\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.402333 -> initscore=-0.395752\n",
      "[LightGBM] [Info] Start training from score -0.395752\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.806962\tvalid_0's pr_auc: 0.313289\n",
      "[40]\tvalid_0's auc: 0.81187\tvalid_0's pr_auc: 0.348173\n",
      "[60]\tvalid_0's auc: 0.812222\tvalid_0's pr_auc: 0.351668\n",
      "[80]\tvalid_0's auc: 0.81117\tvalid_0's pr_auc: 0.356298\n",
      "[100]\tvalid_0's auc: 0.809686\tvalid_0's pr_auc: 0.354757\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.804039\tvalid_0's pr_auc: 0.374951\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4718, number of negative: 7282\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4716\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393167 -> initscore=-0.434021\n",
      "[LightGBM] [Info] Start training from score -0.434021\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.779291\tvalid_0's pr_auc: 0.38321\n",
      "[40]\tvalid_0's auc: 0.782981\tvalid_0's pr_auc: 0.395269\n",
      "[60]\tvalid_0's auc: 0.785604\tvalid_0's pr_auc: 0.398551\n",
      "[80]\tvalid_0's auc: 0.784241\tvalid_0's pr_auc: 0.399709\n",
      "[100]\tvalid_0's auc: 0.782963\tvalid_0's pr_auc: 0.392026\n",
      "[120]\tvalid_0's auc: 0.783903\tvalid_0's pr_auc: 0.386146\n",
      "[140]\tvalid_0's auc: 0.784954\tvalid_0's pr_auc: 0.386234\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's auc: 0.785991\tvalid_0's pr_auc: 0.401427\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4544, number of negative: 7456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4619\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378667 -> initscore=-0.495211\n",
      "[LightGBM] [Info] Start training from score -0.495211\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.811062\tvalid_0's pr_auc: 0.538691\n",
      "[40]\tvalid_0's auc: 0.814335\tvalid_0's pr_auc: 0.54116\n",
      "[60]\tvalid_0's auc: 0.815727\tvalid_0's pr_auc: 0.541133\n",
      "[80]\tvalid_0's auc: 0.816052\tvalid_0's pr_auc: 0.545068\n",
      "[100]\tvalid_0's auc: 0.815228\tvalid_0's pr_auc: 0.543145\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.8067\tvalid_0's pr_auc: 0.547331\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 2277, number of negative: 9723\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4377\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 42\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.189750 -> initscore=-1.451635\n",
      "[LightGBM] [Info] Start training from score -1.451635\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.810249\tvalid_0's pr_auc: 0.975457\n",
      "[40]\tvalid_0's auc: 0.8109\tvalid_0's pr_auc: 0.97514\n",
      "[60]\tvalid_0's auc: 0.809903\tvalid_0's pr_auc: 0.974773\n",
      "[80]\tvalid_0's auc: 0.808451\tvalid_0's pr_auc: 0.974823\n",
      "[100]\tvalid_0's auc: 0.803985\tvalid_0's pr_auc: 0.974294\n",
      "[120]\tvalid_0's auc: 0.802767\tvalid_0's pr_auc: 0.974261\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.811839\tvalid_0's pr_auc: 0.975735\n",
      "==========================================================\n",
      "0.8031513363978476\n"
     ]
    }
   ],
   "source": [
    "train_x = train_x_\n",
    "train_y = problem\n",
    "\n",
    "models     = []\n",
    "recalls    = []\n",
    "precisions = []\n",
    "auc_scores   = []\n",
    "threshold = 0.5\n",
    "# 파라미터 설정\n",
    "params =      {\n",
    "                'boosting_type' : 'gbdt',\n",
    "                'objective'     : 'binary',\n",
    "                'metric'        : 'auc',\n",
    "                'seed': 1015\n",
    "                }\n",
    "\n",
    "# 5 Kfold cross validation\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_idx, val_idx in k_fold.split(train_x):\n",
    "\n",
    "    # split train, validation set\n",
    "    X = train_x[train_idx]\n",
    "    y = train_y[train_idx]\n",
    "    valid_x = train_x[val_idx]\n",
    "    valid_y = train_y[val_idx]\n",
    "\n",
    "    d_train= lgb.Dataset(X, y)\n",
    "    d_val  = lgb.Dataset(valid_x, valid_y)\n",
    "    \n",
    "    #run traning\n",
    "    model = lgb.train(\n",
    "                        params,\n",
    "                        train_set       = d_train,\n",
    "                        num_boost_round = 1000,\n",
    "                        valid_sets      = d_val,\n",
    "                        feval           = f_pr_auc,\n",
    "                        verbose_eval    = 20, \n",
    "                        early_stopping_rounds = 100\n",
    "                       )\n",
    "    \n",
    "    # cal valid prediction\n",
    "    valid_prob = model.predict(valid_x)\n",
    "    valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "    \n",
    "    # cal scores\n",
    "    recall    = recall_score(    valid_y, valid_pred)\n",
    "    precision = precision_score( valid_y, valid_pred)\n",
    "    auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "    # append scores\n",
    "    models.append(model)\n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)\n",
    "    auc_scores.append(auc_score)\n",
    "\n",
    "    print('==========================================================')\n",
    "    \n",
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16532648/16532648 [00:46<00:00, 355410.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14999, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_err  = pd.read_csv('./data/test_err_data.csv')\n",
    "test_user_id_max = 44998\n",
    "test_user_id_min = 30000\n",
    "test_user_number = 14999\n",
    "id_error = test_err[['user_id','errtype']].values\n",
    "test_x = np.zeros((test_user_number,42))\n",
    "for person_idx, err in tqdm(id_error):\n",
    "    # person_idx - test_user_id_min 위치에 person_idx, errtype에 해당하는 error값을 +1\n",
    "    test_x[person_idx - test_user_id_min,err - 1] += 1\n",
    "test_x = test_x.reshape(test_x.shape[0],-1)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 12.,  36., 120., ..., 108.,  24.,   0.])"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_qual = pd.read_csv('./data/test_quality_data.csv')\n",
    "\n",
    "test_qual_cnt = test_qual.groupby(by='user_id').count()['time']\n",
    "\n",
    "qual_cnt = np.zeros(14999)\n",
    "qual_cnt[test_qual_cnt.index-test_user_id_min] = test_qual_cnt.loc[test_qual_cnt.index]\n",
    "qual_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,   0.,   2.,  12.],\n",
       "       [  0.,   0.,   3., ...,   0.,   0.,  36.],\n",
       "       [  0.,   0.,   0., ...,   1.,   2., 120.],\n",
       "       ...,\n",
       "       [  0.,   0.,   0., ...,   2.,   3., 108.],\n",
       "       [  0.,   0.,   0., ...,  49.,   0.,  24.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_ = np.concatenate((test_x, qual_cnt[:, None]), axis=1)\n",
    "test_x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.756014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.211883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.311274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.697311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.580164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.756014\n",
       "1    30001  0.211883\n",
       "2    30002  0.311274\n",
       "3    30003  0.697311\n",
       "4    30004  0.580164"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y_list = []\n",
    "for model in models:\n",
    "    pred_y = model.predict(test_x_)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test3.csv\", index = False)\n",
    "pd.read_csv('test3.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test3: quality log count column 추가, early stopping 100 -> cross val: 0.8031513363978476"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n",
      "Collecting xgboost\n",
      "\u001b[?25l  Downloading http://mirror.kakao.com/pypi/packages/35/cc/fd3d5fc6b6616a03385a0f6492cc77a253940d1026406ecc07597095e381/xgboost-1.2.1-py3-none-manylinux2010_x86_64.whl (148.9MB)\n",
      "\u001b[K     |████████████████████████████████| 148.9MB 83.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from xgboost) (1.16.4)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from xgboost) (1.2.0)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n",
      "Requirement already satisfied: lightgbm in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (3.1.0)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from lightgbm) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from lightgbm) (0.21.3)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from lightgbm) (1.16.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (0.14.0)\n",
      "Looking in indexes: http://ftp.daumkakao.com/pypi/simple\n",
      "Collecting catboost\n",
      "\u001b[?25l  Downloading http://mirror.kakao.com/pypi/packages/7e/c1/c1c4707013f9e2f8a96899dd3a87f66c9167d6d776a6dc8fe7ec8678d446/catboost-0.24.3-cp36-none-manylinux1_x86_64.whl (66.3MB)\n",
      "\u001b[K     |████████████████████████████████| 66.3MB 22.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: plotly in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from catboost) (4.3.0)\n",
      "Collecting graphviz\n",
      "  Downloading http://mirror.kakao.com/pypi/packages/64/72/f4f4205db2a58e7a49e8190c0b49e9669d7ecadf6385b5bcdcf910354a6d/graphviz-0.15-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from catboost) (0.24.2)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from catboost) (1.11.0)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from catboost) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from catboost) (1.16.4)\n",
      "Requirement already satisfied: matplotlib in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas>=0.24.0->catboost) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pandas>=0.24.0->catboost) (2.7.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib->catboost) (2.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib->catboost) (1.0.1)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.6.0.post20191029)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-0.24.3 graphviz-0.15\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import lightgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "import catboost\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'neg_squared_error' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[0;34m(scoring)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'neg_squared_error'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-517-1d64b68e3ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m                           cv = 5)\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mlightgbm_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# LightBGM with tuned hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[0;32m--> 609\u001b[0;31m             self.estimator, scoring=self.scoring)\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[0;34m(estimator, scoring)\u001b[0m\n\u001b[1;32m    340\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[1;32m    341\u001b[0m                                                           str):\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mscorers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    270\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m# Heuristic to ensure user has not passed a metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[0;34m(scoring)\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError('%r is not a valid scoring value. '\n\u001b[1;32m    231\u001b[0m                              \u001b[0;34m'Use sorted(sklearn.metrics.SCORERS.keys()) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                              'to get valid options.' % (scoring))\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'neg_squared_error' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "train_x = train_x_\n",
    "train_y = problem\n",
    "\n",
    "models     = []\n",
    "recalls    = []\n",
    "precisions = []\n",
    "auc_scores   = []\n",
    "threshold = 0.5\n",
    "\n",
    "# split train, validation set\n",
    "X = train_x[train_idx]\n",
    "y = train_y[train_idx]\n",
    "valid_x = train_x[val_idx]\n",
    "valid_y = train_y[val_idx]\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(booster='gbtree', objective='reg:squarederror')\n",
    "\n",
    "param_lst = {\n",
    "'learning_rate' : [0.01, 0.1, 0.15, 0.3, 0.5],\n",
    "'n_estimators' : [100, 500, 1000, 2000, 3000],\n",
    "'max_depth' : [3, 6, 9],\n",
    "'min_child_weight' : [1, 5, 10, 20],\n",
    "'reg_alpha' : [0.001, 0.01, 0.1],\n",
    "'reg_lambda' : [0.001, 0.01, 0.1]\n",
    "}\n",
    "xgb_reg = RandomizedSearchCV(estimator = model_xgb, param_distributions = param_lst,\n",
    "                          n_iter = 100, scoring = 'neg_mean_squared_error',\n",
    "                          cv = 5)\n",
    "\n",
    "xgb_search = xgb_reg.fit(train_x, train_y)\n",
    "\n",
    "# XGB with tune hyperparameters\n",
    "best_param = xgb_search.best_params_\n",
    "model_xgb = xgb.XGBRegressor(**best_param)\n",
    "\n",
    "\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0001, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMRegressor(boosting_type='gbdt',objective='regression', max_depth=-1,\n",
    "                lambda_l1=0.0001, lambda_l2=0, learning_rate=0.1,\n",
    "                n_estimators=100, max_bin=200, min_child_samples=20, \n",
    "                bagging_fraction=0.75, bagging_freq=5,\n",
    "                bagging_seed=7, feature_fraction=0.8,\n",
    "                feature_fraction_seed=7, verbose=-1)\n",
    "param_lst = {\n",
    "'max_depth' : [2, 5, 8, 10],\n",
    "'learning_rate' : [0.001, 0.01, 0.1, 0.2],\n",
    "'n_estimators' : [100, 300, 500, 1000, 1500],\n",
    "'lambda_l1' : [0.0001, 0.001, 0.01],\n",
    "'lambda_l2' : [0, 0.0001, 0.001, 0.01],\n",
    "'feature_fraction' : [0.4, 0.6, 0.8],\n",
    "'min_child_samples' : [5, 10, 20, 25]\n",
    "}\n",
    "\n",
    "lightgbm = RandomizedSearchCV(estimator = lgbm, param_distributions = param_lst,\n",
    "                          n_iter = 100, scoring = 'neg_mean_squared_error',\n",
    "                          cv = 5)\n",
    "\n",
    "lightgbm_search = lightgbm.fit(train_x, train_y)\n",
    "\n",
    "# LightBGM with tuned hyperparameters\n",
    "best_param = lightgbm_search.best_params_\n",
    "lgbm = LGBMRegressor(**best_param)\n",
    "\n",
    "#############\n",
    "cb = CatBoostRegressor(loss_function='RMSE', logging_level='Silent')\n",
    "\n",
    "param_lst = {\n",
    "'n_estimators' : [100, 300, 500, 1000, 1300, 1600],\n",
    "'learning_rate' : [0.0001, 0.001, 0.01, 0.1],\n",
    "'l2_leaf_reg' : [0.001, 0.01, 0.1],\n",
    "'random_strength' : [0.25, 0.5 ,1],\n",
    "'max_depth' : [3, 6, 9],\n",
    "'min_child_samples' : [2, 5, 10, 15, 20],\n",
    "'rsm' : [0.5, 0.7, 0.9],\n",
    "\n",
    "}\n",
    "\n",
    "catboost = RandomizedSearchCV(estimator = cb, param_distributions = param_lst,\n",
    "                              n_iter = 100, scoring = 'neg_mean_squared_error',\n",
    "                              cv = 5)\n",
    "\n",
    "catboost_search = catboost.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# CatBoost with tuned hyperparams\n",
    "best_param = catboost_search.best_params_\n",
    "cb = CatBoostRegressor(logging_level='Silent', **best_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'rsm': 0.5,\n",
       "  'random_strength': 0.5,\n",
       "  'n_estimators': 1000,\n",
       "  'min_child_samples': 5,\n",
       "  'max_depth': 9,\n",
       "  'learning_rate': 0.01,\n",
       "  'l2_leaf_reg': 0.001},\n",
       " {'n_estimators': 1000,\n",
       "  'min_child_samples': 5,\n",
       "  'max_depth': 10,\n",
       "  'learning_rate': 0.01,\n",
       "  'lambda_l2': 0,\n",
       "  'lambda_l1': 0.0001,\n",
       "  'feature_fraction': 0.6},\n",
       " {'reg_lambda': 0.1,\n",
       "  'reg_alpha': 0.01,\n",
       "  'n_estimators': 1000,\n",
       "  'min_child_weight': 10,\n",
       "  'max_depth': 6,\n",
       "  'learning_rate': 0.01})"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_search.best_params_, lightgbm_search.best_params_, xgb_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              feature_fraction=0.6, importance_type='split', lambda_l1=0.0001,\n",
       "              lambda_l2=0, learning_rate=0.01, max_depth=10,\n",
       "              min_child_samples=5, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=1000, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm model auc score: 0.8964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('lgbm model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model auc score: 0.8895\n"
     ]
    }
   ],
   "source": [
    "model_xgb.fit(train_x, train_y)\n",
    "y_pred = model_xgb.predict(train_x)\n",
    "print('XGBoost model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cb model auc score: 0.8897\n"
     ]
    }
   ],
   "source": [
    "cb.fit(train_x, train_y)\n",
    "y_pred = cb.predict(train_x)\n",
    "print('cb model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.875263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.199652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.286769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.831189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.729701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.875263\n",
       "1    30001  0.199652\n",
       "2    30002  0.286769\n",
       "3    30003  0.831189\n",
       "4    30004  0.729701"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y_list = []\n",
    "for model in [lgbm, model_xgb, cb]:\n",
    "    pred_y = model.predict(test_x_)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test4.csv\", index = False)\n",
    "pd.read_csv('test4.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test4: lgb, xgb, cb hyper parameter tuning, ensembling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85968094, 0.19027789, 0.2733351 , ..., 0.59826909, 0.8382008 ,\n",
       "       0.35208991])"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = lgbm.predict(test_x_)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.859681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.190278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.273335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.818343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.749239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.859681\n",
       "1    30001  0.190278\n",
       "2    30002  0.273335\n",
       "3    30003  0.818343\n",
       "4    30004  0.749239"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = lgbm.predict(test_x_)\n",
    "    \n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_y.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test5.csv\", index = False)\n",
    "pd.read_csv('test5.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test5: 위의 모델에서 lgbm만 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 7), (15000, 43))"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_qual_0.shape, train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 50)"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_q0 = np.concatenate((train_x, full_qual_0), axis=1)\n",
    "train_x_q0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 43)"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fwver</th>\n",
       "      <th>time</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>20201129090000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       fwver            time  quality_1  quality_2  quality_5  \\\n",
       "0    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "1    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "2    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "3    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "4    10000  05.15.2138  20201129090000          0        0.0        0.0   \n",
       "\n",
       "   quality_7  quality_8  quality_10  quality_11  \n",
       "0        0.0        0.0         4.0           0  \n",
       "1        0.0        0.0         4.0           0  \n",
       "2        0.0        0.0         4.0           0  \n",
       "3        0.0        0.0         4.0           0  \n",
       "4        0.0        0.0         4.0           0  "
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_qual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fwver</th>\n",
       "      <th>time</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>20201128195000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30000</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>20201128195000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>20201128195000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30000</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>20201128195000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30000</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>20201128195000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       fwver            time  quality_1  quality_2  quality_5  \\\n",
       "0    30000  04.33.1261  20201128195000        0.0        0.0        0.0   \n",
       "1    30000  04.33.1261  20201128195000        0.0        0.0        0.0   \n",
       "2    30000  04.33.1261  20201128195000        0.0        0.0        0.0   \n",
       "3    30000  04.33.1261  20201128195000        0.0        0.0        0.0   \n",
       "4    30000  04.33.1261  20201128195000        0.0        0.0        0.0   \n",
       "\n",
       "   quality_7  quality_8  quality_10  quality_11  \n",
       "0        5.0        0.0         2.0           0  \n",
       "1        5.0        0.0         2.0           0  \n",
       "2        5.0        0.0         2.0           0  \n",
       "3        5.0        0.0         2.0           0  \n",
       "4        5.0        0.0         2.0           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  1.66666667e-01 ...  0.00000000e+00\n",
      "   2.00000000e+00  0.00000000e+00]\n",
      " [-2.50000000e-01 -2.50000000e-01  7.09444444e+01 ...  0.00000000e+00\n",
      "   8.54333333e+02 -2.50000000e-01]\n",
      " [-1.25000000e-01 -1.25000000e-01  9.83333333e-01 ...  0.00000000e+00\n",
      "   1.33000000e+01 -1.25000000e-01]\n",
      " ...\n",
      " [-4.62962963e-02 -4.62962963e-02  2.96296296e-01 ...  0.00000000e+00\n",
      "   4.11111111e+00 -4.62962963e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  5.41666667e-01 ...  0.00000000e+00\n",
      "   6.50000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "test_qual_num = test_qual[['quality_' + str(i) for i in range(13)]].copy()\n",
    "\n",
    "del test_qual_num['quality_3']\n",
    "del test_qual_num['quality_4']\n",
    "del test_qual_num['quality_0']\n",
    "del test_qual_num['quality_6']\n",
    "del test_qual_num['quality_9']\n",
    "del test_qual_num['quality_12']\n",
    "\n",
    "obj_col = ['quality_1', 'quality_5', 'quality_7', 'quality_8', 'quality_10']\n",
    "num_col = ['quality_2', 'quality_11']\n",
    "\n",
    "for col in obj_col:\n",
    "    test_qual_num[col] = test_qual_num[col].astype(str).str.replace(',', '').astype(float)\n",
    "    \n",
    "new_test_qual = test_qual[['user_id', 'fwver', 'time']].join(test_qual_num)\n",
    "display(new_test_qual.head())\n",
    "\n",
    "test_qual_0 = new_test_qual.fillna(0)\n",
    "qual_0_t = test_qual_0.groupby('user_id').mean().loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0_t = np.zeros((14999, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0_t[qual_0_t.index-test_user_id_min] = qual_0_t.loc[qual_0_t.index]\n",
    "print(full_qual_0_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14999, 7), (14999, 43))"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_qual_0_t.shape, test_x_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 50)"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_q0 = np.concatenate((test_x_, full_qual_0_t), axis=1)\n",
    "test_x_q0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "lgbm model auc score: 0.9009\n",
      "XGBoost model auc score: 0.8942\n",
      "cb model auc score: 0.8974\n",
      "mean value:  [0.17677089 0.98289207 0.30494357 ... 0.38850456 0.18925122 0.15439553]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.884624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.264988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.275618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.784076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.660604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.884624\n",
       "1    30001  0.264988\n",
       "2    30002  0.275618\n",
       "3    30003  0.784076\n",
       "4    30004  0.660604"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(train_x_q0, train_y)\n",
    "y_pred1 = lgbm.predict(train_x_q0)\n",
    "print('lgbm model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred1)))\n",
    "\n",
    "model_xgb.fit(train_x_q0, train_y)\n",
    "y_pred2 = model_xgb.predict(train_x_q0)\n",
    "print('XGBoost model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred2)))\n",
    "\n",
    "cb.fit(train_x_q0, train_y)\n",
    "y_pred3 = cb.predict(train_x_q0)\n",
    "print('cb model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred3)))\n",
    "\n",
    "print('mean value: ', (y_pred1 + y_pred2 + y_pred3) / 3)\n",
    "\n",
    "pred_y_list = []\n",
    "for model in [lgbm, model_xgb, cb]:\n",
    "    pred_y = model.predict(test_x_q0)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test6.csv\", index = False)\n",
    "pd.read_csv('test6.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8975"
      ]
     },
     "execution_count": 707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.9009 + 0.8942 + 0.8974) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test6: qulaity 7개 열 추가, nan 값은 0으로 채우고 평균 값을 대표 값으로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_0 = train_qual_0.groupby('user_id').max().loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0 = np.zeros((15000, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0[qual_0.index-10000] = qual_0.loc[qual_0.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 50)"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_q0 = np.concatenate((train_x, full_qual_0), axis=1)\n",
    "train_x_q0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>fwver</th>\n",
       "      <th>time</th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>20201128195000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30000</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>20201128195000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30000</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>20201128195000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30000</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>20201128195000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30000</td>\n",
       "      <td>04.33.1261</td>\n",
       "      <td>20201128195000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       fwver            time  quality_1  quality_2  quality_5  \\\n",
       "0    30000  04.33.1261  20201128195000        0.0        0.0        0.0   \n",
       "1    30000  04.33.1261  20201128195000        0.0        0.0        0.0   \n",
       "2    30000  04.33.1261  20201128195000        0.0        0.0        0.0   \n",
       "3    30000  04.33.1261  20201128195000        0.0        0.0        0.0   \n",
       "4    30000  04.33.1261  20201128195000        0.0        0.0        0.0   \n",
       "\n",
       "   quality_7  quality_8  quality_10  quality_11  \n",
       "0        5.0        0.0         2.0           0  \n",
       "1        5.0        0.0         2.0           0  \n",
       "2        5.0        0.0         2.0           0  \n",
       "3        5.0        0.0         2.0           0  \n",
       "4        5.0        0.0         2.0           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000e+00 0.000e+00 2.000e+00 ... 0.000e+00 2.000e+00 0.000e+00]\n",
      " [0.000e+00 0.000e+00 1.287e+03 ... 0.000e+00 2.556e+03 0.000e+00]\n",
      " [0.000e+00 0.000e+00 4.600e+01 ... 0.000e+00 4.900e+01 0.000e+00]\n",
      " ...\n",
      " [0.000e+00 0.000e+00 5.000e+00 ... 0.000e+00 9.000e+00 0.000e+00]\n",
      " [0.000e+00 0.000e+00 3.000e+00 ... 0.000e+00 1.000e+01 0.000e+00]\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 0.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "test_qual_num = test_qual[['quality_' + str(i) for i in range(13)]].copy()\n",
    "\n",
    "del test_qual_num['quality_3']\n",
    "del test_qual_num['quality_4']\n",
    "del test_qual_num['quality_0']\n",
    "del test_qual_num['quality_6']\n",
    "del test_qual_num['quality_9']\n",
    "del test_qual_num['quality_12']\n",
    "\n",
    "obj_col = ['quality_1', 'quality_5', 'quality_7', 'quality_8', 'quality_10']\n",
    "num_col = ['quality_2', 'quality_11']\n",
    "\n",
    "for col in obj_col:\n",
    "    test_qual_num[col] = test_qual_num[col].astype(str).str.replace(',', '').astype(float)\n",
    "    \n",
    "new_test_qual = test_qual[['user_id', 'fwver', 'time']].join(test_qual_num)\n",
    "display(new_test_qual.head())\n",
    "\n",
    "test_qual_0 = new_test_qual.fillna(0)\n",
    "qual_0_t = test_qual_0.groupby('user_id').max().loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0_t = np.zeros((14999, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0_t[qual_0_t.index-test_user_id_min] = qual_0_t.loc[qual_0_t.index]\n",
    "print(full_qual_0_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 50)"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_q0 = np.concatenate((test_x_, full_qual_0_t), axis=1)\n",
    "test_x_q0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "lgbm model auc score: 0.8990\n",
      "XGBoost model auc score: 0.8946\n",
      "cb model auc score: 0.8929\n",
      "mean value:  0.8954765066666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.879123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.271169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.253773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.835108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.691965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.879123\n",
       "1    30001  0.271169\n",
       "2    30002  0.253773\n",
       "3    30003  0.835108\n",
       "4    30004  0.691965"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(train_x_q0, train_y)\n",
    "y_pred1 = lgbm.predict(train_x_q0)\n",
    "print('lgbm model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred1)))\n",
    "\n",
    "model_xgb.fit(train_x_q0, train_y)\n",
    "y_pred2 = model_xgb.predict(train_x_q0)\n",
    "print('XGBoost model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred2)))\n",
    "\n",
    "cb.fit(train_x_q0, train_y)\n",
    "y_pred3 = cb.predict(train_x_q0)\n",
    "print('cb model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred3)))\n",
    "\n",
    "print('mean value: ', (roc_auc_score(train_y, y_pred1) + roc_auc_score(train_y, y_pred2) + roc_auc_score(train_y, y_pred3)) / 3)\n",
    "\n",
    "pred_y_list = []\n",
    "for model in [lgbm, model_xgb, cb]:\n",
    "    pred_y = model.predict(test_x_q0)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test7.csv\", index = False)\n",
    "pd.read_csv('test7.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test7: test6와 동일한 조건, 평균값 대신 최대값 사용 -> test6보다 0.2% 점수 상승"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 50)\n",
      "[[ 0.0000e+00  0.0000e+00  2.0000e+00 ...  0.0000e+00  2.4000e+01\n",
      "   0.0000e+00]\n",
      " [-9.0000e+00 -9.0000e+00  2.5540e+03 ...  0.0000e+00  3.0756e+04\n",
      "  -9.0000e+00]\n",
      " [-1.5000e+01 -1.5000e+01  1.1800e+02 ...  0.0000e+00  1.5960e+03\n",
      "  -1.5000e+01]\n",
      " ...\n",
      " [-5.0000e+00 -5.0000e+00  3.2000e+01 ...  0.0000e+00  4.4400e+02\n",
      "  -5.0000e+00]\n",
      " [ 0.0000e+00  0.0000e+00  1.3000e+01 ...  0.0000e+00  1.5600e+02\n",
      "   0.0000e+00]\n",
      " [ 0.0000e+00  0.0000e+00  0.0000e+00 ...  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00]]\n",
      "(14999, 50)\n"
     ]
    }
   ],
   "source": [
    "qual_0 = train_qual_0.groupby('user_id').sum().loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0 = np.zeros((15000, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0[qual_0.index-10000] = qual_0.loc[qual_0.index]\n",
    "train_x_q0 = np.concatenate((train_x, full_qual_0), axis=1)\n",
    "print(train_x_q0.shape)\n",
    "\n",
    "test_qual_num = test_qual[['quality_' + str(i) for i in range(13)]].copy()\n",
    "\n",
    "del test_qual_num['quality_3']\n",
    "del test_qual_num['quality_4']\n",
    "del test_qual_num['quality_0']\n",
    "del test_qual_num['quality_6']\n",
    "del test_qual_num['quality_9']\n",
    "del test_qual_num['quality_12']\n",
    "\n",
    "obj_col = ['quality_1', 'quality_5', 'quality_7', 'quality_8', 'quality_10']\n",
    "num_col = ['quality_2', 'quality_11']\n",
    "\n",
    "for col in obj_col:\n",
    "    test_qual_num[col] = test_qual_num[col].astype(str).str.replace(',', '').astype(float)\n",
    "    \n",
    "new_test_qual = test_qual[['user_id', 'fwver', 'time']].join(test_qual_num)\n",
    "#display(new_test_qual.head())\n",
    "\n",
    "test_qual_0 = new_test_qual.fillna(0)\n",
    "qual_0_t = test_qual_0.groupby('user_id').sum().loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0_t = np.zeros((14999, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0_t[qual_0_t.index-test_user_id_min] = qual_0_t.loc[qual_0_t.index]\n",
    "print(full_qual_0_t)\n",
    "test_x_q0 = np.concatenate((test_x_, full_qual_0_t), axis=1)\n",
    "print(test_x_q0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "lgbm model auc score: 0.8998\n",
      "XGBoost model auc score: 0.8937\n",
      "cb model auc score: 0.8939\n",
      "mean value:  0.8957729199999999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.863248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.193087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.252897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.818819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.687278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.863248\n",
       "1    30001  0.193087\n",
       "2    30002  0.252897\n",
       "3    30003  0.818819\n",
       "4    30004  0.687278"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(train_x_q0, train_y)\n",
    "y_pred1 = lgbm.predict(train_x_q0)\n",
    "print('lgbm model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred1)))\n",
    "\n",
    "model_xgb.fit(train_x_q0, train_y)\n",
    "y_pred2 = model_xgb.predict(train_x_q0)\n",
    "print('XGBoost model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred2)))\n",
    "\n",
    "cb.fit(train_x_q0, train_y)\n",
    "y_pred3 = cb.predict(train_x_q0)\n",
    "print('cb model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred3)))\n",
    "\n",
    "print('mean value: ', (roc_auc_score(train_y, y_pred1) + roc_auc_score(train_y, y_pred2) + roc_auc_score(train_y, y_pred3)) / 3)\n",
    "\n",
    "pred_y_list = []\n",
    "for model in [lgbm, model_xgb, cb]:\n",
    "    pred_y = model.predict(test_x_q0)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test8.csv\", index = False)\n",
    "pd.read_csv('test8.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test8: test6와 같은 조건, 평균 대신 합 사용 -> test7보다 0.001 오름..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 50)\n",
      "[[0.  0.  0.  ... 0.  2.  0. ]\n",
      " [0.  0.  0.  ... 0.  4.  0. ]\n",
      " [0.  0.  0.  ... 0.  4.5 0. ]\n",
      " ...\n",
      " [0.  0.  0.  ... 0.  3.  0. ]\n",
      " [0.  0.  0.  ... 0.  6.5 0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]]\n",
      "(14999, 50)\n"
     ]
    }
   ],
   "source": [
    "qual_0 = train_qual_0.groupby('user_id').median().loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0 = np.zeros((15000, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0[qual_0.index-10000] = qual_0.loc[qual_0.index]\n",
    "train_x_q0 = np.concatenate((train_x, full_qual_0), axis=1)\n",
    "print(train_x_q0.shape)\n",
    "\n",
    "test_qual_num = test_qual[['quality_' + str(i) for i in range(13)]].copy()\n",
    "\n",
    "del test_qual_num['quality_3']\n",
    "del test_qual_num['quality_4']\n",
    "del test_qual_num['quality_0']\n",
    "del test_qual_num['quality_6']\n",
    "del test_qual_num['quality_9']\n",
    "del test_qual_num['quality_12']\n",
    "\n",
    "obj_col = ['quality_1', 'quality_5', 'quality_7', 'quality_8', 'quality_10']\n",
    "num_col = ['quality_2', 'quality_11']\n",
    "\n",
    "for col in obj_col:\n",
    "    test_qual_num[col] = test_qual_num[col].astype(str).str.replace(',', '').astype(float)\n",
    "    \n",
    "new_test_qual = test_qual[['user_id', 'fwver', 'time']].join(test_qual_num)\n",
    "#display(new_test_qual.head())\n",
    "\n",
    "test_qual_0 = new_test_qual.fillna(0)\n",
    "qual_0_t = test_qual_0.groupby('user_id').median().loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0_t = np.zeros((14999, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0_t[qual_0_t.index-test_user_id_min] = qual_0_t.loc[qual_0_t.index]\n",
    "print(full_qual_0_t)\n",
    "test_x_q0 = np.concatenate((test_x_, full_qual_0_t), axis=1)\n",
    "print(test_x_q0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "lgbm model auc score: 0.8978\n",
      "XGBoost model auc score: 0.8905\n",
      "cb model auc score: 0.8913\n",
      "mean value:  0.8932057633333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.856280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.184770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.282335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.829092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.697690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.856280\n",
       "1    30001  0.184770\n",
       "2    30002  0.282335\n",
       "3    30003  0.829092\n",
       "4    30004  0.697690"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(train_x_q0, train_y)\n",
    "y_pred1 = lgbm.predict(train_x_q0)\n",
    "print('lgbm model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred1)))\n",
    "\n",
    "model_xgb.fit(train_x_q0, train_y)\n",
    "y_pred2 = model_xgb.predict(train_x_q0)\n",
    "print('XGBoost model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred2)))\n",
    "\n",
    "cb.fit(train_x_q0, train_y)\n",
    "y_pred3 = cb.predict(train_x_q0)\n",
    "print('cb model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred3)))\n",
    "\n",
    "print('mean value: ', (roc_auc_score(train_y, y_pred1) + roc_auc_score(train_y, y_pred2) + roc_auc_score(train_y, y_pred3)) / 3)\n",
    "\n",
    "pred_y_list = []\n",
    "for model in [lgbm, model_xgb, cb]:\n",
    "    pred_y = model.predict(test_x_q0)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test9.csv\", index = False)\n",
    "pd.read_csv('test9.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test9: 중간값 사용, 제출 x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 50)\n",
      "[[0.00000000e+00 0.00000000e+00 3.05555556e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.75000000e-01 3.75000000e-01 1.34061728e+02 ... 0.00000000e+00\n",
      "  1.13444444e+03 3.75000000e-01]\n",
      " [2.18750000e-01 2.18750000e-01 2.00361111e+00 ... 0.00000000e+00\n",
      "  1.17600000e+01 2.18750000e-01]\n",
      " ...\n",
      " [8.83058985e-02 8.83058985e-02 6.02880658e-01 ... 0.00000000e+00\n",
      "  2.14814815e+00 8.83058985e-02]\n",
      " [0.00000000e+00 0.00000000e+00 7.22222222e-01 ... 0.00000000e+00\n",
      "  3.50000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(14999, 50)\n"
     ]
    }
   ],
   "source": [
    "qual_0 = train_qual_0.groupby('user_id').mad().loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0 = np.zeros((15000, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0[qual_0.index-10000] = qual_0.loc[qual_0.index]\n",
    "train_x_q0 = np.concatenate((train_x, full_qual_0), axis=1)\n",
    "print(train_x_q0.shape)\n",
    "\n",
    "test_qual_num = test_qual[['quality_' + str(i) for i in range(13)]].copy()\n",
    "\n",
    "del test_qual_num['quality_3']\n",
    "del test_qual_num['quality_4']\n",
    "del test_qual_num['quality_0']\n",
    "del test_qual_num['quality_6']\n",
    "del test_qual_num['quality_9']\n",
    "del test_qual_num['quality_12']\n",
    "\n",
    "obj_col = ['quality_1', 'quality_5', 'quality_7', 'quality_8', 'quality_10']\n",
    "num_col = ['quality_2', 'quality_11']\n",
    "\n",
    "for col in obj_col:\n",
    "    test_qual_num[col] = test_qual_num[col].astype(str).str.replace(',', '').astype(float)\n",
    "    \n",
    "new_test_qual = test_qual[['user_id', 'fwver', 'time']].join(test_qual_num)\n",
    "#display(new_test_qual.head())\n",
    "\n",
    "test_qual_0 = new_test_qual.fillna(0)\n",
    "qual_0_t = test_qual_0.groupby('user_id').mad().loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0_t = np.zeros((14999, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0_t[qual_0_t.index-test_user_id_min] = qual_0_t.loc[qual_0_t.index]\n",
    "print(full_qual_0_t)\n",
    "test_x_q0 = np.concatenate((test_x_, full_qual_0_t), axis=1)\n",
    "print(test_x_q0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost_search.best_params_, lightgbm_search.best_params_, xgb_search.best_params_\n",
    "\n",
    "cb = CatBoostRegressor(logging_level='Silent', **catboost_search.best_params_)\n",
    "model_xgb = xgb.XGBRegressor(**xgb_search.best_params_)\n",
    "lgbm = LGBMRegressor(**lightgbm_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "lgbm model auc score: 0.9006\n",
      "XGBoost model auc score: 0.8943\n",
      "cb model auc score: 0.8987\n",
      "mean value:  0.8978779966666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.848569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.280271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.254670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.783499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.689899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.848569\n",
       "1    30001  0.280271\n",
       "2    30002  0.254670\n",
       "3    30003  0.783499\n",
       "4    30004  0.689899"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(train_x_q0, train_y)\n",
    "y_pred1 = lgbm.predict(train_x_q0)\n",
    "print('lgbm model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred1)))\n",
    "\n",
    "model_xgb.fit(train_x_q0, train_y)\n",
    "y_pred2 = model_xgb.predict(train_x_q0)\n",
    "print('XGBoost model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred2)))\n",
    "\n",
    "cb.fit(train_x_q0, train_y)\n",
    "y_pred3 = cb.predict(train_x_q0)\n",
    "print('cb model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred3)))\n",
    "\n",
    "print('mean value: ', (roc_auc_score(train_y, y_pred1) + roc_auc_score(train_y, y_pred2) + roc_auc_score(train_y, y_pred3)) / 3)\n",
    "\n",
    "pred_y_list = []\n",
    "for model in [lgbm, model_xgb, cb]:\n",
    "    pred_y = model.predict(test_x_q0)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test10.csv\", index = False)\n",
    "pd.read_csv('test10.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test10: groupby.mad 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality_1</th>\n",
       "      <th>quality_2</th>\n",
       "      <th>quality_5</th>\n",
       "      <th>quality_7</th>\n",
       "      <th>quality_8</th>\n",
       "      <th>quality_10</th>\n",
       "      <th>quality_11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0        quality_1  quality_2  quality_5  quality_7  quality_8  quality_10  \\\n",
       "user_id                                                                      \n",
       "10000          0.0        0.0        0.0        0.0        0.0         4.0   \n",
       "10002          0.0        0.0        0.0        0.0        0.0         3.0   \n",
       "10004          0.0        0.0        0.0        0.0        0.0         1.0   \n",
       "10005          0.0        0.0       -1.0        0.0        0.0         4.0   \n",
       "10006          0.0        0.0        0.0        0.0        0.0         4.0   \n",
       "\n",
       "0        quality_11  \n",
       "user_id              \n",
       "10000           0.0  \n",
       "10002           0.0  \n",
       "10004           0.0  \n",
       "10005           0.0  \n",
       "10006           0.0  "
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_qual_0.groupby('user_id').apply(lambda x: x.mode().iloc[0]).head().loc[:, 'quality_1':'quality_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 50)\n",
      "[[0. 0. 0. ... 0. 2. 0.]\n",
      " [0. 0. 0. ... 0. 3. 0.]\n",
      " [0. 0. 0. ... 0. 3. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 2. 0.]\n",
      " [0. 0. 0. ... 0. 3. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(14999, 50)\n"
     ]
    }
   ],
   "source": [
    "qual_0 = train_qual_0.groupby('user_id').apply(lambda x: x.mode().iloc[0]).loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0 = np.zeros((15000, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0[qual_0.index-10000] = qual_0.loc[qual_0.index]\n",
    "train_x_q0 = np.concatenate((train_x, full_qual_0), axis=1)\n",
    "print(train_x_q0.shape)\n",
    "\n",
    "test_qual_num = test_qual[['quality_' + str(i) for i in range(13)]].copy()\n",
    "\n",
    "del test_qual_num['quality_3']\n",
    "del test_qual_num['quality_4']\n",
    "del test_qual_num['quality_0']\n",
    "del test_qual_num['quality_6']\n",
    "del test_qual_num['quality_9']\n",
    "del test_qual_num['quality_12']\n",
    "\n",
    "obj_col = ['quality_1', 'quality_5', 'quality_7', 'quality_8', 'quality_10']\n",
    "num_col = ['quality_2', 'quality_11']\n",
    "\n",
    "for col in obj_col:\n",
    "    test_qual_num[col] = test_qual_num[col].astype(str).str.replace(',', '').astype(float)\n",
    "    \n",
    "new_test_qual = test_qual[['user_id', 'fwver', 'time']].join(test_qual_num)\n",
    "#display(new_test_qual.head())\n",
    "\n",
    "test_qual_0 = new_test_qual.fillna(0)\n",
    "qual_0_t = test_qual_0.groupby('user_id').apply(lambda x: x.mode().iloc[0]).loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0_t = np.zeros((14999, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0_t[qual_0_t.index-test_user_id_min] = qual_0_t.loc[qual_0_t.index]\n",
    "print(full_qual_0_t)\n",
    "test_x_q0 = np.concatenate((test_x_, full_qual_0_t), axis=1)\n",
    "print(test_x_q0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "lgbm model auc score: 0.8966\n",
      "XGBoost model auc score: 0.8926\n",
      "cb model auc score: 0.8922\n",
      "mean value:  0.8938008166666666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.854712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.198431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.291205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.829099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.691000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.854712\n",
       "1    30001  0.198431\n",
       "2    30002  0.291205\n",
       "3    30003  0.829099\n",
       "4    30004  0.691000"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# catboost_search.best_params_, lightgbm_search.best_params_, xgb_search.best_params_\n",
    "\n",
    "cb = CatBoostRegressor(logging_level='Silent', **catboost_search.best_params_)\n",
    "model_xgb = xgb.XGBRegressor(**xgb_search.best_params_)\n",
    "lgbm = LGBMRegressor(**lightgbm_search.best_params_)\n",
    "\n",
    "lgbm.fit(train_x_q0, train_y)\n",
    "y_pred1 = lgbm.predict(train_x_q0)\n",
    "print('lgbm model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred1)))\n",
    "\n",
    "model_xgb.fit(train_x_q0, train_y)\n",
    "y_pred2 = model_xgb.predict(train_x_q0)\n",
    "print('XGBoost model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred2)))\n",
    "\n",
    "cb.fit(train_x_q0, train_y)\n",
    "y_pred3 = cb.predict(train_x_q0)\n",
    "print('cb model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred3)))\n",
    "\n",
    "print('mean value: ', (roc_auc_score(train_y, y_pred1) + roc_auc_score(train_y, y_pred2) + roc_auc_score(train_y, y_pred3)) / 3)\n",
    "\n",
    "pred_y_list = []\n",
    "for model in [lgbm, model_xgb, cb]:\n",
    "    pred_y = model.predict(test_x_q0)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test11.csv\", index = False)\n",
    "pd.read_csv('test11.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test11: 최빈값 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test11_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 50)\n",
      "[[0.00000000e+00 0.00000000e+00 5.77350269e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [4.39155033e-01 4.39155033e-01 2.96793622e+02 ... 0.00000000e+00\n",
      "  1.22032848e+03 4.39155033e-01]\n",
      " [3.32105582e-01 3.32105582e-01 5.04764415e+00 ... 0.00000000e+00\n",
      "  1.50699211e+01 3.32105582e-01]\n",
      " ...\n",
      " [2.11105646e-01 2.11105646e-01 1.01630869e+00 ... 0.00000000e+00\n",
      "  2.52587852e+00 2.11105646e-01]\n",
      " [0.00000000e+00 0.00000000e+00 9.31532943e-01 ... 0.00000000e+00\n",
      "  3.57527743e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "(14999, 50)\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "lgbm model auc score: 0.9021\n",
      "XGBoost model auc score: 0.8960\n",
      "cb model auc score: 0.8990\n",
      "mean value:  0.8990359099999999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.851073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.297793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.259600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.796066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.696561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.851073\n",
       "1    30001  0.297793\n",
       "2    30002  0.259600\n",
       "3    30003  0.796066\n",
       "4    30004  0.696561"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qual_0 = train_qual_0.groupby('user_id').std().loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0 = np.zeros((15000, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0[qual_0.index-10000] = qual_0.loc[qual_0.index]\n",
    "train_x_q0 = np.concatenate((train_x, full_qual_0), axis=1)\n",
    "print(train_x_q0.shape)\n",
    "\n",
    "test_qual_num = test_qual[['quality_' + str(i) for i in range(13)]].copy()\n",
    "\n",
    "del test_qual_num['quality_3']\n",
    "del test_qual_num['quality_4']\n",
    "del test_qual_num['quality_0']\n",
    "del test_qual_num['quality_6']\n",
    "del test_qual_num['quality_9']\n",
    "del test_qual_num['quality_12']\n",
    "\n",
    "obj_col = ['quality_1', 'quality_5', 'quality_7', 'quality_8', 'quality_10']\n",
    "num_col = ['quality_2', 'quality_11']\n",
    "\n",
    "for col in obj_col:\n",
    "    test_qual_num[col] = test_qual_num[col].astype(str).str.replace(',', '').astype(float)\n",
    "    \n",
    "new_test_qual = test_qual[['user_id', 'fwver', 'time']].join(test_qual_num)\n",
    "#display(new_test_qual.head())\n",
    "\n",
    "test_qual_0 = new_test_qual.fillna(0)\n",
    "qual_0_t = test_qual_0.groupby('user_id').std().loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0_t = np.zeros((14999, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0_t[qual_0_t.index-test_user_id_min] = qual_0_t.loc[qual_0_t.index]\n",
    "print(full_qual_0_t)\n",
    "test_x_q0 = np.concatenate((test_x_, full_qual_0_t), axis=1)\n",
    "print(test_x_q0.shape)\n",
    "\n",
    "cb = CatBoostRegressor(logging_level='Silent', **catboost_search.best_params_)\n",
    "model_xgb = xgb.XGBRegressor(**xgb_search.best_params_)\n",
    "lgbm = LGBMRegressor(**lightgbm_search.best_params_)\n",
    "\n",
    "lgbm.fit(train_x_q0, train_y)\n",
    "y_pred1 = lgbm.predict(train_x_q0)\n",
    "print('lgbm model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred1)))\n",
    "\n",
    "model_xgb.fit(train_x_q0, train_y)\n",
    "y_pred2 = model_xgb.predict(train_x_q0)\n",
    "print('XGBoost model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred2)))\n",
    "\n",
    "cb.fit(train_x_q0, train_y)\n",
    "y_pred3 = cb.predict(train_x_q0)\n",
    "print('cb model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred3)))\n",
    "\n",
    "print('mean value: ', (roc_auc_score(train_y, y_pred1) + roc_auc_score(train_y, y_pred2) + roc_auc_score(train_y, y_pred3)) / 3)\n",
    "\n",
    "pred_y_list = []\n",
    "for model in [lgbm, model_xgb, cb]:\n",
    "    pred_y = model.predict(test_x_q0)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test11_2.csv\", index = False)\n",
    "pd.read_csv('test11_2.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test11_2: std 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test11_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 57)\n",
      "[[ 0.0000e+00  0.0000e+00  2.0000e+00 ...  0.0000e+00  2.4000e+01\n",
      "   0.0000e+00]\n",
      " [-9.0000e+00 -9.0000e+00  2.5540e+03 ...  0.0000e+00  3.0756e+04\n",
      "  -9.0000e+00]\n",
      " [-1.5000e+01 -1.5000e+01  1.1800e+02 ...  0.0000e+00  1.5960e+03\n",
      "  -1.5000e+01]\n",
      " ...\n",
      " [-5.0000e+00 -5.0000e+00  3.2000e+01 ...  0.0000e+00  4.4400e+02\n",
      "  -5.0000e+00]\n",
      " [ 0.0000e+00  0.0000e+00  1.3000e+01 ...  0.0000e+00  1.5600e+02\n",
      "   0.0000e+00]\n",
      " [ 0.0000e+00  0.0000e+00  0.0000e+00 ...  0.0000e+00  0.0000e+00\n",
      "   0.0000e+00]]\n",
      "(14999, 57)\n"
     ]
    }
   ],
   "source": [
    "qual_0 = train_qual_0.groupby('user_id').sum().loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0 = np.zeros((15000, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0[qual_0.index-10000] = qual_0.loc[qual_0.index]\n",
    "train_x_q0_ = np.concatenate((train_x_q0, full_qual_0), axis=1)\n",
    "print(train_x_q0_.shape)\n",
    "\n",
    "test_qual_num = test_qual[['quality_' + str(i) for i in range(13)]].copy()\n",
    "\n",
    "del test_qual_num['quality_3']\n",
    "del test_qual_num['quality_4']\n",
    "del test_qual_num['quality_0']\n",
    "del test_qual_num['quality_6']\n",
    "del test_qual_num['quality_9']\n",
    "del test_qual_num['quality_12']\n",
    "\n",
    "obj_col = ['quality_1', 'quality_5', 'quality_7', 'quality_8', 'quality_10']\n",
    "num_col = ['quality_2', 'quality_11']\n",
    "\n",
    "for col in obj_col:\n",
    "    test_qual_num[col] = test_qual_num[col].astype(str).str.replace(',', '').astype(float)\n",
    "    \n",
    "new_test_qual = test_qual[['user_id', 'fwver', 'time']].join(test_qual_num)\n",
    "#display(new_test_qual.head())\n",
    "\n",
    "test_qual_0 = new_test_qual.fillna(0)\n",
    "qual_0_t = test_qual_0.groupby('user_id').sum().loc[:, 'quality_1':'quality_11']\n",
    "\n",
    "full_qual_0_t = np.zeros((14999, 7))\n",
    "# error와 동일한 방법으로 person_idx - 10000 위치에 \n",
    "# person_idx의 problem이 한 번이라도 발생했다면 1\n",
    "# 없다면 0\n",
    "full_qual_0_t[qual_0_t.index-test_user_id_min] = qual_0_t.loc[qual_0_t.index]\n",
    "print(full_qual_0_t)\n",
    "test_x_q0_ = np.concatenate((test_x_q0, full_qual_0_t), axis=1)\n",
    "print(test_x_q0_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "lgbm model auc score: 0.9034\n",
      "XGBoost model auc score: 0.8959\n",
      "cb model auc score: 0.8995\n",
      "mean value:  0.8995994533333334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.858972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.219879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.244954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.816365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.708748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.858972\n",
       "1    30001  0.219879\n",
       "2    30002  0.244954\n",
       "3    30003  0.816365\n",
       "4    30004  0.708748"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = CatBoostRegressor(logging_level='Silent', **catboost_search.best_params_)\n",
    "model_xgb = xgb.XGBRegressor(**xgb_search.best_params_)\n",
    "lgbm = LGBMRegressor(**lightgbm_search.best_params_)\n",
    "\n",
    "lgbm.fit(train_x_q0_, train_y)\n",
    "y_pred1 = lgbm.predict(train_x_q0_)\n",
    "print('lgbm model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred1)))\n",
    "\n",
    "model_xgb.fit(train_x_q0_, train_y)\n",
    "y_pred2 = model_xgb.predict(train_x_q0_)\n",
    "print('XGBoost model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred2)))\n",
    "\n",
    "cb.fit(train_x_q0_, train_y)\n",
    "y_pred3 = cb.predict(train_x_q0_)\n",
    "print('cb model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred3)))\n",
    "\n",
    "print('mean value: ', (roc_auc_score(train_y, y_pred1) + roc_auc_score(train_y, y_pred2) + roc_auc_score(train_y, y_pred3)) / 3)\n",
    "\n",
    "pred_y_list = []\n",
    "for model in [lgbm, model_xgb, cb]:\n",
    "    pred_y = model.predict(test_x_q0_)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test11_3.csv\", index = False)\n",
    "pd.read_csv('test11_3.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test11_3: quality add, std 열 추가 -> 제출?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_f12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>fwver</th>\n",
       "      <th>errtype</th>\n",
       "      <th>errcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101025616</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101030309</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101030309</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101050514</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101050515</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id            time       fwver  errtype errcode\n",
       "0    10000  20201101025616  05.15.2138       15       1\n",
       "1    10000  20201101030309  05.15.2138       12       1\n",
       "2    10000  20201101030309  05.15.2138       11       1\n",
       "3    10000  20201101050514  05.15.2138       16       1\n",
       "4    10000  20201101050515  05.15.2138        4       0"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_err.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>fwver</th>\n",
       "      <th>errtype</th>\n",
       "      <th>errcode</th>\n",
       "      <th>fw1</th>\n",
       "      <th>fw2</th>\n",
       "      <th>fw3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101025616</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>05</td>\n",
       "      <td>15</td>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101030309</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>05</td>\n",
       "      <td>15</td>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101030309</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>05</td>\n",
       "      <td>15</td>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101050514</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>05</td>\n",
       "      <td>15</td>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>20201101050515</td>\n",
       "      <td>05.15.2138</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>05</td>\n",
       "      <td>15</td>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id            time       fwver  errtype errcode fw1 fw2   fw3\n",
       "0    10000  20201101025616  05.15.2138       15       1  05  15  2138\n",
       "1    10000  20201101030309  05.15.2138       12       1  05  15  2138\n",
       "2    10000  20201101030309  05.15.2138       11       1  05  15  2138\n",
       "3    10000  20201101050514  05.15.2138       16       1  05  15  2138\n",
       "4    10000  20201101050515  05.15.2138        4       0  05  15  2138"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_err['fw1'] = train_err.fwver.str.split('.').str[0]\n",
    "train_err['fw2'] = train_err.fwver.str.split('.').str[1]\n",
    "train_err['fw3'] = train_err.fwver.str.split('.').str[2]\n",
    "train_err.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>fw1</th>\n",
       "      <th>fw2</th>\n",
       "      <th>fw3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>top</th>\n",
       "      <th>top</th>\n",
       "      <th>top</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>05</td>\n",
       "      <td>15</td>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>04</td>\n",
       "      <td>33</td>\n",
       "      <td>1261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>05</td>\n",
       "      <td>15</td>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>04</td>\n",
       "      <td>33</td>\n",
       "      <td>1261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>04</td>\n",
       "      <td>22</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fw1 fw2   fw3\n",
       "        top top   top\n",
       "user_id              \n",
       "10000    05  15  2138\n",
       "10001    04  33  1261\n",
       "10002    05  15  2138\n",
       "10003    04  33  1261\n",
       "10004    04  22  1750"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fw = train_err[['user_id', 'fw1', 'fw2', 'fw3']]\n",
    "fw_desc = train_fw.groupby('user_id').describe()\n",
    "fw = fw_desc.iloc[:, fw_desc.columns.get_level_values(1)=='top']\n",
    "fw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 3)"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fw_arr = fw.to_numpy()\n",
    "fw_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 60)"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_q0_fw = np.concatenate((train_x_q0_, fw_arr), axis=1)\n",
    "train_x_q0_fw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14999, 60)"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split fwver to 3 columns\n",
    "test_err['fw1'] = test_err.fwver.str.split('.').str[0]\n",
    "test_err['fw2'] = test_err.fwver.str.split('.').str[1]\n",
    "test_err['fw3'] = test_err.fwver.str.split('.').str[2]\n",
    "\n",
    "# select the most frquent values in 3 columns\n",
    "test_fw = test_err[['user_id', 'fw1', 'fw2', 'fw3']]\n",
    "fw_desc = test_fw.groupby('user_id').describe()\n",
    "fw = fw_desc.iloc[:, fw_desc.columns.get_level_values(1)=='top']\n",
    "\n",
    "# conver to numpy array\n",
    "fw_arr_test = fw.to_numpy()\n",
    "\n",
    "# 인덱스 맞춰주기??\n",
    "full_fw = np.zeros((14999, 3))\n",
    "full_fw[fw.index-test_user_id_min] = fw.loc[fw.index]\n",
    "\n",
    "# concat array\n",
    "test_x_q0_fw = np.concatenate((test_x_q0_, full_fw), axis=1)\n",
    "\n",
    "test_x_q0_fw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "lgbm model auc score: 0.9035\n",
      "XGBoost model auc score: 0.8971\n",
      "cb model auc score: 0.8988\n",
      "mean value:  0.8997963633333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.900958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.216581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.253440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.827457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.698259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.900958\n",
       "1    30001  0.216581\n",
       "2    30002  0.253440\n",
       "3    30003  0.827457\n",
       "4    30004  0.698259"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = CatBoostRegressor(logging_level='Silent', **catboost_search.best_params_)\n",
    "model_xgb = xgb.XGBRegressor(**xgb_search.best_params_)\n",
    "lgbm = LGBMRegressor(**lightgbm_search.best_params_)\n",
    "\n",
    "lgbm.fit(train_x_q0_fw, train_y)\n",
    "y_pred1 = lgbm.predict(train_x_q0_fw)\n",
    "print('lgbm model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred1)))\n",
    "\n",
    "model_xgb.fit(train_x_q0_fw, train_y)\n",
    "y_pred2 = model_xgb.predict(train_x_q0_fw)\n",
    "print('XGBoost model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred2)))\n",
    "\n",
    "cb.fit(train_x_q0_fw, train_y)\n",
    "y_pred3 = cb.predict(train_x_q0_fw)\n",
    "print('cb model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred3)))\n",
    "\n",
    "print('mean value: ', (roc_auc_score(train_y, y_pred1) + roc_auc_score(train_y, y_pred2) + roc_auc_score(train_y, y_pred3)) / 3)\n",
    "\n",
    "pred_y_list = []\n",
    "for model in [lgbm, model_xgb, cb]:\n",
    "    pred_y = model.predict(test_x_q0_fw)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test_f12.csv\", index = False)\n",
    "pd.read_csv('test_f12.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_f12: quality sum, std, fwver 3 column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_f12_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f122 = np.concatenate((train_x_q0, fw_arr), axis=1)\n",
    "test_f122 = np.concatenate((test_x_q0, full_fw), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "lgbm model auc score: 0.9019\n",
      "XGBoost model auc score: 0.8953\n",
      "cb model auc score: 0.8997\n",
      "mean value:  0.8989612766666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.878671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.299096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.273274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.826986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.712437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.878671\n",
       "1    30001  0.299096\n",
       "2    30002  0.273274\n",
       "3    30003  0.826986\n",
       "4    30004  0.712437"
      ]
     },
     "execution_count": 781,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = CatBoostRegressor(logging_level='Silent', **catboost_search.best_params_)\n",
    "model_xgb = xgb.XGBRegressor(**xgb_search.best_params_)\n",
    "lgbm = LGBMRegressor(**lightgbm_search.best_params_)\n",
    "\n",
    "lgbm.fit(train_f122, train_y)\n",
    "y_pred1 = lgbm.predict(train_f122)\n",
    "print('lgbm model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred1)))\n",
    "\n",
    "model_xgb.fit(train_f122, train_y)\n",
    "y_pred2 = model_xgb.predict(train_f122)\n",
    "print('XGBoost model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred2)))\n",
    "\n",
    "cb.fit(train_f122, train_y)\n",
    "y_pred3 = cb.predict(train_f122)\n",
    "print('cb model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred3)))\n",
    "\n",
    "print('mean value: ', (roc_auc_score(train_y, y_pred1) + roc_auc_score(train_y, y_pred2) + roc_auc_score(train_y, y_pred3)) / 3)\n",
    "\n",
    "pred_y_list = []\n",
    "for model in [lgbm, model_xgb, cb]:\n",
    "    pred_y = model.predict(test_f122)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test_f12_2.csv\", index = False)\n",
    "pd.read_csv('test_f12_2.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testf12_2: quality std, fwver 3 -> quality 정보가 많을수록 좋다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 60)\n",
      "(14999, 60)\n"
     ]
    }
   ],
   "source": [
    "# train data\n",
    "train_qual_f = new_train_qual.sort_values(by=['user_id', 'time']).fillna(method='ffill')\n",
    "train_qual_f = train_qual_f.fillna(0)\n",
    "\n",
    "# sum\n",
    "qual_0 = train_qual_f.groupby('user_id').sum().loc[:, 'quality_1':'quality_11']\n",
    "full_qual_0 = np.zeros((15000, 7))\n",
    "full_qual_0[qual_0.index-10000] = qual_0.loc[qual_0.index]\n",
    "\n",
    "# std\n",
    "qual_0 = train_qual_f.groupby('user_id').std().loc[:, 'quality_1':'quality_11']\n",
    "full_qual_1 = np.zeros((15000, 7))\n",
    "full_qual_1[qual_0.index-10000] = qual_0.loc[qual_0.index]\n",
    "\n",
    "# concat\n",
    "train_x_q0_ = np.concatenate((train_x, full_qual_0, full_qual_1, fw_arr), axis=1)\n",
    "print(train_x_q0_.shape)\n",
    "\n",
    "#test data\n",
    "test_qual_num = test_qual[['quality_' + str(i) for i in range(13)]].copy()\n",
    "\n",
    "# delete unwanted colums\n",
    "del test_qual_num['quality_3']\n",
    "del test_qual_num['quality_4']\n",
    "del test_qual_num['quality_0']\n",
    "del test_qual_num['quality_6']\n",
    "del test_qual_num['quality_9']\n",
    "del test_qual_num['quality_12']\n",
    "\n",
    "obj_col = ['quality_1', 'quality_5', 'quality_7', 'quality_8', 'quality_10']\n",
    "num_col = ['quality_2', 'quality_11']\n",
    "\n",
    "for col in obj_col:\n",
    "    test_qual_num[col] = test_qual_num[col].astype(str).str.replace(',', '').astype(float)\n",
    "    \n",
    "new_test_qual = test_qual[['user_id', 'fwver', 'time']].join(test_qual_num)\n",
    "#display(new_test_qual.head())\n",
    "\n",
    "# fillna\n",
    "test_qual_0 = new_test_qual.fillna(method='ffill')\n",
    "test_qual_0 = new_test_qual.fillna(0)\n",
    "\n",
    "#sum\n",
    "qual_0_t = test_qual_0.groupby('user_id').sum().loc[:, 'quality_1':'quality_11']\n",
    "full_qual_0_t = np.zeros((14999, 7))\n",
    "full_qual_0_t[qual_0_t.index-test_user_id_min] = qual_0_t.loc[qual_0_t.index]\n",
    "\n",
    "#std\n",
    "qual_1_t = test_qual_0.groupby('user_id').std().loc[:, 'quality_1':'quality_11']\n",
    "full_qual_1_t = np.zeros((14999, 7))\n",
    "full_qual_1_t[qual_1_t.index-test_user_id_min] = qual_1_t.loc[qual_1_t.index]\n",
    "\n",
    "#concat\n",
    "test_x_q0_ = np.concatenate((test_x_, full_qual_0_t, full_qual_1_t, full_fw), axis=1)\n",
    "print(test_x_q0_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0001, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "lgbm model auc score: 0.9037\n",
      "XGBoost model auc score: 0.8975\n",
      "cb model auc score: 0.8986\n",
      "mean value:  0.89995068\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>problem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.907646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.229830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.245918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.839090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.701422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id   problem\n",
       "0    30000  0.907646\n",
       "1    30001  0.229830\n",
       "2    30002  0.245918\n",
       "3    30003  0.839090\n",
       "4    30004  0.701422"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = CatBoostRegressor(logging_level='Silent', **catboost_search.best_params_)\n",
    "model_xgb = xgb.XGBRegressor(**xgb_search.best_params_)\n",
    "lgbm = LGBMRegressor(**lightgbm_search.best_params_)\n",
    "\n",
    "lgbm.fit(train_x_q0_, train_y)\n",
    "y_pred1 = lgbm.predict(train_x_q0_)\n",
    "print('lgbm model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred1)))\n",
    "\n",
    "model_xgb.fit(train_x_q0_, train_y)\n",
    "y_pred2 = model_xgb.predict(train_x_q0_)\n",
    "print('XGBoost model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred2)))\n",
    "\n",
    "cb.fit(train_x_q0_, train_y)\n",
    "y_pred3 = cb.predict(train_x_q0_)\n",
    "print('cb model auc score: {0:0.4f}'. format(roc_auc_score(train_y, y_pred3)))\n",
    "\n",
    "print('mean value: ', (roc_auc_score(train_y, y_pred1) + roc_auc_score(train_y, y_pred2) + roc_auc_score(train_y, y_pred3)) / 3)\n",
    "\n",
    "pred_y_list = []\n",
    "for model in [lgbm, model_xgb, cb]:\n",
    "    pred_y = model.predict(test_x_q0_)\n",
    "    pred_y_list.append(pred_y.reshape(-1,1))\n",
    "    \n",
    "pred_ensemble = np.mean(pred_y_list, axis = 0)\n",
    "sample_submssion = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_submssion['problem'] = pred_ensemble.reshape(-1)\n",
    "\n",
    "sample_submssion.to_csv(\"test_13.csv\", index = False)\n",
    "pd.read_csv('test_13.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test13: fillna=ffill, qulity std and sum, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3633, number of negative: 8367\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7574\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302750 -> initscore=-0.834237\n",
      "[LightGBM] [Info] Start training from score -0.834237\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.802929\tvalid_0's pr_auc: 0.789782\n",
      "[40]\tvalid_0's auc: 0.81014\tvalid_0's pr_auc: 0.803029\n",
      "[60]\tvalid_0's auc: 0.809061\tvalid_0's pr_auc: 0.802543\n",
      "[80]\tvalid_0's auc: 0.808551\tvalid_0's pr_auc: 0.802337\n",
      "[100]\tvalid_0's auc: 0.807865\tvalid_0's pr_auc: 0.802405\n",
      "[120]\tvalid_0's auc: 0.805878\tvalid_0's pr_auc: 0.801123\n",
      "[140]\tvalid_0's auc: 0.804825\tvalid_0's pr_auc: 0.801623\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.810818\tvalid_0's pr_auc: 0.80384\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4828, number of negative: 7172\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7747\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.402333 -> initscore=-0.395752\n",
      "[LightGBM] [Info] Start training from score -0.395752\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.810476\tvalid_0's pr_auc: 0.325038\n",
      "[40]\tvalid_0's auc: 0.813244\tvalid_0's pr_auc: 0.340273\n",
      "[60]\tvalid_0's auc: 0.810839\tvalid_0's pr_auc: 0.332119\n",
      "[80]\tvalid_0's auc: 0.813121\tvalid_0's pr_auc: 0.336721\n",
      "[100]\tvalid_0's auc: 0.812685\tvalid_0's pr_auc: 0.330062\n",
      "[120]\tvalid_0's auc: 0.811394\tvalid_0's pr_auc: 0.328665\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.812416\tvalid_0's pr_auc: 0.347959\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4718, number of negative: 7282\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7858\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.393167 -> initscore=-0.434021\n",
      "[LightGBM] [Info] Start training from score -0.434021\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.780465\tvalid_0's pr_auc: 0.4002\n",
      "[40]\tvalid_0's auc: 0.782672\tvalid_0's pr_auc: 0.403856\n",
      "[60]\tvalid_0's auc: 0.779212\tvalid_0's pr_auc: 0.411403\n",
      "[80]\tvalid_0's auc: 0.779669\tvalid_0's pr_auc: 0.411143\n",
      "[100]\tvalid_0's auc: 0.779398\tvalid_0's pr_auc: 0.405052\n",
      "[120]\tvalid_0's auc: 0.778281\tvalid_0's pr_auc: 0.404736\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.785128\tvalid_0's pr_auc: 0.401065\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 4544, number of negative: 7456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7750\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.378667 -> initscore=-0.495211\n",
      "[LightGBM] [Info] Start training from score -0.495211\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.814217\tvalid_0's pr_auc: 0.493064\n",
      "[40]\tvalid_0's auc: 0.816245\tvalid_0's pr_auc: 0.548171\n",
      "[60]\tvalid_0's auc: 0.816285\tvalid_0's pr_auc: 0.54478\n",
      "[80]\tvalid_0's auc: 0.816245\tvalid_0's pr_auc: 0.543809\n",
      "[100]\tvalid_0's auc: 0.814368\tvalid_0's pr_auc: 0.539014\n",
      "[120]\tvalid_0's auc: 0.811347\tvalid_0's pr_auc: 0.532606\n",
      "[140]\tvalid_0's auc: 0.81057\tvalid_0's pr_auc: 0.534175\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.817218\tvalid_0's pr_auc: 0.551873\n",
      "==========================================================\n",
      "[LightGBM] [Info] Number of positive: 2277, number of negative: 9723\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7453\n",
      "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 59\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.189750 -> initscore=-1.451635\n",
      "[LightGBM] [Info] Start training from score -1.451635\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\tvalid_0's auc: 0.804001\tvalid_0's pr_auc: 0.97428\n",
      "[40]\tvalid_0's auc: 0.8073\tvalid_0's pr_auc: 0.9738\n",
      "[60]\tvalid_0's auc: 0.811745\tvalid_0's pr_auc: 0.974468\n",
      "[80]\tvalid_0's auc: 0.814191\tvalid_0's pr_auc: 0.975299\n",
      "[100]\tvalid_0's auc: 0.814079\tvalid_0's pr_auc: 0.975629\n",
      "[120]\tvalid_0's auc: 0.810283\tvalid_0's pr_auc: 0.975496\n",
      "[140]\tvalid_0's auc: 0.810124\tvalid_0's pr_auc: 0.975534\n",
      "[160]\tvalid_0's auc: 0.807551\tvalid_0's pr_auc: 0.975368\n",
      "[180]\tvalid_0's auc: 0.807159\tvalid_0's pr_auc: 0.975344\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.814613\tvalid_0's pr_auc: 0.975627\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "#-------------------------------------------------------------------------------------\n",
    "# validation auc score를 확인하기 위해 정의\n",
    "def f_pr_auc(probas_pred, y_true):\n",
    "    labels=y_true.get_label()\n",
    "    p, r, _ = precision_recall_curve(labels, probas_pred)\n",
    "    score=auc(r,p) \n",
    "    return \"pr_auc\", score, True\n",
    "#-------------------------------------------------------------------------------------\n",
    "models     = []\n",
    "recalls    = []\n",
    "precisions = []\n",
    "auc_scores   = []\n",
    "threshold = 0.5\n",
    "# 파라미터 설정\n",
    "params =      {\n",
    "                'boosting_type' : 'gbdt',\n",
    "                'objective'     : 'binary',\n",
    "                'metric'        : 'auc',\n",
    "                'seed': 1015\n",
    "                }\n",
    "#-------------------------------------------------------------------------------------\n",
    "# 5 Kfold cross validation\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_idx, val_idx in k_fold.split(train_x):\n",
    "\n",
    "    # split train, validation set\n",
    "    X = train_x_q0_[train_idx]\n",
    "    y = train_y[train_idx]\n",
    "    valid_x = train_x_q0_[val_idx]\n",
    "    valid_y = train_y[val_idx]\n",
    "\n",
    "    d_train= lgb.Dataset(X, y)\n",
    "    d_val  = lgb.Dataset(valid_x, valid_y)\n",
    "    \n",
    "    #run traning\n",
    "    model = lgb.train(\n",
    "                        params,\n",
    "                        train_set       = d_train,\n",
    "                        num_boost_round = 1000,\n",
    "                        valid_sets      = d_val,\n",
    "                        feval           = f_pr_auc,\n",
    "                        verbose_eval    = 20, \n",
    "                        early_stopping_rounds = 100\n",
    "                       )\n",
    "    \n",
    "    # cal valid prediction\n",
    "    valid_prob = model.predict(valid_x)\n",
    "    valid_pred = np.where(valid_prob > threshold, 1, 0)\n",
    "    \n",
    "    # cal scores\n",
    "    recall    = recall_score(    valid_y, valid_pred)\n",
    "    precision = precision_score( valid_y, valid_pred)\n",
    "    auc_score = roc_auc_score(   valid_y, valid_prob)\n",
    "\n",
    "    # append scores\n",
    "    models.append(model)\n",
    "    recalls.append(recall)\n",
    "    precisions.append(precision)\n",
    "    auc_scores.append(auc_score)\n",
    "\n",
    "    print('==========================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8080384967172769\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
